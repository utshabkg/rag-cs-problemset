Q_ID,Domain,Question,Answer,Difficulty,Source
1,Networking,The following data fragment occurs in the middle of a data stream for which the bytestuffing algorithm described in the text is used: A B ESC C ESC FLAG FLAG D. What is the output after stuffing?,A B ESC ESC C ESC ESC ESC FLAG ESC FLAG D,Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
2,Networking,What is the maximum overhead in byte-stuffing algorithm?,"The maximum overhead occurs when the payload consists of only ESC and
FLAG bytes. In this case, there will be 100% overhead.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
3,Networking,"A 12-bit Hamming code whose hexadecimal value is 0xE4F arrives at a receiver.
What was the original value in hexadecimal? Assume that not more than 1 bit is in
error.","If we number the bits from left to right starting at bit 1, in this example bit 2
(a parity bit) is incorrect. The 12-bit value transmitted (after Hamming encoding)
was 0xA4F. The original 8-bit data value was 0xAF.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
4,Networking,"What is the length of a contention slot in CSMA/CD for (a) a 2-km twin-lead cable
(signal propagation speed is 82% of the signal propagation speed in vacuum)?, and (b)
a 40-km multimode fiber optic cable (signal propagation speed is 65% of the signal
propagation speed in vacuum)?","(a) Signal propagation speed in twin lead is 2.46 × 108 m/sec. Signal propagation
time for 2 km is 8.13 μsec. So, the length of contention slot is 16.26
μsec. (b) Signal propagation speed in multimode fiber is 1.95 × 108 m/s. Signal
propagation time for 40 km is 205.13 μsec. So, the length of contention
slot is 410.26 μsec.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
5,Networking,Sketch the Manchester encoding on a classic Ethernet for the bit stream 0001110101.,"The signal is a square wave with two values, high (H) and low (L). The pattern
is LHLHLHHLHLHLLHHLLHHL",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
6,Networking,One important difference between a bridge and a router?,"Bridge is L2 switching, router is L3 routing with routing tables.",Easy,UMass CMPSCI453 Final 2002
7,Networking,Do ATM cells carry source or destination addresses in the header?,No. They carry VPI/VCI only.,Easy,UMass CMPSCI453 Final 2002
8,Networking,True or False: An input port on a router performs the physical layer function of line termination.,True,Easy,UCalgary CPSC441 Final 2021
9,Networking,True or False: Every datalink layer protocol requires a MAC channel access protocol.,False,Easy,UCalgary CPSC441 Final 2021
10,Networking,What is a distinctive feature of Asynchronous Transfer Mode ATM networks,ATM uses fixed size 53 byte packets called cells rather than variable length packets,Easy,University of Calgary Final F2018 solution Q2
11,Networking,On classic Ethernet what is the maximum transmission unit MTU for an IP datagram,The Ethernet MTU for an IP datagram is 1500 bytes,Easy,University of Calgary Final F2018 solution Q2
12,Networking,Does every data link layer protocol require a MAC channel access protocol,False point to point links do not need a multiple access control protocol,Easy,University of Calgary  Final F2021 solution Q3
13,Networking,Is an Ethernet switch a link layer device,True it operates at layer two and forwards based on MAC addresses,Easy,University of Calgary Final F2021 solution Q6
14,Networking,Is Cyclic Redundancy Check a powerful error correction code,False CRC is used for error detection not for correcting errors,Easy,University of Calgary Final F2021 solution Q7
15,Networking,Which IP address is private? (a) 10.13.159.125 (b) 172.186.11.21 (c) 244.244.244.244 (d) 11.189.11.21 (e) 192.166.125.221,(a) 10.13.159.125,Easy,UCalgary CPSC441 Final 2021
16,Networking,The allocation of IP addresses is managed by: (a) ICANN (b) IEEE (c) IETF (d) Internet Society (e) Prof. Williamson,(a) ICANN,Easy,UCalgary CPSC441 Final 2021
17,Networking,IP-in-IP tunneling can support: (a) mobility with stable identity (b) IPv6 over IPv4 (c) multicast overlay (d) all (e) none,(d) all of the above,Easy,UCalgary CPSC441 Final 2021
18,Networking,Which algorithm is used in Routing Information Protocol (RIP) ? (a) Dijkstra (b) Bellman–Ford (c) Prim (d) Floyd–Warshall (e) Kruskal,(b) Bellman–Ford,Easy,UCalgary CPSC441 Final 2021
19,Networking,Each AS communicates with other ASes using: (a) IS-IS (b) OSPF (c) RIP (d) BGP (e) none,(d) BGP,Easy,UCalgary CPSC441 Final 2021
20,Networking,What does it mean to be multihomed?,Connected to two or more networks or ISPs.,Easy,UMass CMPSCI453 Final 2002
21,Networking,"In BGP, how can an AS A control whether others route traffic to destination X via A?",By advertising or not advertising paths to X.,Easy,UMass CMPSCI453 Final 2002
22,Networking,"Assuming that all routers and hosts are working properly and that all software in both
is free of all errors, is there any chance, however small, that a packet will be delivered
to the wrong destination?","Yes. A large noise burst could garble a packet badly. With a k-bit checksum, there is a probability of 2^−k that the error is undetected. If the destination field or, equivalently, virtual-circuit number, is changed, the packet will be delivered to the wrong destination and accepted as genuine. Put in other words, an occasional noise burst could change a perfectly legal packet for one destination into a perfectly legal packet for another destination.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
23,Networking,"Describe two major differences between the ECN method and the RED method of
congestion avoidance.","First, the ECN method explicitly sends a congestion notification to the source
by setting a bit, whereas RED implicitly notifies the source by simply dropping
one of its packets. Second, the ECN method drops a packet only when
there is no buffer space left, whereas RED drops packets before all the buffer
are exhausted.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
24,Networking,"A token bucket scheme is used for traffic shaping. A new token is put into the bucket
every 5 μsec. Each token is good for one short packet, which contains 48 bytes of
data. What is the maximum sustainable data rate?","With a token every 5 μsec, 200,000 cells/sec can be sent. Each packet holds
48 data bytes or 384 bits. The net data rate is then 76.8 Mbps.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
25,Networking,In a Class B IPv4 address such as 136.159.5.20 how long is the network identifier portion,In Class B the network identifier is 16 bits long corresponding to the first two octets for this example 136.159,Easy,University of Calgary Final F2018 solution Q9
26,Networking,In Classless Inter Domain Routing CIDR what is the length of the network identifier in an IPv4 address,The network identifier length is variable and is specified by the prefix length notation for example slash 20 or slash 24 so none of the fixed length options apply,Easy,University of Calgary Final F2018 solution Q10
27,Networking,Is the statement correct that an input port on a router performs the physical layer function of line termination,True,Easy,University of Calgary Final F2021 solution Q1
28,Networking,Does the Link State routing algorithm suffer from the count to infinity problem,False the count to infinity problem is a weakness of distance vector routing not Link State routing,Easy,University of Calgary  Final F2021 solution Q2
29,Networking,Is IP fragmentation a new feature that is supported in IPv6 but not in IPv4,False IPv4 supports fragmentation while IPv6 removes it from routers,Easy,University of Calgary Final F2021 solution Q4
30,Networking,Is it correct to say that BGP is the glue that holds Internet routing together,True BGP is the inter domain routing protocol that connects autonomous systems,Easy,University of Calgary Final F2021 solution Q5
31,Networking,Why add playout delay for Internet voice?,To compensate for variable delay (jitter).,Easy,UMass CMPSCI453 Final 2002
32,Networking,Wireless TCP: Which mechanism does TCP use to detect bit errors?,Internet checksum.,Easy,UMass CMPSCI453 Final 2002
33,Networking,AIMD sawtooth: relation between (W_{\min}) and (W_{\max}) after a loss,(W_{\min}= \frac{1}{2} W_{\max}),Easy,Stanford CS144 Midterm Fall 2020
34,Networking,Ideal buffer for full utilization with AIMD on a single bottleneck,Buffer = one BDP,Easy,Stanford CS144 Midterm Fall 2020
35,Networking,Data in flight just before a loss with AIMD at steady state,2 × BDP,Easy,Stanford CS144 Midterm Fall 2020
36,Networking,"Why does UDP exist? Would it not have been enough to just let user processes send
raw IP packets?","No. IP packets contain IP addresses, which specify a destination machine.
Once such a packet arrived, how would the network handler know which process
to give it to? UDP packets contain a destination port. This information
is essential so they can be delivered to the correct process.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
37,Networking,"Both UDP and TCP use port numbers to identify the destination entity when delivering
a message. Give two reasons why these protocols invented a new abstract ID (port
numbers), instead of using process IDs, which already existed when these protocols
were designed.","Here are three reasons. First, process IDs are OS-specific. Using process IDs
would have made these protocols OS-dependent. Second, a single process
may establish multiple channels of communications. A single process ID (per
process) as the destination identifier cannot be used to distinguish between
these channels. Third, having processes listen on well-known ports is easy,
but well-known process IDs are impossible.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
38,Networking,"Datagram fragmentation and reassembly are handled by IP and are invisible to TCP.
Does this mean that TCP does not have to worry about data arriving in the wrong
order?","Even though each datagram arrives intact, it is possible that datagrams arrive
in the wrong order, so TCP has to be prepared to reassemble the parts of a
message properly.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
39,Networking,"RTP is used to transmit CD-quality audio, which makes a pair of 16-bit samples
44,100 times/sec, one sample for each of the stereo channels. How many packets per
second must RTP transmit?","Each sample occupies 4 bytes. This gives a total of 256 samples per packet.
There are 44,100 samples/sec, so with 256 samples/packet, it takes 44100/256
or 172 packets to transmit one second’s worth of music.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
40,Networking,Give one reason that DNS lookups are run over UDP rather than TCP.,"Avoids connection setup overhead for short, small queries.",Easy,CMU 15-441 Final Spring 2005 
41,Networking,You turn on a laptop and browse to https colon slash slash cs144 dot stanford dot edu. In order of first use which protocols and messages are involved to obtain an IP address learn the local MAC next hop resolve the hostname open a TCP connection establish security verify server identity and request the page root path Give protocol or flag names,DHCP then ARP then DNS then TCP SYN then TLS and CA verify then HTTP GET slash,Easy,Stanford CS144 Final Spring 2023 Ans
42,Networking,"Can a machine with a single DNS name have multiple IP addresses? How could this
occur?","Yes. If a machine has two Ethernet cards, it can be on two separate networks,
and if so, it needs two IP addresses.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
43,Networking,"Suppose that you want to send an MP3 file to a friend, but your friend’s ISP limits the
size of each incoming message to 1 MB and the MP3 file is 4 MB. Is there a way to
handle this situation by using RFC 5322 and MIME?","Yes. Use the message/external-body subtype and just send the URL of the file
instead of the actual file.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
44,Networking,"When Web pages are sent out, they are prefixed by MIME headers. Why?","The browser has to be able to know whether the page is text, audio, video, or
something else. The MIME headers provide this information",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
45,Networking,What is the main difference between HTTP and HTTPS,HTTP traffic is sent in clear text while HTTPS encrypts the application data using transport layer security on top of TCP,Easy,University of Calgary Final F2018 solution Q2
46,Networking,Is DHCP considered an application layer protocol,True DHCP runs in the application layer and typically uses UDP,Easy,University of Calgary Final F2021 solution Q9
47,Networking,In the same home networking question what is one reason to use DHCP in a home network,DHCP makes it easy to add new devices or allow guests on WiFi because IP configuration is assigned automatically,Easy,University of Calgary Final F2021 solution Q24 example 4
48,Networking,"Alice used a transposition cipher to encrypt her messages to Bob. For added security,
she encrypted the transposition cipher key using a substitution cipher, and kept the encrypted
cipher in her computer. Trudy managed to get hold of the encrypted
transposition cipher key. Can Trudy decipher Alice’s messages to Bob? Why or why
not?","By getting hold of the encrypted key, Trudy now knows the length of the key.
She can therefore determine how many columns there were in the transposition
cipher matrix, and can break the ciphertext into columns. Subsequently,
all Trudy has to do in order to decipher the message is try out all the arrangements
of the columns until she finds one that makes sense. Assuming that the
length of the encrypted key is k characters, finding the correct arrangement of
the columns would require at most 2^k attempts.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
49,Networking,"You are a spy, and, conveniently, have a library with an infinite number of books at
your disposal. Your operator also has such a library at his disposal. You have agreed to use Lord of the Rings as a one-time pad. Explain how you could use these assets to
generate an infinitely long one-time pad.","You could use ASCII representation of the characters in Lord of the Rings to
encrypt your messages. This will give you a one-time pad which is as long as
the number of bits required to represent all the characters in Lord of the
Rings. When you are near the end of the book, and your key is almost used
up, you use the last portion of the book to send a message announcing the
name of the next book you will be using as your one-time pad, and switch to
that book for your subsequent messages. By continuing in this routine, because
you have an infinite number of books, you also have an infinitely long
one-time pad.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
50,Networking,"Quantum cryptography requires having a photon gun that can, on demand, fire a single
photon carrying 1 bit. In this problem, calculate how many photons a bit carries on a
250-Gbps fiber link. Assume that the length of a photon is equal to its wavelength,
which for purposes of this problem, is 1 micron. The speed of light in fiber is 20
cm/nsec.","At 250 Gbps, a bit takes 4 × 10−12 sec to be transmitted. With the speed of
light being 2 × 108 meters/sec, in 1 bit time, the light pulse achieves a length
of 0.8 mm or 800 microns. Since a photon is about 1 micron in length, the
pulse is 800 photons long. Thus, we are nowhere near one photon per bit
even at 250 Gbps. Only at 200 Tbps do we achieve 1 bit per photon.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
51,Networking,"If Trudy captures and regenerates photons when quantum cryptography is in use, she
will get some of them wrong and cause errors to appear in Bob’s one-time pad. What
fraction of Bob’s one-time pad bits will be in error, on average?","Half the time Trudy will guess right. All those bits will be regenerated correctly.
The other half she will guess wrong and send random bits to Bob.
Half of these will be wrong. Thus, 25% of the bits she puts on the fiber will
be wrong. Bob’s one-time pad will thus be 75% right and 25% wrong",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
52,Networking,"Alice wants to send a message to Bob using SHA-1 hashes. She consults with you
regarding the appropriate signature algorithm to be used. What would you suggest?","The recommended method would be by using HMACs, since they are computationally
faster than using RSA. However, this requires establishing a shared
key with Bob prior to the transmission of the message.",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
53,Networking,"Give one reason why a firewall might be configured to inspect incoming traffic. Give
one reason why it might be configured to inspect outgoing traffic. Do you think the
inspections are likely to be successful?","Incoming traffic might be inspected for the presence of viruses. Outgoing
traffic might be inspected to see if company confidential information is leaking
out. Checking for viruses might work if a good antivirus program is used.
Checking outgoing traffic, which might be encrypted, is nearly hopeless
against a serious attempt to leak information",Easy,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
54,Networking,ElGamal variant decryption blank: compute (K = H(______)) before decrypting (C_2). What goes in the blank?,(C_1^b \bmod p),Easy,Berkeley CS161 Spring 2025 Midterm Q7
55,Networking,True or False: Cipher Block Chaining (CBC) mode encryption is secure under indistinguishability under chosen plaintext attack (IND CPA) even if the initialization vector (IV) is reused across multiple encryptions with the same key.,False,Easy,Berkeley CS161 Spring 2025 Midterm Q2
56,Networking,Why can the IP UDP and TCP checksums not protect against a malicious party that modifies packets in transit Give one to two concise sentences,Unkeyed checksums cannot stop intentional modification,Easy,Stanford CS144 Final Spring 2023 Ans
57,Networking,How does a MAC or an AEAD cipher preserve integrity against intentional modification by an adversary Give one to two concise sentences,Secret key tag prevents forgeries,Easy,Stanford CS144 Final Spring 2023 Ans
58,Networking,If an attacker host C must guess a 32 bit TCP sequence number chosen uniformly at random how many guesses are needed on average to get the correct value.,Approximately 2^31 guesses.,Easy,Final_2007_soln Q20 part a
59,Networking,If the attacker already knows 12 bits of the 32 bit TCP sequence number how many guesses are needed on average to guess the remaining bits correctly.,Approximately 2^19 guesses.,Easy,Final_2007_soln Q20 follow up
60,Networking,"Link layer. Which of the following are true?
(a.) An Ethernet switch can interconnect a 10Mb/s Ethernet network and a 1Gb/s Ethernet.
(b.) An Ethernet hub can interconnect a 10Mb/s Ethernet network and a 1Gb/s Ethernet.
(c.) An Ethernet network cannot detect collisions until it has computed a checksum over the frame.
(d.) 4B/5B is considered more efficient than Manchester encoding because more user data is transmitted in same amount of time.
(e.) The 802.11b wireless protocol incorporates a link-layer ACK not present in regular Ethernet.","a,d,e",Medium,Stanford – CS244a Final 2007
61,Networking,"CSMA/CD. In a CSMA/CD network we require TRANSP >2PROP because:
(a.) PROP is the round-trip time from a source to the destination and back again. Therefore, it must be at least twice the one way propagation delay.
(b.) Otherwise, the signal would degrade too much along the wire making it difficult to detect collisions.
(c.) The sender needs to unambiguously determine that a packet encountered a collision before it finishes transmitting the packet.
(d.) In any network (regardless of whether we use CSMA/CD or not) the transmission time of a packet is a function of both the data rate, and speed of propagation
along the wire.",c,Medium,Stanford – CS244a Final 2007
62,Networking,Why can WiFi not use collision detection like Ethernet,In air the local transmit power swamps the receiver and signals lose strength quickly so a sender cannot listen while sending and collision detection is not feasible WiFi must use collision avoidance,Medium,Book (Computer Networking Problems and Solutions.)
63,Networking,When is RTS CTS expected to help throughput,Throughput benefit depends on the number of senders and receivers and on frame length,Medium,Book (Computer Networking Problems and Solutions.)
64,Networking,"If Parallel Iterative Matching (PIM) runs to completion in each cell time until no more connections can be added, what is the maximum number of iterations required for an N×N switch? Options: A) log₂(N), B) N/2, C) N, D) log₂(N)+1.",C) N.,Medium,Stanford CS244 Midterm 2016
65,Networking,"Parallel Iterative Matching (PIM): The paper proves a lower bound on the expected fraction of unresolved requests resolved each iteration. Options: A) 3/4, B) 1/4, C) 1/2, D) None.",A) 3/4.,Medium,Stanford CS244 Midterm 2016 
66,Networking,"Parallel Iterative Matching (PIM) tuning: If outputs are twice as likely to grant a requester that received no other grants (2k/n), what happens to convergence time? Options: A) No effect, B) Faster resolves ≥7/8, C) Faster resolves ≥3/8, D) Slower resolves ≥1/8.","B) Converges faster, resolving at least 7/8 per iteration.",Medium,Stanford CS244 Midterm 2016 
67,Networking,"For IP telephony only, which MACs fit: TDMA, CSMA, Slotted Aloha, Token Passing?","Good: TDMA, Token. Bad: CSMA, Slotted Aloha.",Medium,UMass CMPSCI453 Final 2002
68,Networking,"For occasional data bursts, which MACs fit?","Good: CSMA, Slotted Aloha; OK: Token; Poor: TDMA.",Medium,UMass CMPSCI453 Final 2002
69,Networking,"For a LAN mixing voice (priority) and data, what access strategy?",Priority token or TDMA for voice plus random access for data.,Medium,UMass CMPSCI453 Final 2002
70,Networking,"An upper-layer packet is split into 10 frames, each of which has an 80% chance of arriving  undamaged. If no error control is done by the data link protocol, how many times must the message be sent on average to get the entire thing through?","Since each frame has a chance of 0.8 of getting through, the probability that all 10 frames of the message get through in one attempt is p = 0.8^10 ≈ 0.107. The expected number of transmissions is E = Σ_{i=1}^{∞} i·p·(1−p)^{i−1}. Using the geometric series formula S = Σ_{i=0}^{∞} α^i = 1/(1−α) and differentiating to get Σ_{i=1}^{∞} i·α^{i−1} = 1/(1−α)^2, then setting α = 1−p gives E = p · (1/p^2) = 1/p ≈ 1/0.107 ≈ 9.3, so on average the entire message must be sent about 9.3 times.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
71,Networking,"Compute the fraction of the bandwidth that is wasted on overhead (headers and retransmissions)
for protocol 6 on a heavily loaded 50-kbps satellite channel with data
frames consisting of 40 header and 3960 data bits. Assume that the signal propagation
time from the earth to the satellite is 270 msec. ACK frames never occur. NAK frames
are 40 bits. The error rate for data frames is 1%, and the error rate for NAK frames is
negligible. The sequence numbers are 8 bits.","With a 50-kbps channel and 8-bit sequence numbers, the pipe is always full. The number of retransmissions per frame is about 0.01. Each good frame wastes 40 header bits, plus 1% of 4000 bits (retransmission), plus a 40-bit NAK once every 100 frames. The total overhead is 80.4 bits per 3960 data bits, giving 80.4/(3960 + 80.4) = 1.99%.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
72,Networking,"The distance from earth to a distant planet is approximately 9 × 1010 m. What is the
channel utilization if a stop-and-wait protocol is used for frame transmission on a 64
Mbps point-to-point link? Assume that the frame size is 32 KB and the speed of light
is 3 × 108 m/s.","Link utilization = (1/(1 + 2BD))
BD = bandwidth-delay product / frame size
delay = (9 × 1010)/(3 × 108) = 300 sec
bandwidth-delay product = 64 ×300 = 19.2 Gb
BD = 19200000 / 256 = 75000
So, link utilization is 6.67 × 10−4%",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
73,Networking,"A switch designed for use with fast Ethernet has a backplane that can move 10 Gbps.
How many frames/sec can it handle in the worst case?","The worst case is an endless stream of 64-byte (512-bit) frames. If the backplane
can handle 109 bps, the number of frames it can handle is 109 /512. This
is 1,953,125 frames/sec.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
74,Networking,"The Ethernet network has two end hosts connected by two store and forward Ethernet switches. The link from host A to the first switch runs at 100 Mb per second. The other two links run at 1 Gb per second. All links are 200 meters long and propagation speed is 2×10^8 meters per second. If host A sends a 1000 bit packet to host B and there is no other traffic, how long is it from the first bit leaving A until the last bit reaches B",Propagation delay is 600 meters divided by 2×10^8 meters per second which is 3 microseconds. Transmission delay is 1000 times the sum of 1 over 100×10^6 plus 1 over 10^9 plus 1 over 10^9 which is about 12 microseconds. Total end to end latency is 15 microseconds,Medium,CS144 practice final answers question 2
75,Networking,"Assuming that there are 100 million households in the US, and that each household has two HDTVs, and that each HDTV is used to watch 4 hours of video per day. We’ll assume that each (compressed) video stream runs at 9Mb/s. If all households are watching TV at the same time, but all watching video on-demand (i.e. data is delivered unicast to every household), then
which of the following is the closest approximation of the total peak aggregate data rate delivered to all homes?
(a.) 100 Tb/s ( 12 100!10b/s)
(b.) 2 Pb/s ( 15 2!10b/s)
(c.) 1 Pb/s
(d.) 100 Gb/s
(e.) 2 Tb/s",b,Medium,Standford Final 2007
76,Networking,"Now let’s compare our answer above with an estimate of the future capacity needed to carry web traffic. We’ll assume 100 million people download an average of 100 web pages per day, each containing 1Mbyte of data. If the peak traffic is five times the average, then which of the following is the closest estimate of the capacity needed by the network to deliver this traffic?
(a.) 10Gb/s
(b.) 500Gb/s
(c.) 1 Tb/s
(d.) 5 Tb/s
(e.) 10 Tb/s",d,Medium,Standford Final 2007
77,Networking,"Three users are sharing a common link of 1 Mb/s. User A is downloading large files and is connected to the common link via a slow access link at x Mb/s, user B is connected via a 100 Mb/s link, but the application she is using requires at most x Mb/s, and finally user C is connected via a 1 Gb/s link and is downloading a movie that can take up any amount of bandwidth available to it. What is the max-min fair allocation for these three flows at the common link?","Two Cases: 1) If x < 1/3Mb/s then A and B get x Mb/s, C gets (1-2x)Mb/s, otherwise A, B,
and C get 1/3 Mb/s",Medium,Standford Final 2007
78,Networking,Why is switched Ethernet considered superior to shared Ethernet,It isolates each station in its own collision domain allows different link speeds on segments and uses selective forwarding between segments which improves performance and reduces collisions,Medium,University of Calgary Final F2018 solution Q2
79,Networking,Which local area network technology Ethernet or Wi Fi has the higher bit error rate and why,Wi Fi has a higher bit error rate because it sends over a wireless air interface that is more susceptible to interference noise multipath fading and limits on radio frequency power,Medium,University of Calgary Final F2018 solution Q2
80,Networking,Which technology Ethernet or Wi Fi provides better support for mobile users and how,Wi Fi provides better mobility support because radio signals propagate in all directions mobile devices can roam and reassociate with access points and multiple access points can form an extended service set for campus wide coverage,Medium,University of Calgary Final F2018 solution Q2
81,Networking,Conceptually how does the Pure ALOHA medium access protocol work,Stations send whenever they have data without sensing the channel which gives very low access delay but many collisions and a maximum throughput of about one divided by two e or around eighteen percent,Medium,University of Calgary Final F2018 solution Q2
82,Networking,Is the link layer service model in IEEE 802.11 wireless LANs connectionless and unacknowledged,False wireless LANs use acknowledgements at the MAC layer to provide reliable delivery,Medium,University of Calgary Final F2021 solution Q8
83,Networking,Briefly describe how the Pure ALOHA MAC protocol works and where it was used,In Pure ALOHA a station with a frame simply transmits without sensing the channel if a collision happens it waits a random time and retries It was used in early packet radio networks and gives low delay at low load but has many collisions at high load with maximum throughput about 1 over 2e which is around eighteen percent,Medium,University of Calgary Final F2021 solution Q23a
84,Networking,Briefly describe how CSMA CA works and in what environment it is used,CSMA CA is a random access MAC protocol used in IEEE 802.11 wireless LANs A station with a frame listens to the channel and transmits only if idle if busy it defers and later retries after a random backoff Collisions cause further random backoff and methods such as the network allocation vector and optional RTS CTS help avoid collisions especially from hidden nodes,Medium,University of Calgary Final F2021 solution Q23b
85,Networking,Briefly describe the Token Ring MAC protocol and its key property,Token Ring is a turn taking protocol used in older IBM LANs where a single token circulates around a ring of stations A station that has a frame waits for the token seizes it sends its frame then releases the token The protocol is collision free,Medium,University of Calgary Final F2021 solution Q23c
86,Networking,Identify the individual IP networks in the diagram and give one interface address per network.,"Six distinct /24 subnets (e.g., 11.11.12.0/24 ... 11.11.16.0/24).",Medium,UMass CMPSCI453 Final 2002
87,Networking,Four autonomous systems W X Y and Z run BGP with each other to exchange reachability information about p a prefix in network X. X advertises p to Y and Z but not to W. Y advertises p to W and Z. Z advertises p to W but not to Y. For each of the following statements circle True or False. i W may be X transit service provider ii Y and Z must be in a peering relationship iii X and Z may be in a peering relationship iv Y must be X transit service provider,i False ii False iii True iv False,Medium,MIT 6.829 Quiz F2016 Solns
88,Networking,Same two hop path as above. The sender sends two packets back to back each 10 kbit. What queueing delay does the second packet experience at the router in milliseconds,Zero ms,Medium,Stanford CS144 Final Spring 2023 Ans
89,Networking,How does BGP prevent loops before best path selection,A route whose AS Path contains the local AS is ignored so only loop free routes enter best path selection,Medium,Book (Computer Networking Problems and Solutions.)
90,Networking,Which nodes run an intra-domain routing protocol? Which run an inter-domain protocol and what prefix is advertised?,"All run IGP; R4 runs BGP, advertises 11.11/16.",Medium,UMass CMPSCI453 Final 2002
91,Networking,A sender transmits over a two hop path through one router. Link 1 has rate r1 equals 1 Mbit per second length l1 equals two times ten to the five meters and propagation speed c1 equals two times ten to the eight meters per second. Link 2 has rate r2 equals 10 Mbit per second length l2 equals two times ten to the seven meters and propagation speed c2 equals two times ten to the eight meters per second. There is no other traffic and the router is store and forward. If the sender sends one packet of size 20 kbit what is the total end to end delay in milliseconds,123 ms,Medium,Stanford CS144 Final Spring 2023 Ans
92,Networking,"Datagram networks route each packet as a separate unit, independent of all others. Virtual-circuit networks do not have to do this, since each data packet follows a predetermined route. Does this observation mean that virtual-circuit networks do not need the capability to route isolated packets from an arbitrary source to an arbitrary destination?",Virtual circuit networks most certainly need this capability in order to route connection setup packets from an arbitrary source to an arbitrary destination,Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
93,Networking,"If costs are recorded as 8-bit numbers in a 50-router network, and distance vectors are exchanged twice a second, how much bandwidth per (full-duplex) line is chewed up by the distributed routing algorithm? Assume that each router has three lines to other
routers.","The routing table is 400 bits. Twice a second this table is written onto each
line, so 800 bps are needed on each line in each direction.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
94,Networking,"In the text it was stated that when a mobile host is not at home, packets sent to its
home LAN are intercepted by its home agent on that LAN. For an IP network on an
802.3 LAN, how does the home agent accomplish this interception?","Conceivably it might go into promiscuous mode, reading all frames dropped onto the LAN, but this is very inefficient. Instead, what is normally done is that the home agent tricks the router into thinking it is the mobile host by responding to ARP requests. When the router gets an IP packet destined for the mobile host, it broadcasts an ARP query asking for the 802.3 MAC-level address of the machine with that IP address. When the mobile host is not around, the home agent responds to the ARP, so the router associates the mobile user’s IP address with the home agent’s 802.3 MAC-level address.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
95,Networking,"As a possible congestion control mechanism in a network using virtual circuits internally, a router could refrain from acknowledging a received packet until (1) it knows its last transmission along the virtual circuit was received successfully and (2) it has a free buffer. For simplicity, assume that the routers use a stop-and-wait protocol and that each virtual circuit has one buffer dedicated to it for each direction of traffic. If it takes T sec to transmit a packet (data or acknowledgement) and there are n routers on the path, what is the rate at which packets are delivered to the destination host? Assume that transmission errors are rare and that the host-router connection is infinitely fast.","The protocol is terrible. Let time be slotted in units of T sec. In slot 1 the source router sends the first packet. At the start of slot 2, the second router has received the packet but cannot acknowledge it yet. At the start of slot 3, the third router has received the packet, but it cannot acknowledge it either, so all the routers behind it are still hanging. The first acknowledgement can only be sent when the destination host takes the packet from the destination router. Now the acknowledgement begins propagating back. It takes two full transits of the network, 2(n − 1)T sec, before the source router can send the second packet. Thus, the throughput is one packet every 2(n − 1)T sec.
",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
96,Networking,"A datagram network allows routers to drop packets whenever they need to. The probability of a router discarding a packet is p. Consider the case of a source host connected to the source router, which is connected to the destination router, and then to the destination host. If either of the routers discards a packet, the source host eventually times out and tries again. If both host-router and router-router lines are counted as hops, what is the mean number of
(a) hops a packet makes per transmission?
(b) transmissions a packet makes?
(c) hops required per received packet?","Each packet emitted by the source host makes either 1, 2, or 3 hops. The
probability that it makes one hop is p. The probability that it makes two hops
 is p(1 − p). The probability that it makes 3 hops is (1 − p)^2. The mean path
length a packet can expect to travel is then the weighted sum of these three
probabilities, or p^2 − 3p + 3. Notice that for p = 0 the mean is 3 hops and for
 p = 1 the mean is 1 hop. With 0 < p < 1, multiple transmissions may be
needed. The mean number of transmissions can be found by realizing that the
probability of a successful transmission all the way is (1 − p)^2, which we will call α. The expected number of transmissions is α + 2α(1 − α) + 3α(1 − α)^2 + ... = 1/α = 1/(1 − p)^2. Finally, the total hops used is (p^2 − 3p + 3)/(1 − p)^2.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
97,Networking,IP routers remove the link layer header and verify that the IP header checksum is correct before forwarding the packet. They then encapsulate the packet in a new link layer frame and send it along the next hop. Does this behavior violate the end to end principle Explain briefly why or why not,It does not violate the end to end principle. Routers must read and update the IP header in order to forward packets so for the header they are legitimate endpoints. The IP header checksum only protects simple forwarding information not application data. End to end checks at the hosts are still needed for correctness of the actual data,Medium,CS144 practice final answers question 4
98,Networking,In the Bellman Ford computation of lowest cost paths to router R1 after convergence what is the final shortest path from router R7 to R1 in terms of next hop and total cost.,Router R7 forwards to router R5 as next hop with total path cost 30.,Medium,Final_2007_soln Q22 part a
99,Networking,What is the key advantage of OSPF over RIP,OSPF supports hierarchical management of a very large autonomous system allowing better scalability than RIP,Medium,University of Calgary Final F2018 solution Q2
100,Networking,What is the data plane in the network layer and what does it do,The data plane is the lower level function in routers that forwards each datagram from an input port to the correct output port using the forwarding table It operates in hardware at link speed on the order of microseconds,Medium,University of Calgary Final F2018 solution Q2
101,Networking,What is the control plane in the network layer and what does it do,The control plane runs higher level routing logic that computes paths and constructs the forwarding tables using routing algorithms in router software or an SDN controller It operates on longer time scales such as minutes or hours,Medium,University of Calgary Final F2018 solution Q2
102,Networking,Briefly define data plane and control plane and give one key difference,Data plane performs packet forwarding in simple fast hardware lookups on the order of nano seconds to micro seconds Control plane runs routing logic in software to choose end to end paths on time scales of seconds to minutes,Medium,University of Calgary Final F2021 solution Q19a
103,Networking,What is the difference between an IPv4 address and a MAC address,An IPv4 address is a thirty two bit network layer address written in dotted decimal with network and host parts that can be set by software A MAC address is a forty eight bit data link layer address written in hexadecimal that is intended to be globally unique and is usually set in hardware,Medium,University of Calgary Final F2021 solution Q19b
104,Networking,Briefly contrast destination based forwarding with generalized forwarding,Destination based forwarding is the traditional Internet approach where routers look only at the destination IP address and forward on a chosen link Generalized forwarding as in SDN can match on many header fields and apply a variety of actions not just simple forwarding,Medium,University of Calgary Final F2021 solution Q19d
105,Networking,With the forwarding table given in the exam over which outgoing link should a router send a datagram destined to 63.19.5.3 when using longest prefix match,The datagram should be sent on outgoing link 3 because prefix 63.19.5.0 slash 28 is the most specific match,Medium,University of Calgary Final F2021 solution Q21 A
106,Networking,In the same forwarding table problem which outgoing link is used for destination 171.15.15.0,Outgoing link 4 using prefix 171.0.0.0 slash 10 as the best match,Medium,University of Calgary Final F2021 solution Q21 B
107,Networking,Give two key differences between RIP and OSPF as described in the solution,RIP is an intra AS distance vector protocol that uses hop count in small flat autonomous systems and runs over UDP OSPF is an intra AS link state protocol that uses link weights in large hierarchical autonomous systems can compute multiple best paths and runs directly over IP,Medium,University of Calgary Final F2021 solution Q22
108,Networking,Wireless TCP: Does vanilla TCP meet goals of retransmitting bit-error losses without reducing rate and reducing rate only on congestion?,"No, it reduces rate on non-congestion loss.",Medium,UMass CMPSCI453 Final 2002
109,Networking,Wireless TCP: What modification helps meet those goals?,Add explicit NAKs to distinguish error vs loss.,Medium,UMass CMPSCI453 Final 2002
110,Networking,Wireless TCP: Does vanilla TCP meet goals of retransmitting bit-error losses without reducing rate and reducing rate only on congestion?,"No, it reduces rate on non-congestion loss.",Medium,UMass CMPSCI453 Final 2002
111,Networking,Wireless TCP: What modification helps meet those goals?,Add explicit NAKs to distinguish error vs loss.,Medium,UMass CMPSCI453 Final 2002
112,Networking,How do Tahoe and Reno react on fast retransmit,Tahoe sets sst to half sets cwnd to initial and slow starts Reno sets sst and cwnd to half and stays in avoidance,Medium,Book (Computer Networking Problems and Solutions.)
113,Networking,"Stop-and-Wait vs Sliding-Window: Given RTT = 100 ms, bottleneck = 30 Mb/s, MSS = 1500 B. What percent of max throughput does stop-and-wait achieve",0.12 Mb/s ÷ 30 Mb/s = 0.4 percent,Medium,Stanford CS144 Midterm Fall 2020
114,Networking,"Consider the following plot of TCP window size as a function of time. Assuming TCP Reno is the protocol experiencing the behavior shown above, answer the following questions. (a) Identify the intervals of time when TCP slow start is operating.","1–6, 23–26.",Medium,CMU 15-441 HW3 (Solns)
115,Networking,Suppose each response or request can be fit into one packet. Which of the following techniques is likely to reduce the likelihood of a congestion collapse? (Circle ALL that apply) Increase the size of the queue in each router from 4 packets to 8 packets. Suppose the timeout value is appropriately adjusted accordingly to the queue length.,Solution: nuanced discussion as in key.,Medium,CMU 15-441 HW3 (Solns)
116,Networking,"D Pick the true choices about congestion collapse and backoff Otto Pilot creates a new network for the 150 PC computers he mounted within his car. Each computer sends indepenent UDP query response packets to the other computers in the car when it needs to know or do something. Requests are retried after a time out that is a fixed, small multiple of the typial response time. After running the OttoNet for a few days, Otto notices that network congestion occasionally causes a congestion collapse because too many packets are sent into the network, only to be dropped before reaching the eventual destination. These packets consume valuable resources. Suppose each response or request can be fit into one packet. Which of the following techniques is likely to reduce the likelihood of a congestion collapse Circle ALL that apply D. Use a TCP style flow control window per session at each receiver to prevent buffer overruns.",NO.,Medium,CMU 15-441 HW3 Solns
117,Networking,TCP Cubic increases window based on elapsed real time rather than per ACK steps. Why adopt a real time increase rule Statement ? Evaluate as True or False .This reduces the throughput bias against long RTT connections compared to Reno.,True,Medium,MIT 6.829 Quiz F2016
118,Networking,"Primitives of transport service assume asymmetry between the two end points during connection establishment, one end (server) executes LISTEN while the other end (client) executes CONNECT. However, in peer to peer applications such file sharing systems, e.g. BitTorrent, all end points are peers. There is no server or client functionality. How can transport service primitives may be used to build such peer to peer applications?","Since the two end points are peers, a separate application-level mechanism is
needed that informs the end points at run time about which end will act as
server and which end will act as client, as well as their addresses. One way to
do this is to have a separate coordinator process that provides this information
to the end points before a connection between the end points is established.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
119,Networking,"Imagine that a two-way handshake rather than a three-way handshake were used to set
up connections. In other words, the third message was not required. Are deadlocks
now possible? Give an example or show that none exist.","Deadlocks are possible. For example, a packet arrives at A out of the blue, and A acknowledges it. The acknowledgement gets lost, but A is now open while B knows nothing at all about what has happened. Now the same thing happens to B, and both are open, but expecting different sequence numbers. Timeouts have to be introduced to avoid the deadlocks.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
120,Networking,"Consider a simple application-level protocol built on top of UDP that allows a client to
retrieve a file from a remote server residing at a well-known address. The client first
sends a request with a file name, and the server responds with a sequence of data
packets containing different parts of the requested file. To ensure reliability and
sequenced delivery, client and server use a stop-and-wait protocol. Ignoring the obvious
performance issue, do you see a problem with this protocol? Think carefully
about the possibility of processes crashing.","It is possible that a client may get the wrong file. Suppose client A sends a
request for file f1 and then crashes. Another client B then uses the same protocol
to request another file f2. Suppose client B, running on the same
machine as A (with the same IP address), binds its UDP socket to the same
port that A was using earlier. Furthermore, suppose B’s request is lost. When
the server’s reply (to A’s request) arrives, client B will receive it and assume
that it is a reply its own request.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
121,Networking,"A client sends a 128-byte request to a server located 100 km away over a 1-gigabit
optical fiber. What is the efficiency of the line during the remote procedure call?","Sending 1000 bits over a 1 Gbps line takes 1 μsec. The speed of light in fiber
optics is 200 km/msec, so it takes 0.5 msec for the request to arrive and
another 0.5 msec for the reply to get back. In all, 1000 bits have been
transmitted in 1 msec. This is equivalent to 1 megabit/sec, or 1/10 of 1%
efficiency.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
122,Networking,"What is the total size of the minimum TCP MTU, including TCP and IP overhead but
not including data link layer overhead?","The default segment is 536 bytes. TCP adds 20 bytes and so does IP, making
the default 576 bytes in total.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
123,Networking,"Would it be possible to place the RTP code in the operating system kernel, along with
the UDP code? Explain your answer.","Sure. The caller would have to provide all the needed information, but there
is no reason RTP could not be in the kernel, just as UDP is.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
124,Networking,"A process on host 1 has been assigned port p, and a process on host 2 has been
assigned port q. Is it possible for there to be two or more TCP connections between
these two ports at the same time?","No. A connection is identified only by its sockets. Thus, (1, p) – (2, q) is the
only possible connection between those two ports.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
125,Networking,"The maximum payload of a TCP segment is 65,495 bytes. Why was such a strange
number chosen?","The entire TCP segment must fit in the 65,515-byte payload field of an IP
packet. Since the TCP header is a minimum of 20 bytes, only 65,495 bytes
are left for TCP data.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
126,Networking,"For a single TCP flow that uses additive increase and multiplicative decrease with loss as the only congestion signal and a buffer that is large enough, does the AIMD congestion window sawtooth have a fixed or variable period in time between loss events Explain briefly",The sawtooth has a fixed period in this setting. The height of the sawtooth is determined by how long it takes to fill the buffer. After each loss the window is cut and then grows by one packet per round trip until the buffer again fills and another loss occurs. The number of rounds needed is the same each time so the time between losses is effectively fixed,Medium,CS144 practice final answers question 5
127,Networking,When you plot the AIMD behavior of a single TCP flow as congestion window size versus time is the additive increase line that forms the hypotenuse of the sawtooth straight or curved Explain why,The hypotenuse is curved not straight. Each time the congestion window increases by one packet the round trip time also increases because more packets are in the queue. As the window grows the time between increases gets longer so the line bends rather than remaining a straight line,Medium,CS144 practice final answers question 6
128,Networking,Now suppose many TCP flows between different sender receiver pairs share the same bottleneck and are not synchronized. Will the AIMD sawtooth for each sender still have a fixed period in time between loss events Explain briefly,The period is no longer fixed. Many flows contribute to the occupancy of the buffer. Whether a particular flow experiences a loss depends on how full the buffer is when its packets arrive which is influenced by all other flows. Because that state varies unpredictably the time between loss events for one flow is not constant,Medium,CS144 practice final answers question 8
129,Networking,A middle box B splits a TCP path into two connections. You are asked about the connection from B to C. The route from A to B drops ten percent of packets and the route from B to C also drops ten percent. What is the steady state throughput from B to C compared with the earlier calculation for the A to B connection,The throughput from B to C is the same as the throughput from A to B computed previously. The B to C leg has the same round trip time and the same packet loss probability so the standard TCP throughput approximation gives the same value,Medium,CS144 practice final answers question 16
130,Networking,Three users A B and C share a 1 Mb per second link. Users A and B are each limited by an access link of x Mb per second and user C is greedy. What is the max min fair allocation when x is less than one third Mb per second and when x is at least one third Mb per second.,If x is less than one third Mb per second then A gets x Mb per second B gets x Mb per second and C gets 1 − 2x Mb per second. Otherwise A B and C each get one third Mb per second.,Medium,Final_2007_soln Q19
131,Networking,Flow C generates at most 1000 packets in any 10 second interval. Can this traffic be modeled as leaky bucket traffic and if so what parameters sigma and rho correspond to this constraint.,Yes. It can be modeled with sigma equal to 1000 packets and rho equal to 100 packets per second.,Medium,Final_2007_soln Q23 part c
132,Networking,In weighted fair queuing suppose packet p of flow A is scheduled to leave before packet q of flow B. Can future arriving packets change the departure order of p and q.,No. Once packets are scheduled they are ordered by increasing finishing time and they depart in that order so the departure order of p and q is fixed.,Medium,Final_2007_soln Q23 part d
133,Networking,Why is it customary to assume in theory that a burst can leave a leaky bucket regulator at infinite rate even though the real link rate R is finite.,Because in practice the link rate R is usually much greater than the average rate so using an infinite burst rate approximation changes the result very little.,Medium,Final_2007_soln Q24 part c
134,Networking,Give an example of how TCP performance could be improved using cached state information,A TCP sender could remember an estimated congestion window for a recent destination so that a later connection to the same host can resume with a large window instead of repeating slow start which reduces start up delay,Medium,University of Calgary Final F2018 solution Q2
135,Networking,"Right before the final, a secure transfer scenario is described: Dave must receive the exam securely from Srini over a channel where attackers can intercept modify packets. Dave and Srini already possess uncompromised public private keys for each other. For each of the following methods, can the exam be stolen or replaced Explain briefly: (a) plaintext (b) signed by Srini’s private key (c) encrypted with Dave’s public key (d) encrypt with Dave’s public key and sign with Srini’s private key (e) sign and encrypt with a shared secret key (f) use Diffie–Hellman to negotiate a session key then encrypt the exam.",(a) stolen yes replaced yes (b) stolen yes replaced no (c) stolen no replaced yes (d) stolen no replaced no (e) if key already secret stolen no replaced no (f) without authentication stolen maybe replaced yes via MitM.,Medium,CMU 15-441 Final Spring 2005 
136,Networking,"Consider a situation in which a cyberterrorist makes all the DNS servers in the world
crash simultaneously. How does this change one’s ability to use the Internet?","The DNS servers provide a mapping between domain names and IP addresses,
such that when a request for a Web page is received, the browser can
look up in the DNS server the IP address corresponding to the domain name
of the requested page, and then download the requested page from that IP address.
If all the DNS servers in the world were to crash at the same time, one would
not be able to map between domain names and IP addresses. Therefore, the
only way to access Web pages would be by using the IP address of the host
server instead of the domain name. Since most of us do not know the IP addresses
of the servers we access, this type of situation would make use of the
Internet extremely inefficient, if not virtually impossible for most users.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
137,Networking,"DNS uses UDP instead of TCP. If a DNS packet is lost, there is no automatic recovery.
Does this cause a problem, and if so, how is it solved?","DNS is idempotent. Operations can be repeated without harm. When a process
makes a DNS request, it starts a timer. If the timer expires, it just makes
the request again. No harm is done.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
138,Networking,"John wants to have an original domain name and uses a randomized program to generate
a secondary domain name for him. He wants to register this domain name in the
com generic domain. The domain name that was generated is 253 characters long.
Will the com registrar allow this domain name to be registered?","The generated name would probably be unique, and should therefore be allowed.
However, DNS names must be shorter than 256 bytes, as required by
the standard. Since together with the com ending the generated name would
be longer than 256 characters, it is not permissible.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
139,Networking,"Some email systems support a Content Return: header field. It specifies whether the
body of a message is to be returned in the event of nondelivery. Does this field belong
to the envelope or to the header?","It belongs to the envelope because the delivery system needs to know its
value to handle email that cannot be delivered.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
140,Networking,"Is it possible that when a user clicks on a link with Firefox, a particular helper is started,
but clicking on the same link in Internet Explorer causes a completely different
helper to be started, even though the MIME type returned in both cases is identical?
Explain your answer.","Yes, it is possible. Which helper is started depends on the configuration
tables inside the browser, and Firefox and IE may have been configured differently.
Furthermore, IE takes the file extension more seriously than the
MIME type, and the file extension may indicate a different helper than the
MIME type.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
141,Networking,"Sloth Bank wants to make online banking easy for its lazy customers, so after a customer signs up and is authenticated by a password, the bank returns a cookie containing a customer ID number. In this way, the customer does not have to identify himself or type a password on future visits to the online bank. What do you think of this idea? Will it work? Is it a good idea?","Technically, it will work, but it is a terrible idea. All the customer has to do
is modify the cookie to get access to someone else’s bank account. Having
the cookie provide the customer’s ID number is safe, but the customer should
be required to enter a password to prove his identity.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
142,Networking,"For each of the following applications, tell whether it would be (1) possible and (2)
better to use a PHP script or JavaScript, and why:
(a) Displaying a calendar for any requested month since September 1752.
(b) Displaying the schedule of flights from Amsterdam to New York.
(c) Graphing a polynomial from user-supplied coefficients.","(a) There are only 14 annual calendars, depending on the day of the week on
which 1 January falls and whether the year is a leap year. Thus, a JavaScript
program could easily contain all 14 calendars and a small database of which
year gets which calendar. A PHP script could also be used, but it would be
slower.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
143,Networking,"An HTML page is as follows:
<html> <body>
<a href=""www.info-source.com/welcome.html""> Click here for info </a>
</body> </html>
If the user clicks on the hyperlink, a TCP connection is opened and a series of lines is
sent to the server. List all the lines sent.","The commands sent are as follows:
GET /welcome.html HTTP/1.1
Host: www.info-source.com
Note the blank line at the end. It is mandatory.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
144,Networking,Conceptually what does DNS do and what does ARP do,DNS is an application layer protocol that maps host names to IP addresses typically over UDP ARP is a low layer protocol that maps IP addresses to link layer MAC addresses using link layer frames on the local network,Medium,University of Calgary Final F2018 solution Q2
145,Networking,How does DNS use caching to improve performance,DNS resolvers keep a cache of recent mappings from domain names to IP addresses so repeated lookups can be answered locally without contacting authority servers entries remain for a configurable time to live typically hours or days,Medium,University of Calgary Final F2018 solution Q2
146,Networking,In the home networking question what is one example of how NAT and a middle box firewall improve a home network,NAT lets multiple in home devices share one public IP address while the middle box can act as a firewall that blocks unwanted inbound traffic from the Internet which improves security for the internal home network,Medium,University of Calgary Final F2021 solution Q24 example 3
147,Networking,Each spoofed email fits in a single 1500 byte packet. Host C sends guesses over a 1 Gb per second link and already knows 12 bits of the TCP sequence number. How long does it take on average to send one spoofed email that succeeds.,Approximately 6.3 seconds.,Medium,Final_2007_soln Q20 follow up
148,Networking,What simple change can be added to the SMTP protocol to defend against this TCP sequence number spoofing attack on email.,Add an application layer challenge response and wait for a correct answer before accepting the message.,Medium,Final_2007_soln Q20 part b
149,Networking,In the spoofing variant where a low bandwidth host forwards acknowledgements from the victim back to a high bandwidth host the low bandwidth host has a 56 Kb per second link and each TCP acknowledgement is 64 bytes. Approximately how many spoofed email messages per second can the high bandwidth host send.,The attack is limited by the acknowledgements on the 56 Kb per second link so the high bandwidth server can send about 109 messages per second.,Medium,Final_2007_soln Q20 part c
150,Networking,Does the SMTP challenge response fix from the earlier spoofing question also prevent the variant that uses a low bandwidth forwarder and a high bandwidth sender. Explain briefly.,No. The attacker still receives the acknowledgements forwarded by the low bandwidth host so any defense that assumes the attacker cannot see the SYN and ACK does not work here.,Medium,Final_2007_soln Q20 part d
151,Networking,"Alice and Bob use RSA public key encryption in order to communicate between them.
Trudy finds out that Alice and Bob shared one of the primes used to determine the
number n of their public key pairs. In other words, Trudy found out that na = pa × q
and nb = pb × q. How can Trudy use this information to break Alice’s code?","Trudy can look up Alice’s and Bob’s public key pairs, and retrieve na and nb.
Because of the properties of the RSA algorithm, Trudy knows that each of
these numbers is a multiplication of two primes, and therefore has only two
prime factors. As stated in the question, Trudy also knows that one of the
prime factors is common to na and nb. Thus, Trudy concludes that the
Greatest Common Divisor (GCD) of na and nb is the common prime factor, q.
All Trudy needs to do in order to break Alice’s code is to use the Euclidean
algorithm to find the GCD of na and nb to obtain q, and then divide na by the
result, q, to obtain pa. Trudy can look up ea in Alice’s public key pair, and can then find a solution to the equation da × ea = 1 mod (p −1) (q −1), thereby
determining Alice’s private key.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
152,Networking,"A math class has 25 students. Assuming that all of the students were born in the first
half of the year—between January 1st and June 30th— what is the probability that at
least two students have the same birthday? Assume that nobody was born on leap day,
so there are 181 possible birthdays.","With 20 students, there are (25 × 24)/2 = 300 pairs of students. The probability
that the students in any pair have the same birthday is 1/181, and the
probability that they have different birthdays is 180/181. The probability that
all 300 pairs have different birthdays is thus (180/181)^300. This number is
about 0.190. If the probability that all pairs are mismatches is 0.190, then the
probability that one or more pairs have the same birthday is about 0.810.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
153,Networking,"Consider the failed attempt of Alice to get Bob’s public key in Fig. 8-23. Suppose that
Bob and Alice already share a secret key, but Alice still wants Bob’s public key. Is
there now a way to get it securely? If so, how?","It is doable. Alice encrypts a nonce with the shared key and sends it to Bob.
Bob sends back a message encrypted with the shared key containing the
nonce, his own nonce, and the public key. Trudy cannot forge this message,
and if she sends random junk, when decrypted it will not contain Alice’s
nonce. To complete the protocol, Alice sends back Bob’s nonce encrypted
with Bob’s public key.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
154,Networking,"Alice wants to communicate with Bob, using public-key cryptography. She establishes
a connection to someone she hopes is Bob. She asks him for his public key and
he sends it to her in plaintext along with an X.509 certificate signed by the root CA.
Alice already has the public key of the root CA. What steps does Alice carry out to
verify that she is talking to Bob? Assume that Bob does not care who he is talking to
(e.g., Bob is some kind of public service).","Step 1 is to verify the X.509 certificate using the root CA’s public key. If it is
genuine, she now has Bob’s public key, although she should check the CRL if
there is one. But to see if it is Bob on the other end of the connection, she
needs to know if Bob has the corresponding private key. She picks a nonce
and sends it to him with his public key. If Bob can send it back in plaintext, she is convinced that it is Bob.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
155,Networking,"Suppose that a system uses PKI based on a tree-structured hierarchy of CAs. Alice
wants to communicate with Bob, and receives a certificate from Bob signed by a CA
X after establishing a communication channel with Bob. Suppose Alice has never
heard of X. What steps does Alice take to verify that she is talking to Bob?","First Alice establishes a communication channel with X and asks X for a certificate
to verify his public key. Suppose X provides a certificate signed by
another CA Y. If Alice does not know Y, she repeats the above step with Y.
Alice continues to do this, until she receives a certificate verifying the public
key of a CA Z signed by A and Alice knows A’s public key. Note that this
may continue until a root is reached, that is, A is the root. After this Alice
verifies the public keys in reverse order starting from the certificate that Z
provided. In each step during verification, she also checks the CRL to make
sure that the certificate provided have not been revoked. Finally, after verifying
Bob’s public key, Alice ensures that she is indeed to talking to Bob using
the same method as in the previous problem.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
156,Networking,"Can IPsec using AH be used in transport mode if one of the machines is behind a NAT
box? Explain your answer.","No. AH in transport mode includes the IP header in the checksum. The NAT
box changes the source address, ruining the checksum. All packets will be
perceived as having errors.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
157,Networking,"Suppose an organization uses VPN to securely connect its sites over the Internet. Jim,
a user in the organization, uses the VPN to communicate with his boss, Mary. Describe
one type of communication between Jim and Mary which would not require use
of encryption or other security mechanism, and another type of communication which
would require encryption or other security mechanisms. Explain your answer.","The VPN provides security for communication over the Internet, but not within
the organization. Therefore, when communicating with Mary regarding
R&D purchases, or any other communication which need only be secure from
people outside the organization, Jim does not need to use additional encryption
or security measures. However, if Jim wants his communication
with Mary to be secure also with respect to people inside the organization,
such as when communicating with Mary about his salary and the raise he had
been promised, additional security measures should be used.",Medium,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
158,Networking,"AES COMBO: which initialization vectors IVs generation methods make the scheme indistinguishability under chosen plaintext attack IND CPA secure select all that apply Options A. IV1 and IV2 are independently randomly generated B Seed a pseudorandom number generator PRNG with key K, set IV1 equals Generate 128 and then set IV2 equals Generate 128 using the same PRNG instance C. Seed two separate PRNGs with key K, set IV1 equals Generate 128 from the first PRNG and then set IV2 equals Generate 128 from the second PRNG  D. IV1 is randomly generated and IV2 equals H left parenthesis IV1 right parenthesis  E. IV2 is randomly generated and IV1 equals H left parenthesis IV2 right parenthesis F None of the above",A D E,Medium,Berkeley CS161 Spring 2025 Midterm Q5.2
159,Networking,"Confidential, authenticated, integrity-checked file from Alice to Bob with efficiency goals: what does Alice do?",Encrypt with shared key; send encrypted file and encrypted hash.,Medium,UMass CMPSCI453 Final 2002
160,Networking,Same scenario: what does Bob do to verify?,"Decrypt both, compare hashes; trust via shared key.",Medium,UMass CMPSCI453 Final 2002
161,Networking,What TLS component provides sender authentication separate from encryption,The TLS record includes a MAC to validate the sender which prevents a relay that would pass if you relied on encryption only,Medium,UMass CMPSCI453 Final 2002
162,Networking,In the proposed traffic light free intersection system what cybersecurity challenge is mentioned and why is it important,A major challenge is that attackers could hack or jam the wireless control system and create traffic chaos so strong cybersecurity measures standards and regulation would be needed to protect safety,Medium,University of Calgary Final F2018 solution Q2
163,Networking,In the Internet and society question give one way the Internet was harmful during the COVID nineteen pandemic,The Internet enabled rapid spread of misinformation such as fake news about vaccines and health measures which undermined public trust and complicated the public health response,Medium,University of Calgary Final F2021 solution Q25b
164,Networking,"Consider an error-free 64-kbps satellite channel used to send 512-byte data frames in
one direction, with very short acknowledgements coming back the other way. What is
the maximum throughput for window sizes of 1, 7, 15, and 127? The earth-satellite
propagation time is 270 msec.","The transmission starts at t = 0. At t = 4096/64000 sec = 64 msec, the last bit is sent. At t = 334 msec, the last bit arrives at the satellite and the very short ACK is sent. At t = 604 msec, the ACK arrives at the earth. The data rate here is 4096 bits in 604 msec, or about 6781 bps. With a window size of 7 frames, transmission time is 448 msec for the full window, at which time the sender has to stop. At 604 msec, the first ACK arrives and the cycle can start again. Here we have 7 × 4096 = 28,672 bits in 604 msec. The data rate is 47,470.2 bps. Continuous transmission can only occur if the transmitter is still sending when the first ACK gets back at t = 604 msec. In other words, if the window size is greater than 604 msec worth of transmission, it can run at full speed. For a window size of 10 or greater this condition is met, so for any window size of 10 or greater (e.g., 15 or 127) the data rate is 64 kbps.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
165,Networking,"In protocol 6, MAX SEQ = 2n − 1. While this condition is obviously desirable to make efficient use of header bits, we have not demonstrated that it is essential. Does the protocol work correctly for MAX SEQ = 4, for example?","No. This implementation fails. With MaxSeq = 4, we get NrBufs = 2. The
even sequence numbers use buffer 0 and the odd ones use buffer 1. This
mapping means that frames 4 and 0 both use the same buffer. Suppose that
frames 0–3 are received and acknowledged. The receiver’s window now contains
4 and 0. If 4 is lost and 0 arrives, it will be put in buffer 0 and
arrived [0] will be set to true. The loop in the code for FrameArrival will be
executed once, and an out-of-order message will be delivered to the host.
This protocol requires MaxSeq to be odd to work properly. However, other
implementations of sliding window protocols do not all have this property.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
166,Networking,"One way of detecting errors is to transmit data as a block of n rows of k bits per row
and add parity bits to each row and each column. The bitin the lower-right corner is a
parity bit that checks its row and its column. Will this scheme detect all single errors?
Double errors? Triple errors? Show that this scheme cannot detect some four-bit errors","A single error will cause both the horizontal and vertical parity checks to be
wrong. Two errors will also be easily detected. If they are in different rows,
the row parity will catch them. If they are in the same row, the column parity
will catch them. Three errors will also be detected. If they are in the same
row or column, that row’s or column’s parity will catch them. If two errors
are in the same row, the column parity of at least one of them will catch the
error. If two errors are in the same column, the row parity of at least one of
them will catch the error. A 4-bit error in which the four error bits lie on the
four corners of a rectangle cannot be caught.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
167,Networking,"A 1024-bit message is sent that contains 992 data bits and 32 CRC bits. CRC is computed
using the IEEE 802 standardized, 32-degree CRC polynomial. For each of the
following, explain whether the errors during message transmission will be detected by
the receiver:
(a) There was a single-bit error.
(b) There were two isolated bit errors.
(c) There were 18 isolated bit errors.
(d) There were 47 isolated bit errors.
(e) There was a 24-bit long burst error.
(f) There was a 35-bit long burst error.","The CRC checksum polynomial is or degree 32, so (a) Yes. CRC catches all
single-bit errors.
(b) Yes. CRC catches all double-bit errors for any reasonably long message.
(c) No. CRC may not be able catch all even number of isolated bit errors.
(d) Yes. CRC catches all odd number of isolated bit errors.
(e) Yes. CRC catches all burst errors with burst lengths less than or equal to
32.
(f) No. CRC may not be able to catch a burst error with burst length greater
than 32.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
168,Networking,"A wireless LAN with one AP has 10 client stations. Four stations have data rates of 6
Mbps, four stations have data rates of 18 Mbps, and the last two stations have data
rates of 54 Mbps. What is the data rate experienced by each station when all ten stations
are sending data together, and
(a) TXOP is not used?
(b) TXOP is used?","(a) Each set of ten frames will include one frame from each station. So, all
stations will experience a data rate of 54/50 Mbps = 1.08 Mbps. (b) Each
station gets the same amount of time to transmit. So, the 6 Mbps stations will
get 0.6 Mbps, 18 Mbps stations will get 1.8 Mbps, and 54 Mbps stations will
get 5.4 Mbps.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
169,Networking,"Give a simple heuristic for finding two paths through a network from a given source to
a given destination that can survive the loss of any communication line (assuming two
such paths exist). The routers are considered reliable enough, so it is not necessary to
worry about the possibility of router crashes.","Pick a route using the shortest path. Now remove all the arcs used in the path
just found, and run the shortest path algorithm again. The second path will be
able to survive the failure of any line in the first path, and vice versa. It is
conceivable, though, that this heuristic may fail even though two line-disjoint
paths exist. To solve it correctly, a max-flow algorithm should be used.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
170,Networking,"For hierarchical routing with 4800 routers, what region and cluster sizes should be
chosen to minimize the size of the routing table for a three-layer hierarchy? A good
starting place is the hypothesis that a solution with k clusters of k regions of k routers
is close to optimal, which means that k is about the cube root of 4800 (around 16).
Use trial and error to check out combinations where all three parameters are in the
general vicinity of 16.","The minimum occurs at 15 clusters, each with 16 regions, each region having
20 routers, or one of the equivalent forms, e.g., 20 clusters of 16 regions of 15
routers. In all cases the table size is 15 + 16 + 20 = 51.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
171,Networking,"Compute a multicast spanning tree for router C in the following network for a group
with members at routers A, B, C, D, E, F, I, and K.",Multiple spanning trees are possible. One of them is: ,Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
172,Networking,"Suppose that host A is connected to a router R 1, R 1 is connected to another router,
R 2, and R 2 is connected to host B. Suppose that a TCP message that contains 900
bytes of data and 20 bytes of TCP header is passed to the IP code at host A for delivery
to B. Show the Total length, Identification, DF, MF, and Fragment offset fields of
the IP header in each packet transmitted over the three links. Assume that link A-R1
can support a maximum frame size of 1024 bytes including a 14-byte frame header,
link R1-R2 can support a maximum frame size of 512 bytes, including an 8-byte frame
header, and link R2-B can support a maximum frame size of 512 bytes including a
12-byte frame header.","The initial IP datagram will be fragmented into two IP datagrams at I1. No other fragmentation will occur.
Link A-R1:
Length = 940; ID = x; DF = 0; MF = 0; Offset = 0
Link R1-R2:
(1) Length = 500; ID = x; DF = 0; MF = 1; Offset = 0
(2) Length = 460; ID = x; DF = 0; MF = 0; Offset = 60
Link R2-B:
(1) Length = 500; ID = x; DF = 0; MF = 1; Offset = 0
(2) Length = 460; ID = x; DF = 0; MF = 0; Offset = 60",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
173,Networking,You plug a new laptop with Ethernet address 00:11:22:33:44:55 into a wired Ethernet jack. The local DHCP server is at IP address 171.64.7.77. The default gateway is 171.64.7.1 with Ethernet address 00:66:77:88:99:00. Your laptop must send an IP datagram to 128.30.2.1. Briefly list the protocol exchanges that occur on the local Ethernet before your laptop can send that datagram,The laptop broadcasts a DHCP discover from 00:11:22:33:44:55. The server at 171.64.7.77 replies with a DHCP offer proposing address 171.64.7.22. The laptop broadcasts a DHCP request for 171.64.7.22 and then receives a DHCP acknowledgment confirming that address. Next the laptop broadcasts an ARP request for 171.64.7.1. The router replies with its Ethernet address 00:66:77:88:99:00. Only after this can the laptop send the IP datagram to 128.30.2.1 inside an Ethernet frame addressed to 00:66:77:88:99:00,Hard,CS144 practice final answers question 13
174,Networking,"Using Figure 1, for which pair of routers is the shortest path between them the longest Give the pair.","A, G",Hard,Stanford CS144 Midterm Fall 2021
175,Networking,After the minimum cost routing tree is formed the link between R4 and R6 fails. Under split horizon with poison reverse what is the final lowest cost path from router R8 to R1 in terms of next hop and cost.,Router R8 forwards to router R7 as next hop with total path cost 34.,Hard,Final_2007_soln Q22 part b
176,Networking,In the simplified AIMD analysis of TCP what fraction of the maximum window W hat is the average window size and how many round trip times between loss events are needed to sustain an average window of w_a packets.,The average window size is (3 over 4) W hat. To sustain an average window of w_a packets the time between loss events must be (2 over 3) w_a round trip times.,Hard,Final_2007_soln Q21 parts a and b
177,Networking,To achieve a sustained rate of 10 Gb per second over a path with round trip time 200 milliseconds using 1500 byte packets what average TCP window size in packets is required.,An average window of about 166667 packets is required.,Hard,Final_2007_soln Q21 part c
178,Networking,Using the simplified TCP model what packet loss probability is required to sustain the window size needed for 10 Gb per second over a 200 millisecond round trip time.,The required loss probability is approximately 5.4 × 10^−11 that is 5.4 multiplied by ten raised to the power minus eleven.,Hard,Final_2007_soln Q21 part c
179,Networking,Alice TCP uses multiplicative increase multiplicative decrease. When acknowledgements arrive the window increases by an additive constant a and when there is a loss the window is multiplied by 1 − b where b is less than 1. If the window oscillates between (1 − b) W hat and W hat what is the average window size in terms of W hat and b.,The average window size is ((2 − b) over 2) W hat.,Hard,Final_2007_soln Q21 part d
180,Networking,Consider a network with two long running TCP Reno flows sharing a single bottleneck router that runs the PIE queue management algorithm. Each flow increases its congestion window by 1 cwnd on each ACK and reduces by one half on a packet drop. The bottleneck link capacity is C equals 1500 packets per second and the minimum RTT in the absence of queueing for the two flows are 10 ms and 30 ms. The target queueing delay for PIE is set to 10 ms which it achieves on average. The bottleneck link is fully utilized. You may use the fact that TCP throughput depends on the packet loss rate and RTT with constant of proportionality equal to square root of 3 over 2. What is the average packet drop probability in this network You may express your answer as a fraction,3/800,Hard,MIT 6.829 Quiz F2016 Solns
181,Networking,"Harry Bovik is given the responsibility of configuring the packet queuing component of a new router. The link speed of the router is 100 Mbit/s and he expects the average Internet round-trip time of connections through the router to be 80 ms. Harry realizes that he needs to size the buffers appropriately. Assume the following for the rest of this problem: • There is exactly one TCP flow traversing this router • The flow is long-running and uses AIMD congestion control • The advertised window is large enough that it does not limit the flow • Losses are perfectly recovered • Ignore all header overheads Harry’s argument: “Because the average RTT is 80 ms, the average one-way delay is 40 ms. Therefore, the amount of buffering he needs for high link utilization is 100 Mbit/s × 40 ms or 500 KBytes.” Approximately what bandwidth will TCP achieve with this buffering",≈ 96.45 Mbit/sec exact and ≈ 95.8 Mbit/sec simplified.,Hard,CMU 15-441 HW3 (Solns)
182,Networking,"Assume that the switch is store and forward, and assume that there is no other traffic in the network the router’s buffer is always empty. In this case, what is the total, one way delay for a packet of size p traveling from node 1 to node 2 (see Figure)",(p/r_1 + p/r_2 + l_1/c_1 + l_2/c_2).,Hard,Stanford CS144 Midterm Fall 2021 
183,Networking,"What is the time between when the sender sends a packet, and when it can receive an acknowledgement for the data in that packet, when there is no queuing This is called the minimum round trip time MinRTT see Figure A",Accepted either (2(l_1/c_1 + l_2/c_2) + p/r_1 + p/r_2) or (2(l_1/c_1 + l_2/c_2 + p/r_1 + p/r_2)).,Hard,Stanford CS144 Midterm Fall 2021 
184,Networking,"Suppose that the clock-driven scheme for generating initial sequence numbers is used
with a 15-bit wide clock counter. The clock ticks once every 100 msec, and the maximum
packet lifetime is 60 sec. How often need resynchronization take place
(a) in the worst case?
(b) when the data consumes 240 sequence numbers/min?","(a) The clock takes 32768 ticks, i.e., 3276.8 sec to cycle around. At zero generation
rate, the sender would enter the forbidden zone at 3276.8 − 60 =
3216.8 sec.
(b) At 240 sequence numbers/min, the actual sequence number is 4t, where t
is in sec. The left edge of the forbidden region is 10(t − 3216.8). Equating
these two formulas, we find that they intersect at t = 5361.3 sec.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
185,Networking,"Imagine a generalized n-army problem, in which the agreement of any two of the blue
armies is sufficient for victory. Does a protocol exist that allows blue to win?",No. The problem is essentially the same with more than two armies.,Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
186,Networking,"Some other policies for fairness in congestion control are Additive Increase Additive
Decrease (AIAD), Multiplicative Increase Additive Decrease (MIAD), and Multiplicative
Increase Multiplicative Decrease (MIMD). Discuss these three policies in terms
of convergence and stability","In AIAD and MIMD, the users will oscillate along the efficiency line, but will
not converge. MIAD will converge just like AIMD. None of these policies
are stable. Decrease policy in AIAD and MIAD is not aggressive, and
increase policy in MIAD and MIMD is not gentle.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
187,Networking,"Consider two networks, N1 and N2, that have the same average delay between a
source A and a destination D. In N1, the delay experienced by different packets is
unformly distributed with maximum delay being 10 seconds, while in N2, 99% of the
packets experience less than one second delay with no limit on maximum delay. Discuss 
how RTP may be used in these two cases to transmit live audio/video stream.","In N, since the maximum delay is 10 seconds, an appropriate buffer can be
chosen to store a little more than 10 seconds of data at destination D. This
will ensure that there will be no jitter experienced. On the other hand, in N 2,
a smaller buffer, perhaps 2-3 seconds will be used, but some frames (that
experience larger delays) will be dropped.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
188,Networking,,,Hard,
189,Networking,"The number of companies with a Web site has grown explosively in recent years. As
a result, thousands of companies are registered in the com domain, causing a heavy
load on the top-level server for this domain. Suggest a way to alleviate this problem
without changing the naming scheme (i.e., without introducing new top-level domain
names). It is permitted that your solution requires changes to the client code.","There are, obviously, many approaches. One is to turn the top-level server
into a server farm. Another is to have 26 separate servers, one for names beginning
with a, one for b, and so on. For some period of time (say, 3 years)
after introducing the new servers, the old one could continue to operate to
give people a chance to adapt their software.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
190,Networking,"Does Webmail use POP3, IMAP, or neither? If one of these, why was that one chosen?
If neither, which one is it closer to in spirit?","It does not use either one, but it is fairly similar in spirit to IMAP because
both of them allow a remote client to examine and manage a remote mailbox.
In contrast, POP3 just sends the mailbox to the client for processing there.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
191,Networking,"Suppose that John just set up an auto-forwarding mechanism on his work email address,
which receives all of his business-related emails, to forward them to his personal
email address, which he shares with his wife. John’s wife was unaware of this, and
activated a vacation agent on their personal account. Because John forwarded his
email, he did not set up a vacation daemon on his work machine. What happens when
an email is received at John’s work email address?","Each message received in John’s work email inbox will be forwarded to his
personal inbox, thereby generating an autoreply by the vacation agent, sent to
his work inbox. This reply will be seen by the work computer as a new message,
and thus be forwarded to the personal mailbox, which in turn, will send
another reply to the work inbox. As a result there will be an endless string of
messages for each message received in John’s work email address (unless the
vacation agent is smart enough to reply just once to each sender it sees).
However, assuming that the vacation agent logs email addresses to which it
has already responded, a single auto-reply will be received by the work email
inbox and forwarded back to the personal inbox, and no more canned messages
will be generated.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
192,Networking,"Is the vacation agent part of the user agent or the message transfer agent? Of course,
it is set up using the user agent, but does the user agent actually send the replies? Explain
your answer","The actual replies have to be done by the message transfer agent. When an
SMTP connection comes in, the message transfer agent has to check whether
a vacation agent is set up to respond to the incoming email, and, if so, send an
answer. The user transfer agent cannot do this because it will not even be
invoked until the user comes back from vacation.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
193,Networking,"IMAP allows users to fetch and download email from a remote mailbox. Does this
mean that the internal format of mailboxes has to be standardized so any IMAP program
on the client side can read the mailbox on any mail server? Discuss your
answer.","No. The IMAP program does not actually touch the remote mailbox. It sends
commands to the IMAP daemon on the mail server. As long as that daemon
understands the mailbox format, it can work. Thus, a mail server could
change from one format to another overnight without telling its customers, as
long as it simultaneously changes its IMAP daemon so it understands the new
format.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
194,Networking,The bank uses a two round Feistel network on 64 bit blocks splitting the block into two 32 bit halves and applying a keyed function F in each round. You are given the ciphertext that results when the plaintext block is all zero bits and you know that this ciphertext came from that all zero input. Without knowing the secret keys can you use this to determine the output for some other inputs Explain at a high level,Yes for some inputs. In the Feistel structure the final left half L2 is F applied to the original right half R0 XORed with the original left half L0. If you know the output when both halves are zero you learn F applied to zero. For any other plaintext that uses the same R0 value the effect of changing L0 is carried directly through the XOR into L2 so relations between outputs for different left halves can be deduced even without knowing the keys,Hard,CS144 practice final answers question 12
195,Networking,"Break the following monoalphabetic substitution cipher. The plaintext, consisting of
letters only, is an excerpt from a poem by Lewis Carroll.
mvyy bek mnyx n yvjjyr snijrh invq n muvjvdt je n idnvy
jurhri n fehfevir pyeir oruvdq ki ndq uri jhrnqvdt ed zb jnvy
Irr uem rntrhyb jur yeoijrhi ndq jur jkhjyri nyy nqlndpr
Jurb nhr mnvjvdt ed jur iuvdtyr mvyy bek pezr ndq wevd jur qndpr
mvyy bek, medj bek, mvyy bek, medj bek, mvyy bek wevd jur qndpr
mvyy bek, medj bek, mvyy bek, medj bek, medj bek wevd jur qndpr","will you walk a little faster said a whiting to a snail
theres a porpoise close behind us and hes treading on my tail
see how eagerly the lobsters and the turtles all advance
they are waiting on the shingle will you come and join the dance
will you wont you will you wont you will you join the dance
will you wont you will you wont you wont you join the dance
From Alice in Wonderland (A Whiting and a Snail).",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
196,Networking,"An affine cipher is a version of a monoalphabetic substitution cipher, in which the letters
of an alphabet of size m are first map to the integers in the range 0 to m-1. Subsequently,
the integer representing each plaintext letter is transformed to an integer
representing the corresponding cipher text letter. The encryption function for a single
letter is E(x) = (ax + b) mod m, where m is the size of the alphabet and a and b are the
key of the cipher, and are co-prime. Trudy finds out that Bob generated a ciphertext
using an affine cipher. She gets a copy of the ciphertext, and finds out that the most
frequent letter of the ciphertext is ’R’, and the second most frequent letter of the
ciphertext is ’K’. Show how Trudy can break the code and retrieve the plaintext.","Assume that the most frequent plaintext letter is e and the second most frequent
letter is t. In the ciphertext, the most frequent letter is ’R’, and the second
most frequent letter is ’K’. Note that the numerical values are e = 4; K =
10; R = 17; and t = 19. The following equations therefore exist:
17 = (4a+b)mod26
10 = (19a+b)mod26
Thus, -7 = 15a mod 26, which is equivalent to 19=15a mod 26. By trial and
error, we solve: a = 3. Then 17 = (12 + b) mod 26. By observation, b = 5.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
197,Networking,"Break the following columnar transposition cipher. The plaintext is taken from a popular
computer textbook, so ‘‘computer’’ is a probable word. The plaintext consists entirely
of letters (no spaces). The ciphertext is broken up into blocks of five characters
for readability.
aauan cvlre rurnn dltme aeepb ytust iceat npmey iicgo gorch srsoc
nntii imiha oofpa gsivt tpsit lbolr otoex","The plaintext is: a digital computer is a machine that can solve problems for
people by carrying out instructions given to it.
From Structured Computer Organization by A. S. Tanenbaum.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
198,Networking,"A fundamental cryptographic principle states that all messages must have redundancy.
But we also know that redundancy helps an intruder tell if a guessed key is correct.
Consider two forms of redundancy. First, the initial n bits of the plaintext contain a
known pattern. Second, the final n bits of the message contain a hash over the message.
From a security point of view, are these two equivalent? Discuss your answer.","If the intruder had infinite computing power, they would be the same, but
since that is not the case, the second one is better. It forces the intruder to do
a computation to see if each key tried is correct. If this computation is expensive,
it will slow the intruder down.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
199,Networking,"Design an attack on DES based on the knowledge that the plaintext consists
exclusively of uppercase ASCII letters, plus space, comma, period, semicolon, carriage
return, and line feed. Nothing is known about the plaintext parity bits.","For each possible 56-bit key, decrypt the first ciphertext block. If the resulting
plaintext is legal, try the next block, etc. If the plaintext is illegal, try
the next key.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
200,Networking,"Now consider ciphertext block chaining again. Instead of a single 0 bit being
transformed into a 1 bit, an extra 0 bit is inserted into the ciphertext stream after block
Ci . How much plaintext will be garbled as a result?","Unfortunately, every plaintext block starting at Pi +1 will be wrong now, since
all the inputs to the XOR boxes will be wrong. A framing error is thus much
more serious than an inverted bit.",Hard,Book (Computer Networks by Andrew S Tanenbaum and David J Wetherall)
201,Networking,"Existential Unforgeability under Chosen Message Attack (EU CMA) game: Message Authentication Code (MAC) defined as Cipher Block Chaining (CBC) with key and hash of the message ( \text{MAC}((K, M)) = \text{CBC}((K, H(M))) ) returns tag ( T = (\text{Initialization Vector (IV)}, C) ) with random IV. Secure or insecure? If insecure, give a forgery.","Insecure. Forgery: output ( M' \ne M ) with ( T' = (IV \oplus H(M) \oplus H(M'),\ C) ).",Hard,Berkeley CS161 Spring 2025 Midterm Q6
202,Networking,"ElGamal scheme defines (C_2 = M \cdot B^r \bmod p) instead of (\text{Enc}(,H(B^r \bmod p), M)). Alice and Bob believe that this variant scheme will protect them against a man in the middle (MITM) attack (man in the middle) from Mallory, unlike lecture ElGamal. Assume that Alice and Bob do not know each other public keys and must first share them over the insecure channel. Is this correct? (A) Yes, because Mallory cannot predictably modify (C_2). (B) Yes, because (M \cdot B^r \bmod p) is not confidential that is it leaks some information about (M). (C) No, because encryption (Enc) only provides authenticity if the attacker does not know the key. (D) No, because Mallory can still cause Alice and Bob to derive keys known to Mallory.",D. No because Mallory can still cause Alice and Bob to derive keys known to Mallory.,Hard,Berkeley CS161 Spring 2025 Midterm Q7
203,ML,Explain the bias-variance tradeoff and give an example of a high-bias and a high-variance model.,"Bias: systematic error due to model assumptions; Variance: sensitivity to training data fluctuations.
Example: linear regression on nonlinear target -> high bias; deep unpruned tree -> high variance.",Easy,"Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements of Statistical Learning (2nd ed.). Springer."
204,ML,What is batch normalization and why is it used in training deep networks?,"BatchNorm normalizes activations per batch, improves training stability and speeds convergence; uses learned γ, β and running stats at inference.",Easy,"Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer."
205,ML,What is transfer learning in computer vision and how is it commonly applied with CNNs?,"Use pretrained CNN as feature extractor, replace head; freeze lower layers for small datasets, fine-tune for larger datasets.",Easy,"Schölkopf, B., & Smola, A. J. (2002). Learning with Kernels. MIT Press."
206,ML,What is word embedding and why are contextual embeddings (like BERT) better than static embeddings (like Word2Vec)?,Contextual embeddings vary with context and capture different senses; static embeddings are single vectors per word.,Easy,"Ioffe, S., & Szegedy, C. (2015). “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.” ICML."
207,ML,What is fine-tuning vs. prompt engineering for LLMs? Give pros and cons of each.,Fine-tuning adjusts weights for better accuracy; prompt engineering manipulates inputs; choose based on resources and task stability.,Easy,"Hendrycks, D., & Gimpel, K. (2016). “Gaussian Error Linear Units (GELUs).” arXiv:1606.08415."
208,ML,What is the difference between policy-based and value-based reinforcement learning methods?,Policy-based optimizes policy directly; value-based learns value estimates and derives actions; hybrids exist (actor-critic).,Easy,"Glorot, X., & Bengio, Y. (2010). “Understanding the Difficulty of Training Deep Feedforward Neural Networks.” AISTATS."
209,ML,Explain the bias-variance tradeoff and give an example of a high-bias and a high-variance model.,"Bias: systematic error due to model assumptions; Variance: sensitivity to training data fluctuations.
 Example: linear regression on nonlinear target -> high bias; deep unpruned tree -> high variance.",Easy,"Yosinski, J., Clune, J., Bengio, Y., & Lipson, H. (2014). “How Transferable Are Features in Deep Neural Networks?” NIPS."
210,ML,What is batch normalization and why is it used in training deep networks?,"BatchNorm normalizes activations per batch, improves training stability and speeds convergence; uses learned γ, β and running stats at inference.",Easy,"Rahman, M. M., et al. (2020). “Comparing the Performance of IoU and Dice in Image Segmentation Evaluation.” IEEE Access."
211,ML,What is transfer learning in computer vision and how is it commonly applied with CNNs?,"Use pretrained CNN as feature extractor, replace head; freeze lower layers for small datasets, fine-tune for larger datasets.",Easy,"Ronneberger, O., Fischer, P., & Brox, T. (2015). “U-Net: Convolutional Networks for Biomedical Image Segmentation.” MICCAI."
212,ML,What is word embedding and why are contextual embeddings (like BERT) better than static embeddings (like Word2Vec)?,Contextual embeddings vary with context and capture different senses; static embeddings are single vectors per word.,Easy,"Mikolov, T., Sutskever, I., Chen, K., Corrado, G., & Dean, J. (2013). “Efficient Estimation of Word Representations in Vector Space.” ICLR."
213,ML,What is fine-tuning vs. prompt engineering for LLMs? Give pros and cons of each.,Fine-tuning adjusts weights for better accuracy; prompt engineering manipulates inputs; choose based on resources and task stability.,Easy,"Sennrich, R., Haddow, B., & Birch, A. (2016). “Neural Machine Translation of Rare Words with Subword Units.” ACL."
214,ML,What is the difference between policy-based and value-based reinforcement learning methods?,Policy-based optimizes policy directly; value-based learns value estimates and derives actions; hybrids exist (actor-critic).,Easy,"He, H., & Garcia, E. A. (2009). “Learning from Imbalanced Data.” IEEE Transactions on Knowledge and Data Engineering."
215,ML,Explain the bias-variance tradeoff and give an example of a high-bias and a high-variance model.,"Bias: systematic error due to model assumptions; Variance: sensitivity to training data fluctuations.
 Example: linear regression on nonlinear target -> high bias; deep unpruned tree -> high variance.",Easy,"Wei, J., & Zou, J. (2022). “Instruction Tuning for Large Language Models.” arXiv:2210.11416."
216,ML,What is batch normalization and why is it used in training deep networks?,"BatchNorm normalizes activations per batch, improves training stability and speeds convergence; uses learned γ, β and running stats at inference.",Easy,"Ouyang, L., et al. (2022). “Training Language Models to Follow Instructions with Human Feedback (InstructGPT).” arXiv:2203.02155."
217,ML,What is transfer learning in computer vision and how is it commonly applied with CNNs?,"Use pretrained CNN as feature extractor, replace head; freeze lower layers for small datasets, fine-tune for larger datasets.",Easy,"Hu, E. J., Shen, Y., Wallis, P., et al. (2022). “LoRA: Low-Rank Adaptation of Large Language Models.” arXiv:2106.09685."
218,ML,What is word embedding and why are contextual embeddings (like BERT) better than static embeddings (like Word2Vec)?,Contextual embeddings vary with context and capture different senses; static embeddings are single vectors per word.,Easy,"Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction (2nd ed.). MIT Press."
219,ML,What is fine-tuning vs. prompt engineering for LLMs? Give pros and cons of each.,Fine-tuning adjusts weights for better accuracy; prompt engineering manipulates inputs; choose based on resources and task stability.,Easy,"Mnih, V., et al. (2015). “Human-Level Control through Deep Reinforcement Learning.” Nature, 518(7540)."
220,ML,What is the difference between policy-based and value-based reinforcement learning methods?,Policy-based optimizes policy directly; value-based learns value estimates and derives actions; hybrids exist (actor-critic).,Easy,"Schaul, T., Quan, J., Antonoglou, I., & Silver, D. (2016). “Prioritized Experience Replay.” ICLR."
221,ML,Explain the bias-variance tradeoff and give an example of a high-bias and a high-variance model.,"Bias: systematic error due to model assumptions; Variance: sensitivity to training data fluctuations.
 Example: linear regression on nonlinear target -> high bias; deep unpruned tree -> high variance.",Easy,"Schulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2017). “Proximal Policy Optimization Algorithms.” arXiv:1707.06347."
222,ML,What is batch normalization and why is it used in training deep networks?,"BatchNorm normalizes activations per batch, improves training stability and speeds convergence; uses learned γ, β and running stats at inference.",Easy,"Ng, A. (2017). Machine Learning Specialization. Coursera / Stanford Online."
223,ML,What is transfer learning in computer vision and how is it commonly applied with CNNs?,"Use pretrained CNN as feature extractor, replace head; freeze lower layers for small datasets, fine-tune for larger datasets.",Easy,"Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press."
224,ML,What is word embedding and why are contextual embeddings (like BERT) better than static embeddings (like Word2Vec)?,Contextual embeddings vary with context and capture different senses; static embeddings are single vectors per word.,Easy,"Long, J., Shelhamer, E., & Darrell, T. (2015). “Fully Convolutional Networks for Semantic Segmentation.” CVPR."
225,ML,What is fine-tuning vs. prompt engineering for LLMs? Give pros and cons of each.,Fine-tuning adjusts weights for better accuracy; prompt engineering manipulates inputs; choose based on resources and task stability.,Easy,"Dosovitskiy, A., et al. (2021). “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.” ICLR."
226,ML,What is the difference between policy-based and value-based reinforcement learning methods?,Policy-based optimizes policy directly; value-based learns value estimates and derives actions; hybrids exist (actor-critic).,Easy,"Vaswani, A., et al. (2017). “Attention is All You Need.” NeurIPS."
227,ML,Explain the bias-variance tradeoff and give an example of a high-bias and a high-variance model.,"Bias: systematic error due to model assumptions; Variance: sensitivity to training data fluctuations.
 Example: linear regression on nonlinear target -> high bias; deep unpruned tree -> high variance.",Easy,"Hochreiter, S., & Schmidhuber, J. (1997). “Long Short-Term Memory.” Neural Computation, 9(8)."
228,ML,What is the difference between Supervised and Unsupervised Learning?,Supervised uses labeled data for prediction; Unsupervised finds patterns in unlabeled data.,Easy,"Bishop, C. M. (2006). Pattern Recognition and Machine Learning."
229,ML,"What is the purpose of splitting data into Training, Validation, and Test sets?",Train: fit model; Val: tune hyperparameters; Test: final unbiased evaluation.,Easy,"Hastie, T., et al. (2009). The Elements of Statistical Learning."
230,ML,Define Precision and Recall.,Precision: accuracy of positive predictions; Recall: coverage of actual positives.,Easy,"Goodfellow, I., et al. (2016). Deep Learning. MIT Press."
231,ML,What is Overfitting and how can it be detected?,Model learns noise; detected by low training error but high test error.,Easy,"Bishop, C. M. (2006). Pattern Recognition and Machine Learning."
232,ML,What is the role of the learning rate in Gradient Descent?,Controls step size in optimization; balances convergence speed and stability.,Easy,"Goodfellow, I., et al. (2016). Deep Learning. MIT Press."
233,ML,What is K-Fold Cross-Validation?,Technique to estimate model performance by averaging over K data splits.,Easy,"Hastie, T., et al. (2009). The Elements of Statistical Learning."
234,ML,Explain the difference between L1 and L2 Regularization.,L1 leads to sparse weights (feature selection); L2 shrinks weights evenly.,Easy,"Tibshirani, R. (1996). Regression Shrinkage and Selection via the Lasso."
235,ML,What is the Curse of Dimensionality?,Performance degradation in high-dimensional spaces due to data sparsity.,Easy,"Bellman, R. (1961). Adaptive Control Processes: A Guided Tour."
236,ML,What is an Epoch in training?,One complete pass of the full training dataset through the model.,Easy,"Goodfellow, I., et al. (2016). Deep Learning. MIT Press."
237,ML,What is the function of the Softmax activation?,Converts logits into probabilities summing to 1 for multi-class classification.,Easy,"Bishop, C. M. (2006). Pattern Recognition and Machine Learning."
238,ML,What is a Tensor?,A multi-dimensional array used to represent data in Deep Learning.,Easy,"Goodfellow, I., et al. (2016). Deep Learning. MIT Press."
239,ML,What is a Convolutional Neural Network (CNN)?,"Neural network using convolution layers, specialized for processing grid-like data (images).",Easy,"LeCun, Y., et al. (1998). Gradient-Based Learning Applied to Document Recognition."
240,ML,What is Max Pooling?,Down-sampling by taking the maximum value in a window; reduces spatial size.,Easy,"Goodfellow, I., et al. (2016). Deep Learning. MIT Press."
241,ML,What are Stop Words?,"Common words filtered out during text processing (e.g., 'the', 'and').",Easy,"Jurafsky, D., & Martin, J. H. (2008). Speech and Language Processing."
242,ML,What is Tokenization?,Splitting text into smaller units (words/subwords) for processing.,Easy,"Manning, C., et al. (2008). Introduction to Information Retrieval."
243,ML,What is a Decision Tree?,Tree model splitting data based on feature values to predict target.,Easy,"Quinlan, J. R. (1986). Induction of Decision Trees. Machine Learning."
244,ML,What is Logistic Regression used for?,Binary classification algorithm modeling probability using sigmoid function.,Easy,"Hastie, T., et al. (2009). The Elements of Statistical Learning."
245,ML,What is K-Means Clustering?,Unsupervised algorithm partitioning data into K clusters by minimizing variance.,Easy,"MacQueen, J. (1967). Some methods for classification and analysis of multivariate observations."
246,ML,What is an Agent in RL?,The learner/decision-maker that interacts with the environment.,Easy,"Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction."
247,ML,What is a Reward Signal?,Feedback indicating the immediate success of an action.,Easy,"Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction."
248,ML,What is the purpose of an Activation Function?,"Introduces non-linearity, allowing the network to learn complex patterns.",Easy,"Goodfellow, I., et al. (2016). Deep Learning. MIT Press."
249,ML,What is One-Hot Encoding?,Representing categorical variables as binary vectors.,Easy,"Bishop, C. M. (2006). Pattern Recognition and Machine Learning."
250,ML,What is a Hyperparameter?,"Configuration setting external to the model, set before training.",Easy,"Goodfellow, I., et al. (2016). Deep Learning. MIT Press."
251,ML,What is a Confusion Matrix?,Table summarizing prediction results vs actual class labels.,Easy,"Fawcett, T. (2006). An introduction to ROC analysis."
252,ML,What is Bagging?,Ensemble method using bootstrap samples to reduce model variance.,Easy,"Breiman, L. (1996). Bagging predictors. Machine Learning."
253,ML,Explain and derive how kernel ridge regression can be expressed in dual form and how predictions are computed for a new point.,"Dual solution α = (K + λI)^{-1} y. Prediction f(x*) = k(x*,X) α.",Hard,"Espeholt, L., et al. (2018). “IMPALA: Scalable Distributed Deep-RL.” ICML."
254,ML,"Explain vanishing and exploding gradients in deep networks. Derive why tanh/sigmoid can cause vanishing gradients, and discuss initialization strategies to mitigate these issues.","Vanishing due to small derivatives (sigmoid); use proper initialization (Glorot/He), skip connections, normalization to mitigate.",Hard,Silver et al. (2016). AlphaGo Paper.
255,ML,"Design a CNN architecture for semantic segmentation of high-resolution aerial images with limited labeled data. Explain architecture choices, loss functions, and strategies to handle class imbalance.","Use U-Net/DeepLab with pretrained encoder, combine CE + Dice losses, use augmentation and semi-supervised learning to address limited labels.",Hard,"Heess, N., et al. (2017). “Emergence of Locomotion Behaviors in Rich Environments.” arXiv:1707.02286."
256,ML,"Given an NLP classification dataset with heavy label imbalance, design a training strategy including loss choices, sampling, and evaluation metrics. Justify each choice.",Combine oversampling or class-weighted/focal loss; evaluate with F1/PR-AUC; tune thresholds to optimize desired metric.,Hard,Konda & Tsitsiklis (2000). “Actor-Critic Algorithms.” NIPS.
257,ML,"Compare parameter-efficient fine-tuning (e.g., LoRA, adapters) with full fine-tuning. Explain how LoRA modifies training and why it reduces memory/compute costs.",LoRA injects low-rank adapters so only small matrices are trained; significantly reduces memory and parameter updates.,Hard,Schulman et al. (2017). PPO.
258,ML,Describe Proximal Policy Optimization (PPO). Derive the clipped surrogate objective and explain intuitively why clipping stabilizes policy updates.,"PPO objective clips importance weight r to [1-ε,1+ε], preventing large policy updates while allowing useful changes.",Hard,Schaul et al. (2016). Prioritized Replay.
259,ML,Explain and derive how kernel ridge regression can be expressed in dual form and how predictions are computed for a new point.,"Dual solution α = (K + λI)^{-1} y. Prediction f(x*) = k(x*,X) α.",Hard,Mnih et al. (2015). DQN.
260,ML,"Explain vanishing and exploding gradients in deep networks. Derive why tanh/sigmoid can cause vanishing gradients, and discuss initialization strategies to mitigate these issues.","Vanishing due to small derivatives (sigmoid); use proper initialization (Glorot/He), skip connections, normalization to mitigate.",Hard,Sutton et al. (1999). “Policy Gradient Methods for Reinforcement Learning.” NIPS.
261,ML,"Design a CNN architecture for semantic segmentation of high-resolution aerial images with limited labeled data. Explain architecture choices, loss functions, and strategies to handle class imbalance.","Use U-Net/DeepLab with pretrained encoder, combine CE + Dice losses, use augmentation and semi-supervised learning to address limited labels.",Hard,Silver et al. (2014). “Deterministic Policy Gradient Algorithms.” ICML.
262,ML,"Given an NLP classification dataset with heavy label imbalance, design a training strategy including loss choices, sampling, and evaluation metrics. Justify each choice.",Combine oversampling or class-weighted/focal loss; evaluate with F1/PR-AUC; tune thresholds to optimize desired metric.,Hard,Kingma & Welling (2014). “Auto-Encoding Variational Bayes.” ICLR.
263,ML,"Compare parameter-efficient fine-tuning (e.g., LoRA, adapters) with full fine-tuning. Explain how LoRA modifies training and why it reduces memory/compute costs.",LoRA injects low-rank adapters so only small matrices are trained; significantly reduces memory and parameter updates.,Hard,Ho & Ermon (2016). “Generative Adversarial Imitation Learning.” NIPS.
264,ML,Describe Proximal Policy Optimization (PPO). Derive the clipped surrogate objective and explain intuitively why clipping stabilizes policy updates.,"PPO objective clips importance weight r to [1-ε,1+ε], preventing large policy updates while allowing useful changes.",Hard,Goodfellow et al. (2014). “Generative Adversarial Networks.” NeurIPS.
265,ML,Explain and derive how kernel ridge regression can be expressed in dual form and how predictions are computed for a new point.,"Dual solution α = (K + λI)^{-1} y. Prediction f(x*) = k(x*,X) α.",Hard,"Brock, A., Donahue, J., & Simonyan, K. (2019). “BigGAN: Large Scale GAN Training.” ICLR."
266,ML,"Explain vanishing and exploding gradients in deep networks. Derive why tanh/sigmoid can cause vanishing gradients, and discuss initialization strategies to mitigate these issues.","Vanishing due to small derivatives (sigmoid); use proper initialization (Glorot/He), skip connections, normalization to mitigate.",Hard,"Karras, T., et al. (2019). “A Style-Based Generator Architecture for GANs (StyleGAN).” CVPR."
267,ML,"Design a CNN architecture for semantic segmentation of high-resolution aerial images with limited labeled data. Explain architecture choices, loss functions, and strategies to handle class imbalance.","Use U-Net/DeepLab with pretrained encoder, combine CE + Dice losses, use augmentation and semi-supervised learning to address limited labels.",Hard,Dosovitskiy et al. (2021). ViT Paper.
268,ML,"Given an NLP classification dataset with heavy label imbalance, design a training strategy including loss choices, sampling, and evaluation metrics. Justify each choice.",Combine oversampling or class-weighted/focal loss; evaluate with F1/PR-AUC; tune thresholds to optimize desired metric.,Hard,"Oord, A. v. d., et al. (2016). “Wavenet: A Generative Model for Raw Audio.” SSW."
269,ML,"Compare parameter-efficient fine-tuning (e.g., LoRA, adapters) with full fine-tuning. Explain how LoRA modifies training and why it reduces memory/compute costs.",LoRA injects low-rank adapters so only small matrices are trained; significantly reduces memory and parameter updates.,Hard,Radford et al. (2019). GPT-2.
270,ML,Describe Proximal Policy Optimization (PPO). Derive the clipped surrogate objective and explain intuitively why clipping stabilizes policy updates.,"PPO objective clips importance weight r to [1-ε,1+ε], preventing large policy updates while allowing useful changes.",Hard,Brown et al. (2020). GPT-3.
271,ML,Explain and derive how kernel ridge regression can be expressed in dual form and how predictions are computed for a new point.,"Dual solution α = (K + λI)^{-1} y. Prediction f(x*) = k(x*,X) α.",Hard,Touvron et al. (2023). LLaMA.
272,ML,"Explain vanishing and exploding gradients in deep networks. Derive why tanh/sigmoid can cause vanishing gradients, and discuss initialization strategies to mitigate these issues.","Vanishing due to small derivatives (sigmoid); use proper initialization (Glorot/He), skip connections, normalization to mitigate.",Hard,Hu et al. (2022). LoRA Paper.
273,ML,"Design a CNN architecture for semantic segmentation of high-resolution aerial images with limited labeled data. Explain architecture choices, loss functions, and strategies to handle class imbalance.","Use U-Net/DeepLab with pretrained encoder, combine CE + Dice losses, use augmentation and semi-supervised learning to address limited labels.",Hard,Ouyang et al. (2022). InstructGPT Paper.
274,ML,"Given an NLP classification dataset with heavy label imbalance, design a training strategy including loss choices, sampling, and evaluation metrics. Justify each choice.",Combine oversampling or class-weighted/focal loss; evaluate with F1/PR-AUC; tune thresholds to optimize desired metric.,Hard,Bai et al. (2022). “Training a Helpful and Harmless Assistant with RLHF.” Anthropic.
275,ML,"Compare parameter-efficient fine-tuning (e.g., LoRA, adapters) with full fine-tuning. Explain how LoRA modifies training and why it reduces memory/compute costs.",LoRA injects low-rank adapters so only small matrices are trained; significantly reduces memory and parameter updates.,Hard,Ziegler et al. (2019). “Fine-Tuning Language Models from Human Preferences.” arXiv:1909.08593.
276,ML,Describe Proximal Policy Optimization (PPO). Derive the clipped surrogate objective and explain intuitively why clipping stabilizes policy updates.,"PPO objective clips importance weight r to [1-ε,1+ε], preventing large policy updates while allowing useful changes.",Hard,"Lambert, N., et al. (2022). “Distilling Step-by-Step Reasoning from LLMs.” OpenAI Blog."
277,ML,Explain and derive how kernel ridge regression can be expressed in dual form and how predictions are computed for a new point.,"Dual solution α = (K + λI)^{-1} y. Prediction f(x*) = k(x*,X) α.",Hard,OpenAI (2024). GPT-4 Technical Report.
278,ML,Why are Saddle Points a problem in high-dimensional non-convex optimization?,"In high dimensions, local minima are rare; algorithms are more likely to get stuck at saddle points (where gradients are zero but not a minimum in all directions).",Hard,"Dauphin, Y., et al. (2014). Identifying and attacking the saddle point problem in high-dimensional non-convex optimization."
279,ML,Why is Layer Normalization preferred over Batch Normalization in RNNs and Transformers?,"BN depends on batch statistics which are problematic for variable sequence lengths; Layer Norm computes statistics per sample, independent of the batch.",Hard,"Ba, J. L., et al. (2016). Layer Normalization."
280,ML,Why do VAEs often produce blurry images compared to GANs?,"VAEs optimize the Evidence Lower Bound (ELBO) using MSE (or similar) which is mean-seeking (averages modes), whereas GANs minimize divergence that supports sharp mode selection.",Hard,"Larsen, A. B. L., et al. (2016). Autoencoding beyond pixels using a learned similarity metric."
281,ML,What is the No Free Lunch Theorem?,"It states that averaged over all possible data generating distributions, every classification algorithm has the same error rate; no single model is universally superior.",Hard,"Wolpert, D. H. (1996). The Lack of A Priori Distinctions Between Learning Algorithms."
282,ML,What is the specific purpose of Double Q-Learning?,It addresses the maximization bias of standard Q-Learning (which tends to overestimate values) by using two separate networks to decouple action selection from value estimation.,Hard,"Van Hasselt, H., et al. (2016). Deep Reinforcement Learning with Double Q-learning."
283,ML,Explain He (Kaiming) Initialization.,"Initializes weights with variance 2/n to maintain the variance of activations through layers using ReLU, preventing vanishing/exploding gradients.",Hard,"He, K., et al. (2015). Delving Deep into Rectifiers."
284,ML,How does Focal Loss address class imbalance in Object Detection?,"It adds a modulating factor (1 - p_t)^gamma to the Cross-Entropy loss to down-weight easy negatives and focus training on hard, misclassified examples.",Hard,"Lin, T. Y., et al. (2017). Focal Loss for Dense Object Detection."
285,ML,What is Byte Pair Encoding (BPE)?,A subword tokenization algorithm that iteratively merges the most frequent pair of adjacent characters/tokens to handle out-of-vocabulary words.,Hard,"Sennrich, R., et al. (2016). Neural Machine Translation of Rare Words with Subword Units."
286,ML,Why is the PR (Precision-Recall) curve preferred over ROC for imbalanced datasets?,ROC curves can be deceptively optimistic when the negative class is large; PR curves focus only on the positive class (minority) performance.,Hard,"Davis, J., & Goadrich, M. (2006). The Relationship Between Precision-Recall and ROC Curves."
287,ML,How does Nesterov Accelerated Gradient (NAG) differ from standard Momentum?,Standard Momentum calculates the gradient at the current position; NAG calculates the gradient at the approximate future position (lookahead) to correct the velocity vector.,Hard,"Sutskever, I., et al. (2013). On the importance of initialization and momentum in deep learning."
288,ML,What is the structural difference between GRU and LSTM?,"GRU combines the Forget and Input gates into a single Update gate, merges the cell state and hidden state, and lacks a separate Output gate.",Hard,"Cho, K., et al. (2014). Learning Phrase Representations using RNN Encoder-Decoder."
289,ML,What is Score Matching in the context of Diffusion Models?,"A method to train energy-based models by minimizing the difference between the gradient of the log-density of the model and the data, avoiding the need to compute the partition function.",Hard,"Song, Y., & Ermon, S. (2019). Generative Modeling by Estimating Gradients of the Data Distribution."
290,ML,What condition must a kernel function satisfy according to Mercer's Theorem?,The kernel matrix (Gram matrix) must be symmetric and Positive Semi-Definite (PSD) for any finite set of inputs.,Hard,"Mercer, J. (1909). Functions of positive and negative type."
291,ML,What is the core idea of Trust Region Policy Optimization (TRPO)?,It updates the policy by maximizing expected return subject to a constraint on the KL divergence (trust region) between the old and new policy to ensure monotonic improvement.,Hard,"Schulman, J., et al. (2015). Trust Region Policy Optimization."
292,ML,When should Xavier (Glorot) Initialization be used over He Initialization?,"Xavier is optimized for linear, sigmoid, or tanh activations (variance 2/(n_in+n_out)), whereas He is optimized for ReLU variants.",Hard,"Glorot, X., & Bengio, Y. (2010). Understanding the difficulty of training deep feedforward neural networks."
293,ML,What are Rotary Positional Embeddings (RoPE)?,"A technique that encodes absolute position by rotating the query and key vectors in the complex plane, which naturally allows the model to capture relative positional information.",Hard,"Su, J., et al. (2021). Roformer: Enhanced Transformer with Rotary Position Embedding."
294,ML,What is the Elastic Net?,A regularization technique that linearly combines L1 (Lasso) and L2 (Ridge) penalties to handle correlated features and select groups of variables.,Hard,"Zou, H., & Hastie, T. (2005). Regularization and variable selection via the elastic net."
295,ML,How does Non-Maximum Suppression (NMS) work?,It filters object detection proposals by selecting the box with the highest confidence and discarding all other boxes that have an Intersection over Union (IoU) > threshold with it.,Hard,"Girshick, R., et al. (2014). Rich Feature Hierarchies for Accurate Object Detection."
296,ML,What is the Swish activation function and its property?,"Swish is f(x) = x * sigmoid(x); it is non-monotonic and unbounded above, often outperforming ReLU in deeper networks by allowing a small negative flow.",Hard,"Ramachandran, P., et al. (2017). Searching for Activation Functions."
297,ML,What is the role of the Critic in Actor-Critic methods?,"The Critic estimates the value function (state-value or action-value) to compute the advantage or TD error, which reduces the variance of the Actor's policy gradient updates.",Hard,"Konda, V. R., & Tsitsiklis, J. N. (2000). Actor-Critic Algorithms."
298,ML,What is Stacking (Stacked Generalization)?,An ensemble method where a meta-model is trained to combine the predictions of several base models (level-0) to make the final prediction.,Hard,"Wolpert, D. H. (1992). Stacked Generalization. Neural Networks."
299,ML,What is the KV-Cache in LLM inference?,A memory optimization that stores the Key and Value matrices of past tokens during autoregressive generation to prevent re-computing them for every new token.,Hard,"Pope, R., et al. (2023). Efficiently Scaling Transformer Inference."
300,ML,What is the condition number of the Hessian and its impact?,"The ratio of the largest to smallest eigenvalue of the Hessian; a high condition number indicates an ill-conditioned curvature (ravine), causing slow convergence for SGD.",Hard,"Nocedal, J., & Wright, S. J. (2006). Numerical Optimization."
301,ML,What is PAC Learning (Probably Approximately Correct)?,"A theoretical framework to analyze learning algorithms, determining the sample size needed to generate a hypothesis with low error with high probability.",Hard,"Valiant, L. G. (1984). A Theory of the Learnable."
302,ML,How does Latent Diffusion differ from standard Diffusion Models?,"Latent Diffusion applies the diffusion process in a compressed latent space (via VAE) rather than pixel space, significantly reducing computational cost while maintaining quality.",Hard,"Rombach, R., et al. (2022). High-Resolution Image Synthesis with Latent Diffusion Models."
303,ML,Derive the gradient update for logistic regression with cross-entropy loss and L2 regularization.,Gradient w.r.t w: (p - y)x + λ w. Update as above with learning rate η.,Medium,"Silver, D., et al. (2017). “Mastering the Game of Go without Human Knowledge.” Nature, 550(7676)."
304,ML,"Compare ReLU, Leaky ReLU and GELU activations. When would you prefer GELU?",ReLU simple and sparse; Leaky avoids dead neurons; GELU is smooth and often preferred in transformers for performance.,Medium,"Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). “ImageNet Classification with Deep Convolutional Neural Networks.” NIPS."
305,ML,Explain the difference between IoU and Dice coefficient. Provide formulas and when each is preferred in segmentation evaluation.,"IoU = intersection/union; Dice = 2*intersection/(sum sizes). Dice can be preferred for small, imbalanced masks.",Medium,"He, K., Zhang, X., Ren, S., & Sun, J. (2016). “Deep Residual Learning for Image Recognition.” CVPR."
306,ML,Explain subword tokenization (BPE/WordPiece). Why is it useful for handling rare words and morphology?,Subword tokenization balances vocabulary size and coverage; represents rare words as sequences of subwords.,Medium,"Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” NAACL."
307,ML,Explain instruction tuning and why mixture-of-expert human feedback datasets improve LLM helpfulness.,Instruction tuning uses labeled Q->A pairs; diverse human feedback increases model helpfulness and reduces brittleness.,Medium,"Brown, T. B., et al. (2020). “Language Models are Few-Shot Learners.” NeurIPS (GPT-3 Paper)."
308,ML,Explain experience replay in DQN and why it's important. How does prioritized replay differ and why use it?,Replay reduces correlation and improves stability; prioritized replay focuses learning on informative transitions.,Medium,"Radford, A., et al. (2021). “Learning Transferable Visual Models from Natural Language Supervision (CLIP).” ICML."
309,ML,Derive the gradient update for logistic regression with cross-entropy loss and L2 regularization.,Gradient w.r.t w: (p - y)x + λ w. Update as above with learning rate η.,Medium,"Chen, T., Kornblith, S., Norouzi, M., & Hinton, G. (2020). “A Simple Framework for Contrastive Learning of Visual Representations (SimCLR).” ICML."
310,ML,"Compare ReLU, Leaky ReLU and GELU activations. When would you prefer GELU?",ReLU simple and sparse; Leaky avoids dead neurons; GELU is smooth and often preferred in transformers for performance.,Medium,"Vaswani, A., et al. (2017). “Attention Is All You Need.” NeurIPS."
311,ML,Explain the difference between IoU and Dice coefficient. Provide formulas and when each is preferred in segmentation evaluation.,"IoU = intersection/union; Dice = 2*intersection/(sum sizes). Dice can be preferred for small, imbalanced masks.",Medium,"Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). “Improving Language Understanding by Generative Pre-training.” OpenAI Report."
312,ML,Explain subword tokenization (BPE/WordPiece). Why is it useful for handling rare words and morphology?,Subword tokenization balances vocabulary size and coverage; represents rare words as sequences of subwords.,Medium,"Dosovitskiy, A., et al. (2021). “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.” ICLR."
313,ML,Explain instruction tuning and why mixture-of-expert human feedback datasets improve LLM helpfulness.,Instruction tuning uses labeled Q->A pairs; diverse human feedback increases model helpfulness and reduces brittleness.,Medium,"Hochreiter, S., & Schmidhuber, J. (1997). LSTM."
314,ML,Explain experience replay in DQN and why it's important. How does prioritized replay differ and why use it?,Replay reduces correlation and improves stability; prioritized replay focuses learning on informative transitions.,Medium,"Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). “Learning Representations by Back-Propagating Errors.” Nature, 323(6088)."
315,ML,Derive the gradient update for logistic regression with cross-entropy loss and L2 regularization.,Gradient w.r.t w: (p - y)x + λ w. Update as above with learning rate η.,Medium,"He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Networks. CVPR."
316,ML,"Compare ReLU, Leaky ReLU and GELU activations. When would you prefer GELU?",ReLU simple and sparse; Leaky avoids dead neurons; GELU is smooth and often preferred in transformers for performance.,Medium,"Bengio, Y., Courville, A., & Vincent, P. (2013). “Representation Learning: A Review and New Perspectives.” IEEE TPAMI."
317,ML,Explain the difference between IoU and Dice coefficient. Provide formulas and when each is preferred in segmentation evaluation.,"IoU = intersection/union; Dice = 2*intersection/(sum sizes). Dice can be preferred for small, imbalanced masks.",Medium,Sutton & Barto (2018). Reinforcement Learning: An Introduction.
318,ML,Explain subword tokenization (BPE/WordPiece). Why is it useful for handling rare words and morphology?,Subword tokenization balances vocabulary size and coverage; represents rare words as sequences of subwords.,Medium,"Schulman, J., et al. (2015). “Trust Region Policy Optimization.” ICML."
319,ML,Explain instruction tuning and why mixture-of-expert human feedback datasets improve LLM helpfulness.,Instruction tuning uses labeled Q->A pairs; diverse human feedback increases model helpfulness and reduces brittleness.,Medium,"Silver, D., et al. (2016). “Mastering the Game of Go with Deep Neural Networks and Tree Search.” Nature."
320,ML,Explain experience replay in DQN and why it's important. How does prioritized replay differ and why use it?,Replay reduces correlation and improves stability; prioritized replay focuses learning on informative transitions.,Medium,"Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction."
321,ML,Derive the gradient update for logistic regression with cross-entropy loss and L2 regularization.,Gradient w.r.t w: (p - y)x + λ w. Update as above with learning rate η.,Medium,"Van Hasselt, H., Guez, A., & Silver, D. (2016). “Deep Reinforcement Learning with Double Q-learning.” AAAI."
322,ML,"Compare ReLU, Leaky ReLU and GELU activations. When would you prefer GELU?",ReLU simple and sparse; Leaky avoids dead neurons; GELU is smooth and often preferred in transformers for performance.,Medium,"Haarnoja, T., et al. (2018). “Soft Actor-Critic Algorithms and Applications.” arXiv:1812.05905."
323,ML,Explain the difference between IoU and Dice coefficient. Provide formulas and when each is preferred in segmentation evaluation.,"IoU = intersection/union; Dice = 2*intersection/(sum sizes). Dice can be preferred for small, imbalanced masks.",Medium,"He, K., et al. (2015). “Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification.” ICCV."
324,ML,Explain subword tokenization (BPE/WordPiece). Why is it useful for handling rare words and morphology?,Subword tokenization balances vocabulary size and coverage; represents rare words as sequences of subwords.,Medium,"He, K., & Sun, J. (2015). Rectifier Networks & He Initialization."
325,ML,Explain instruction tuning and why mixture-of-expert human feedback datasets improve LLM helpfulness.,Instruction tuning uses labeled Q->A pairs; diverse human feedback increases model helpfulness and reduces brittleness.,Medium,"Chollet, F. (2017). Deep Learning with Python. Manning Publications."
326,ML,Explain experience replay in DQN and why it's important. How does prioritized replay differ and why use it?,Replay reduces correlation and improves stability; prioritized replay focuses learning on informative transitions.,Medium,"Murphy, K. P. (2022). Probabilistic Machine Learning: An Introduction. MIT Press."
327,ML,Derive the gradient update for logistic regression with cross-entropy loss and L2 regularization.,Gradient w.r.t w: (p - y)x + λ w. Update as above with learning rate η.,Medium,"LeCun, Y., Bengio, Y., & Hinton, G. (2015). “Deep Learning.” Nature, 521(7553)."
328,ML,"Compare ReLU, Leaky ReLU and GELU activations. When would you prefer GELU?",ReLU simple and sparse; Leaky avoids dead neurons; GELU is smooth and often preferred in transformers for performance.,Medium,"Hinton, G. (2012). “A Practical Guide to Training Restricted Boltzmann Machines.” UTML Technical Report."
329,ML,Explain the difference between IoU and Dice coefficient. Provide formulas and when each is preferred in segmentation evaluation.,"IoU = intersection/union; Dice = 2*intersection/(sum sizes). Dice can be preferred for small, imbalanced masks.",Medium,"Rumelhart, Hinton & Williams (1986). Backpropagation Paper."
330,ML,Explain subword tokenization (BPE/WordPiece). Why is it useful for handling rare words and morphology?,Subword tokenization balances vocabulary size and coverage; represents rare words as sequences of subwords.,Medium,Goodfellow et al. (2016). Deep Learning.
331,ML,Explain instruction tuning and why mixture-of-expert human feedback datasets improve LLM helpfulness.,Instruction tuning uses labeled Q->A pairs; diverse human feedback increases model helpfulness and reduces brittleness.,Medium,Krizhevsky et al. (2012). AlexNet.
332,ML,Explain experience replay in DQN and why it's important. How does prioritized replay differ and why use it?,Replay reduces correlation and improves stability; prioritized replay focuses learning on informative transitions.,Medium,"Kingma, D. P., & Ba, J. (2015). “Adam: A Method for Stochastic Optimization.” ICLR."
333,ML,Derive the gradient update for logistic regression with cross-entropy loss and L2 regularization.,Gradient w.r.t w: (p - y)x + λ w. Update as above with learning rate η.,Medium,"Srivastava, N., et al. (2014). “Dropout: A Simple Way to Prevent Neural Networks from Overfitting.” JMLR."
334,ML,"Compare ReLU, Leaky ReLU and GELU activations. When would you prefer GELU?",ReLU simple and sparse; Leaky avoids dead neurons; GELU is smooth and often preferred in transformers for performance.,Medium,He et al. (2015). He Initialization Paper.
335,ML,Explain the difference between IoU and Dice coefficient. Provide formulas and when each is preferred in segmentation evaluation.,"IoU = intersection/union; Dice = 2*intersection/(sum sizes). Dice can be preferred for small, imbalanced masks.",Medium,Glorot & Bengio (2010). Xavier Initialization Paper.
336,ML,Explain subword tokenization (BPE/WordPiece). Why is it useful for handling rare words and morphology?,Subword tokenization balances vocabulary size and coverage; represents rare words as sequences of subwords.,Medium,"Zhang, H., et al. (2018). “mixup: Beyond Empirical Risk Minimization.” ICLR."
337,ML,Explain instruction tuning and why mixture-of-expert human feedback datasets improve LLM helpfulness.,Instruction tuning uses labeled Q->A pairs; diverse human feedback increases model helpfulness and reduces brittleness.,Medium,"Shorten, C., & Khoshgoftaar, T. M. (2019). “A Survey on Image Data Augmentation.” Journal of Big Data."
338,ML,Explain experience replay in DQN and why it's important. How does prioritized replay differ and why use it?,Replay reduces correlation and improves stability; prioritized replay focuses learning on informative transitions.,Medium,"Bengio, Y., Simard, P., & Frasconi, P. (1994). “Learning Long-Term Dependencies with Gradient Descent is Difficult.” IEEE TNN."
339,ML,Derive the gradient update for logistic regression with cross-entropy loss and L2 regularization.,Gradient w.r.t w: (p - y)x + λ w. Update as above with learning rate η.,Medium,Hochreiter & Schmidhuber (1997). LSTM.
340,ML,"Compare ReLU, Leaky ReLU and GELU activations. When would you prefer GELU?",ReLU simple and sparse; Leaky avoids dead neurons; GELU is smooth and often preferred in transformers for performance.,Medium,"Cho, K., et al. (2014). “Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation.” EMNLP."
341,ML,Explain the difference between IoU and Dice coefficient. Provide formulas and when each is preferred in segmentation evaluation.,"IoU = intersection/union; Dice = 2*intersection/(sum sizes). Dice can be preferred for small, imbalanced masks.",Medium,Vaswani et al. (2017). Attention is All You Need.
342,ML,Explain subword tokenization (BPE/WordPiece). Why is it useful for handling rare words and morphology?,Subword tokenization balances vocabulary size and coverage; represents rare words as sequences of subwords.,Medium,Brown et al. (2020). GPT-3 Paper.
343,ML,Explain instruction tuning and why mixture-of-expert human feedback datasets improve LLM helpfulness.,Instruction tuning uses labeled Q->A pairs; diverse human feedback increases model helpfulness and reduces brittleness.,Medium,Radford et al. (2019). GPT-2 Paper.
344,ML,Explain experience replay in DQN and why it's important. How does prioritized replay differ and why use it?,Replay reduces correlation and improves stability; prioritized replay focuses learning on informative transitions.,Medium,Devlin et al. (2019). BERT Paper.
345,ML,Derive the gradient update for logistic regression with cross-entropy loss and L2 regularization.,Gradient w.r.t w: (p - y)x + λ w. Update as above with learning rate η.,Medium,"Raffel, C., et al. (2020). “Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (T5).” JMLR."
346,ML,"Compare ReLU, Leaky ReLU and GELU activations. When would you prefer GELU?",ReLU simple and sparse; Leaky avoids dead neurons; GELU is smooth and often preferred in transformers for performance.,Medium,"Chowdhery, A., et al. (2022). “PaLM: Scaling Language Models with Pathways.” arXiv:2204.02311."
347,ML,Explain the difference between IoU and Dice coefficient. Provide formulas and when each is preferred in segmentation evaluation.,"IoU = intersection/union; Dice = 2*intersection/(sum sizes). Dice can be preferred for small, imbalanced masks.",Medium,"Touvron, H., et al. (2023). “LLaMA: Open and Efficient Foundation Language Models.” arXiv:2302.13971."
348,ML,Explain subword tokenization (BPE/WordPiece). Why is it useful for handling rare words and morphology?,Subword tokenization balances vocabulary size and coverage; represents rare words as sequences of subwords.,Medium,Sutton & Barto (2018). Reinforcement Learning.
349,ML,Explain instruction tuning and why mixture-of-expert human feedback datasets improve LLM helpfulness.,Instruction tuning uses labeled Q->A pairs; diverse human feedback increases model helpfulness and reduces brittleness.,Medium,Silver et al. (2017). AlphaZero Paper.
350,ML,Explain experience replay in DQN and why it's important. How does prioritized replay differ and why use it?,Replay reduces correlation and improves stability; prioritized replay focuses learning on informative transitions.,Medium,Schulman et al. (2017). PPO Paper.
351,ML,Derive the gradient update for logistic regression with cross-entropy loss and L2 regularization.,Gradient w.r.t w: (p - y)x + λ w. Update as above with learning rate η.,Medium,Haarnoja et al. (2018). SAC Paper.
352,ML,"Compare ReLU, Leaky ReLU and GELU activations. When would you prefer GELU?",ReLU simple and sparse; Leaky avoids dead neurons; GELU is smooth and often preferred in transformers for performance.,Medium,Mnih et al. (2015). DQN Paper.
353,ML,How does the Random Forest algorithm work?,Ensemble of decision trees using bagging and random feature selection.,Medium,"Breiman, L. (2001). Random Forests. Machine Learning."
354,ML,Explain the ROC curve and AUC.,ROC plots sensitivity vs (1-specificity); AUC measures separability.,Medium,"Fawcett, T. (2006). An introduction to ROC analysis."
355,ML,What is the difference between Stochastic Gradient Descent (SGD) and Batch Gradient Descent?,"Batch uses full data; SGD uses one sample per step (faster, noisier).",Medium,"Bottou, L. (2010). Large-Scale Machine Learning with SGD."
356,ML,Why is Gradient Boosting often more accurate than Random Forest?,"Boosting corrects previous errors sequentially, often reducing bias better.",Medium,"Friedman, J. H. (2001). Greedy function approximation: A gradient boosting machine."
357,ML,What is Principal Component Analysis (PCA)?,Linear dimensionality reduction projecting data to maximize variance.,Medium,"Jolliffe, I. T. (2002). Principal Component Analysis. Springer."
358,ML,How does SVM handle non-linear data?,Uses Kernel Trick to map data to high dimensions for linear separation.,Medium,"Cortes, C., & Vapnik, V. (1995). Support-vector networks."
359,ML,Explain the vanishing gradient problem.,"Gradients shrink exponentially in deep layers, stopping weight updates.",Medium,"Hochreiter, S. (1998). The vanishing gradient problem."
360,ML,How does LSTM solve the vanishing gradient problem?,Uses gating mechanisms to allow gradients to flow unchanged over time.,Medium,"Hochreiter, S., & Schmidhuber, J. (1997). Long Short-Term Memory."
361,ML,Compare Adam and RMSProp optimizers.,Adam combines RMSProp (squared gradients) with Momentum.,Medium,"Kingma, D. P., & Ba, J. (2014). Adam: A Method for Stochastic Optimization."
362,ML,What is Dropout and why does it work?,Randomly disables neurons during training to prevent overfitting.,Medium,"Srivastava, N., et al. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting."
363,ML,What is the purpose of Skip Connections in ResNets?,"Allows direct gradient flow, enabling training of very deep networks.",Medium,"He, K., et al. (2016). Deep Residual Learning for Image Recognition."
364,ML,"Explain the concept of Word Embeddings (e.g., Word2Vec).",Dense vector representations of words preserving semantic meaning.,Medium,"Mikolov, T., et al. (2013). Efficient Estimation of Word Representations in Vector Space."
365,ML,How does the Attention Mechanism work?,Computes weighted importance of inputs relevant to current output.,Medium,"Bahdanau, D., et al. (2014). Neural Machine Translation by Jointly Learning to Align and Translate."
366,ML,What is the difference between BERT and GPT?,BERT: Bidirectional Encoder (understanding); GPT: Unidirectional Decoder (generation).,Medium,"Devlin, J., et al. (2018) [BERT]; Radford, A., et al. (2018) [GPT]."
367,ML,What is Data Augmentation and why is it used?,Generating modified training samples to improve model generalization.,Medium,"Shorten, C., & Khoshgoftaar, T. M. (2019). A survey on Image Data Augmentation."
368,ML,Explain the difference between Semantic and Instance Segmentation.,Semantic labels class; Instance distinguishes individual objects of a class.,Medium,"Garcia-Garcia, A., et al. (2017). A Review on Deep Learning Techniques for Image Segmentation."
369,ML,How does YOLO (You Only Look Once) achieve real-time detection?,Single-pass regression for bounding boxes/classes; fast inference.,Medium,"Redmon, J., et al. (2016). You Only Look Once: Unified, Real-Time Object Detection."
370,ML,Differentiate between On-Policy and Off-Policy RL.,On-policy learns current policy; Off-policy learns optimal policy (greedy).,Medium,"Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction."
371,ML,What is the Exploration vs. Exploitation trade-off?,Balancing trying new actions vs using known best actions.,Medium,"Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction."
372,ML,How does a GAN (Generative Adversarial Network) work?,"Generator creates fakes, Discriminator detects them; trained competitively.",Medium,"Goodfellow, I., et al. (2014). Generative Adversarial Nets."
373,ML,What is the main difference between VAEs and GANs?,VAEs maximize likelihood (probabilistic); GANs use adversarial game.,Medium,"Kingma, D. P., & Welling, M. (2013) [VAE]; Goodfellow (2014) [GAN]."
374,ML,What is F1 Score and when to use it?,Harmonic mean of Precision/Recall; good for imbalanced datasets.,Medium,"Van Rijsbergen, C. J. (1979). Information Retrieval."
375,ML,Explain Batch Normalization.,Normalizes layer inputs per batch to stabilize and speed up training.,Medium,"Ioffe, S., & Szegedy, C. (2015). Batch Normalization."
376,ML,What is the difference between Parametric and Non-Parametric models?,Parametric has fixed size; Non-parametric grows with data.,Medium,"Murphy, K. P. (2012). Machine Learning: A Probabilistic Perspective."
377,ML,What is Homoscedasticity?,Assumption that error variance is constant across input values.,Medium,"Wooldridge, J. M. (2012). Introductory Econometrics."
378,ML,Explain the difference between Correlation and Causation in ML.,Correlation is association; Causation is effect; ML finds correlation.,Medium,"Pearl, J. (2009). Causality. Cambridge University Press."
379,ML,What is Imbalanced Data and how to handle it?,Skewed class distribution; handle via resampling or weighted loss.,Medium,"Chawla, N. V., et al. (2002). SMOTE: Synthetic Minority Over-sampling Technique."
380,ML,What is Multi-Collinearity?,High correlation between features; destabilizes regression coefficients.,Medium,"Belsley, D. A., et al. (1980). Regression Diagnostics."
381,ML,What is Transfer Learning?,"Reusing a pre-trained model on a new, related task.",Medium,"Pan, S. J., & Yang, Q. (2010). A Survey on Transfer Learning."
382,ML,What is the difference between Max Pooling and Average Pooling?,Max selects peak features; Average smooths/summarizes features.,Medium,"Boureau, Y. L., et al. (2010). A theoretical analysis of feature pooling."
383,ML,Why do we use Non-Linear Activation functions?,To learn complex mappings; linear stacks collapse to single linear layer.,Medium,"Hornik, K. (1991). Approximation capabilities of multilayer feedforward networks."
384,ML,What is TF-IDF?,Statistical measure evaluating word importance in a document relative to corpus.,Medium,"Salton, G., & McGill, M. J. (1983). Introduction to Modern Information Retrieval."
385,ML,What is Beam Search?,Keeps top 'k' sequences during generation to improve output quality.,Medium,"Sutskever, I., et al. (2014). Sequence to Sequence Learning with Neural Networks."
386,ML,Explain the concept of 'Positional Encoding' in Transformers.,Adds order information to embeddings since Transformers are permutation invariant.,Medium,"Vaswani, A., et al. (2017). Attention Is All You Need."
387,ML,What is IoU (Intersection over Union)?,Metric measuring overlap between predicted and ground truth bounding boxes.,Medium,"Everingham, M., et al. (2010). The Pascal Visual Object Classes (VOC) Challenge."
388,ML,What is the Receptive Field?,Input region influencing a specific neuron's activation.,Medium,"Luo, W., et al. (2016). Understanding the Effective Receptive Field in Deep CNNs."
389,ML,What is the Bellman Equation?,Recursive formula for value function: reward + discounted future value.,Medium,"Bellman, R. (1957). Dynamic Programming. Princeton University Press."
390,ML,What is Q-Learning?,Algorithm learning action-values to find optimal policy.,Medium,"Watkins, C. J. C. H., & Dayan, P. (1992). Q-learning. Machine Learning."
391,ML,What is the difference between parameters and hyperparameters?,Parameters are learned; Hyperparameters are set manually.,Medium,"Goodfellow, I., et al. (2016). Deep Learning. MIT Press."
392,ML,What is Cross-Entropy Loss?,Loss function measuring difference between predicted probability and true label.,Medium,"Bishop, C. M. (2006). Pattern Recognition and Machine Learning."
393,ML,What is the Bias-Variance Tradeoff?,Balancing underfitting (bias) and overfitting (variance) to minimize error.,Medium,"Geman, S., et al. (1992). Neural networks and the bias/variance dilemma."
394,ML,Why is feature scaling important for SVM and KNN?,Distance-based algorithms require scaling to prevent dominance of large-range features.,Medium,"Han, J., et al. (2011). Data Mining: Concepts and Techniques."
395,ML,What is Hinge Loss?,Loss function for SVM; penalizes misclassifications and low margins.,Medium,"Rosasco, L., et al. (2004). Are Loss Functions All the Same?"
396,ML,What is Leaky ReLU?,ReLU variant allowing small negative gradient to prevent dead neurons.,Medium,"Maas, A. L., et al. (2013). Rectifier Nonlinearities Improve Neural Network Acoustic Models."
397,ML,What is the purpose of the 'Temperature' parameter in Softmax?,Controls randomness/sharpness of softmax output probabilities.,Medium,"Hinton, G., et al. (2015). Distilling the Knowledge in a Neural Network."
398,ML,What is Stratified K-Fold Cross-Validation?,"A variation of K-Fold that preserves the percentage of samples for each class in every fold, ensuring representative splits.",Medium,"Kohavi, R. (1995). A Study of Cross-Validation and Bootstrap."
399,ML,What is Early Stopping?,A regularization technique where training is halted when the performance on a validation dataset starts to degrade (loss increases).,Medium,"Prechelt, L. (1998). Early Stopping - But When?"
400,ML,What is the difference between GloVe and Word2Vec?,"Word2Vec is a predictive model (local window context), while GloVe is a count-based model using global matrix factorization of co-occurrence statistics.",Medium,"Pennington, J., et al. (2014). GloVe: Global Vectors for Word Representation."
401,ML,What is an Inception Module?,"A network block that performs convolutions with multiple filter sizes (1x1, 3x3, 5x5) in parallel and concatenates the outputs to capture multi-scale features.",Medium,"Szegedy, C., et al. (2015). Going Deeper with Convolutions."
402,ML,What is Experience Replay?,"Storing agent experiences (state, action, reward, next state) in a buffer and sampling random batches for training to break correlation between consecutive samples.",Medium,"Mnih, V., et al. (2015). Human-level control through deep reinforcement learning."
403,Database,What is meant by DBMS and what is its utility?,"As the name suggests DBMS or Database Management System is a set of applications
or programs that enable users to create and maintain a database. DBMS provides a
tool or an interface for performing various operations such as inserting, deleting,
updating, etc. into a database. It is so_x0000_ware that enables the storage of data more
compactly and securely as compared to a file-based system. A DBMS system helps a
user to overcome problems like data inconsistency, data redundancy, etc. in a
database and makes it more convenient and organized to use it.
Examples of popular DBMS systems are file systems, XML, Windows Registry, etc.",easy,https://www.interviewbit.com/dbms-interview-questions/
404,Database," Explain RDBMS
with examples.","RDBMS stands for Relational Database Management System and was introduced in
the 1970s to access and store data more eﬀiciently than DBMS. RDBMS stores data in
the form of tables as compared to DBMS which stores data as files. Storing data as
rows and columns makes it easier to locate specific values in the database and makes
it more eﬀicient as compared to DBMS.
Examples of popular RDBMS systems are MySQL, Oracle DB, etc.",easy,
405,Database,What is meant by a database?,"A Database is an organized, consistent, and logical collection of data that can easily
be updated, accessed, and managed. Database mostly contains sets of tables or
objects (anything created using create command is a database object) which consist
of records and fields. A tuple or a row represents a single entry in a table. An attribute
or a column represents the basic units of data storage, which contain information
about a particular aspect of the table. DBMS extracts data from a database in the
form of queries given by the user.",easy,
406,Database,"Mention the issues with traditional file-based systems that
make DBMS a better choice?","The absence of indexing in a traditional file-based system leaves us with the only
option of scanning the full page and hence making the access of content tedious and
super slow. The other issue is redundancy and inconsistency as files have many
duplicate and redundant data and changing one of them makes all of them
inconsistent. Accessing data is harder in traditional file-based systems because data
is unorganized in them.
Another issue is the lack of concurrency control, which leads to one operation locking
the entire page, as compared to DBMS where multiple operations can work on a
single file simultaneously.
Integrity check, data isolation, atomicity, security, etc. are some other issues with
traditional file-based systems for which DBMSs have provided some good solutions.",easy,
407,Database,Explain a few advantages of a DBMS.,"Following are the few advantages of using a DBMS.Data Sharing: Data from a single database can be simultaneously shared by
multiple users. Such sharing also enables end-users to react to changes quickly
in the database environment.
Integrity constraints: The existence of such constraints allows storing of data in
an organized and refined manner.
Controlling redundancy in a database: Eliminates redundancy in a database by
providing a mechanism that integrates all the data in a single database.
Data Independence: This allows changing the data structure without altering
the composition of any of the executing application programs.
Provides backup and recovery facility: It can be configured to automatically
create the backup of the data and restore the data in the database whenever
required.
Data Security: DBMS provides the necessary tools to make the storage and
transfer of data more reliable and secure. Authentication (the process of giving
restricted access to a user) and encryption (encrypting sensitive data such as
OTP , credit card information, etc.) are some popular tools used to secure data in
a DBMS.",easy,
408,Database,Explain diﬀerent languages present in DBMS.,"Following are various languages present in DBMS:
DDL(Data Definition Language): It contains commands which are required to
define the database.
E.g., CREATE, ALTER, DROP , TRUNCATE, RENAME, etc.
DML(Data Manipulation Language): It contains commands which are required
to manipulate the data present in the database.
E.g., SELECT, UPDATE, INSERT, DELETE, etc.
DCL(Data Control Language): It contains commands which are required to
deal with the user permissions and controls of the database system.
E.g., GRANT and REVOKE.
TCL(Transaction Control Language): It contains commands which are required
to deal with the transaction of the database.
E.g., COMMIT, ROLLBACK, and SAVEPOINT.",easy,
409,Database,What is meant by ACID properties in DBMS?,"ACID stands for Atomicity, Consistency, Isolation, and Durability in a DBMS these are
those properties that ensure a safe and secure way of sharing data among multiple
users.
Atomicity: This property reflects the concept of either executing the whole
query or executing nothing at all, which implies that if an update occurs in a
database then that update should either be reflected in the whole database or
should not be reflected at all.
Consistency: This property ensures that the data remains consistent before and
aer a transaction in a database.
Isolation: This property ensures that each transaction is occurring
independently of the others. This implies that the state of an ongoing
transaction doesn’t aﬀect the state of another ongoing transaction.
Durability: This property ensures that the data is not lost in cases of a system
failure or restart and is present in the same state as it was before the system
failure or restart.",easy,
410,Database,"Are NULL values in a database the same as that of blank space
or zero?","No, a NULL value is very diﬀerent from that of zero and blank space as it represents a
value that is assigned, unknown, unavailable, or not applicable as compared to blank
space which represents a character and zero represents a number.
Example: NULL value in “number_of_courses” taken by a student represents that its
value is unknown whereas 0 in it means that the student hasn’t taken any courses.",easy,
411,Database,What is meant by Data Warehousing?,"The process of collecting, extracting, transforming, and loading data from multiple
sources and storing them into one database is known as data warehousing. A data
warehouse can be considered as a central repository where data flows from
transactional systems and other relational databases and is used for data analytics. A
data warehouse comprises a wide variety of organization’s historical data that
supports the decision-making process in an organization.",medium,
412,Database,Explain diﬀerent levels of data abstraction in a DBMS.,"The process of hiding irrelevant details from users is known as data abstraction. Data
abstraction can be divided into 3 levels:
Physical Level: it is the lowest level and is managed by DBMS. This level
consists of data storage descriptions and the details of this level are typically
hidden from system admins, developers, and users.
Conceptual or Logical level: it is the level on which developers and system
admins work and it determines what data is stored in the database and what is
the relationship between the data points.
External or View level: it is the level that describes only part of the database
and hides the details of the table schema and its physical storage from the users.
The result of a query is an example of View level data abstraction. A view is a
virtual table created by selecting fields from one or more tables present in the
database.",medium,
413,Database,"What is meant by an entity-relationship (E-R) model?
Explain the terms Entity, Entity Type, and Entity Set in
DBMS.","An entity-relationship model is a diagrammatic approach to a database design where
real-world objects are represented as entities and relationships between them are
mentioned.
Entity: An entity is defined as a real-world object having attributes that
represent characteristics of that particular object. For example, a student, an
employee, or a teacher represents an entity.
Entity Type: An entity type is defined as a collection of entities that have the
same attributes. One or more related tables in a database represent an entity
type. Entity type or attributes can be understood as a characteristic which
uniquely identifies the entity. For example, a student represents an entity that
has attributes such as student_id, student_name, etc.
Entity Set: An entity set can be defined as a set of all the entities present in a
specific entity type in a database. For example, a set of all the students,
employees, teachers, etc. represent an entity set.",medium,
414,Database,"Explain diﬀerent types of relationships amongst tables in a
DBMS.","Following are diﬀerent types of relationship amongst tables in a DBMS system:

One to One Relationship: This type of relationship is applied when a particular
row in table X is linked to a singular row in table Y.
One to Many Relationship: This type of relationship is applied when a single
row in table X is related to many rows in table Y.
Many to Many Relationship: This type of relationship is applied when multiple
rows in table X can be linked to multiple rows in table Y.
Self Referencing Relationship: This type of relationship is applied when a
particular row in table X is associated with the same table.",medium,
415,Database,"Explain the diﬀerence between intension and extension in a
database.","Following is the major diﬀerence between intension and extension in a database:

Intension: Intension or popularly known as database schema is used to define
the description of the database and is specified during the design of the
database and mostly remains unchanged.
Extension: Extension on the other hand is the measure of the number of tuples
present in the database at any given point in time. The extension of a database
is also referred to as the snapshot of the database and its value keeps changing
as and when the tuples are created, updated, or destroyed in a database.",medium,
416,Database,"Explain the diﬀerence between the DELETE and TRUNCATE
command in a DBMS.","DELETE command: this command is needed to delete rows from a table based on
the condition provided by the WHERE clause.
It deletes only the rows which are specified by the WHERE clause.
It can be rolled back if required.
It maintains a log to lock the row of the table before deleting it and hence it’s
slow.
TRUNCATE command: this command is needed to remove complete data from a
table in a database. It is like a DELETE command which has no WHERE clause.
It removes complete data from a table in a database.
It can be rolled back even if required.
It doesn’t maintain a log and deletes the whole table at once and hence it’s fast.",medium,
417,Database,"What is a lock. Explain the major diﬀerence between a
shared lock and an exclusive lock during a transaction in a
database.","A database lock is a mechanism to protect a shared piece of data from getting
updated by two or more database users at the same time. When a single database
user or session has acquired a lock then no other database user or session can modify
that data until the lock is released.
Shared Lock: A shared lock is required for reading a data item and many
transactions may hold a lock on the same data item in a shared lock. Multiple
transactions are allowed to read the data items in a shared lock.
Exclusive lock: An exclusive lock is a lock on any transaction that is about to
perform a write operation. This type of lock doesn’t allow more than one
transaction and hence prevents any inconsistency in the database.",medium,
418,Database,What is meant by normalization and denormalization?,"Normalization is a process of reducing redundancy by organizing the data into
multiple tables. Normalization leads to better usage of disk spaces and makes it
easier to maintain the integrity of the database.

Denormalization is the reverse process of normalization as it combines the tables
which have been normalized into a single table so that data retrieval becomes faster.
JOIN operation allows us to create a denormalized form of the data by reversing the
normalization.",medium,
419,Database,Explain diﬀerent types of Normalization forms in a DBMS.,"Following are the major normalization forms in a DBMS:



1NF: It is known as the first normal form and is the simplest type of
normalization that you can implement in a database. A table to be in its first
normal form should satisfy the following conditions:
Every column must have a single value and should be atomic.
Duplicate columns from the same table should be removed.
Separate tables should be created for each group of related data and each
row should be identified with a unique column.

2NF: It is known as the second normal form. A table to be in its second normal
form should satisfy the following conditions:
The table should be in its 1NF i.e. satisfy all the conditions of 1NF.
Every non-prime attribute of the table should be fully functionally
dependent on the primary key i.e. every non-key attribute should be
dependent on the primary key in such a way that if any key element is
deleted then even the non_key element will be saved in the database.

3NF: It is known as the third normal form. A table to be in its second normal
form should satisfy the following conditions:
The table should be in its 2NF i.e. satisfy all the conditions of 2NF.
There is no transitive functional dependency of one attribute on any
attribute in the same table.

BCNF: BCNF stands for Boyce-Codd Normal Form and is an advanced form of
3NF. It is also referred to as 3.5NF for the same reason. A table to be in its BCNF
normal form should satisfy the following conditions:
The table should be in its 3NF i.e. satisfy all the conditions of 3NF.
For every functional dependency of any attribute A on B
(A->B), A should be the super key of the table. It simply implies that A can’t
be a non-prime attribute if B is a prime attribute.",Hard,
420,Database,Explain diﬀerent types of keys in a database.,"There are mainly 7 types of keys in a database:

Candidate Key: The candidate key represents a set of properties that can
uniquely identify a table. Each table may have multiple candidate keys. One key
amongst all candidate keys can be chosen as a primary key. In the below
example since studentId and firstName can be considered as a Candidate Key
since they can uniquely identify every tuple.
Super Key: The super key defines a set of attributes that can uniquely identify a
tuple. Candidate key and primary key are subsets of the super key, in other
words, the super key is their superset.
Primary Key: The primary key defines a set of attributes that are used to
uniquely identify every tuple. In the below example studentId and firstName are
candidate keys and any one of them can be chosen as a Primary Key. In the given
example studentId is chosen as the primary key for the student table.
Unique Key: The unique key is very similar to the primary key except that
primary keys don’t allow NULL values in the column but unique keys allow them.
So essentially unique keys are primary keys with NULL values.
Alternate Key: All the candidate keys which are not chosen as primary keys are
considered as alternate Keys. In the below example, firstname and lastname are
alternate keys in the database.
Foreign Key: The foreign key defines an attribute that can only take the values
present in one table common to the attribute present in another table. In the
below example courseId from the Student table is a foreign key to the Course
table, as both, the tables contain courseId as one of their attributes.
Composite Key: A composite key refers to a combination of two or more
columns that can uniquely identify each tuple in a table. In the below example
the studentId and firstname can be grouped to uniquely identify every tuple in
the table.",Hard,
421,Database,"Explain the diﬀerence between a 2-tier and 3-tier
architecture in a DBMS.","The 2-tier architecture refers to the client-server architecture in which applications
at the client end directly communicate with the database at the server end without
any middleware involved.
Example – Contact Management System created using MS-Access or Railway
Reservation System, etc.The 3-tier architecture contains another layer between the client and the server to
provide GUI to the users and make the system much more secure and accessible. In
this type of architecture, the application present on the client end interacts with an
application on the server end which further communicates with the database system.
Example – Designing registration form which contains a text box, label, button or a
large website on the Internet, etc.",Hard,
422,Database,"Consider the foreign-key constraint from the dept name attribute of instructor to
the department relation. Give examples of inserts and deletes to these relations
that can cause a violation of the foreign-key constraint.




","The appropriate primary keys are shown below:
",easy,https://www.mpgcamb.com/wp-content/uploads/2024/12/Abraham-Silberschatz-Henry-F.-Korth-S.-Sudarshan-Database-System-Concepts-McGraw-Hill-Education-2019.pdf
423,Database,"Consider the time slot relation. Given that a parti
ular time slot 
an meet more
than on
e in a week, explain why day and start time are part of the primary key
of this relation, while end time is not.","The attributes day and start_time are part of the primary key sinc
e a parti
ular

class will most likely meet on several diff_x000c_erent days and may even meet more
than on
ce in a day. However, end_time is not part of the primary key sin
ce a
parti
ular c
lass that starts at a parti
ular time on a parti
ular day c
annot end at
more than one time.
",easy,
424,Database,"In the instan
ce of instruc
tor shown in Figure, no two instru
ctors have the
same name. From this, 
can we 
con
lude that name 
can be used as a superkey
(or primary key) of instruc
tor?



","No. For this possible instanc
e of the instruc
tor table the names are unique, but
in general this may not always be the 
case (unless the university has a rule that
two instru
ctors 
cannot have the same name, whi
ch is a rather unlikey sc
enario).
",medium,
425,Database,"What is the result of first performing the Cartesian product of student and advisor, 
and then performing a selection operation on the result with the predicate s_id = ID? (Using the symboli notation of relational algebra, this
 query an be written as σs_id=ID(student × advisor))","The result attributes in
lude all attribute values of student followed by all attributes of advisor. The tuples in the result are as follows: For ea
h student who
has an advisor, the result has a row c
ontaining that student's attributes, followed
by an s id attribute identi
cal to the student's ID attribute, followed by the i_id
attribute c
ontaining the ID of the students advisor.
Students who do not have an advisor will not appear in the result. A student
who has more than one advisor will appear a c
orresponding number of times
in the result.",medium,
426,Database,"Consider the employee database of Figure . Give an expression in the relational algebra to express each of the following queries:
a. Find the name of eac
h employee who lives in c
ity ""Miami"".
b. Find the name of eac
h employee whose salary is greater than $100000.
c. Find the name of ea
ch employee who lives in ""Miami"" and whose salary
is greater than $100000.","a. Πperson_name(σcity=""Miami""(employee))
b. Πperson_name(σsalary>100000(employee ⋈ works))
c. Πperson_name(σcity=""Miami"" ∧ salary>100000(employee ⋈ works))
",Hard,
427,Database,"Consider the bank database of Figure. Give an expression in the relational
algebra for each of the following queries:
a. Find the name of ea
ch bran
h lo
cated in ""Chi
ago"".
b. Find the ID of eca
h borrower who has a loan in bran
ch ""Downtown"".
","a.Π_branch_name (σ_branch_city = ""Chicago"" (branch))
b.Π_ID (σ_branch_name = ""Downtown"" (borrower ⋈_borrower.loan_number=loan.loan_number loan))
",hard,
428,Database,"Consider the employee database of Figure . Give an expression in the relational algebra to express eah of the following queries:
a. Find the ID and name of ea
ch employee who does not work for ""BigBank"".
b. Find the ID and name of eac
h employee who earns at least as muc
h as
every employee in the database.","a. To find employees who do not work for BigBank, we first find all those
who do work for BigBank. Those are exa
ctly the employees not part of the desired result. We then use set di_x000c_efferenc
e to find the set of all employees
minus those employees that should not be in the result.
Π_{ID,person_name}(employee) − Π_{ID,person_name}(employee ⋈_{employee.ID=works.ID} (σ_{company_name='BigBank'}(works)))
b.We use the same approac
h as in part a by first finding those employess
who do not earn the highest salary, or, said di_x000c_erently, for whom some
other employee earns more. Sinc
e this involves c
omparing two employee
salary values, we need to referen
e the employee relation twi
e and therefore use renaming.
Π_{ID,person_name}(employee) − Π_{A.ID,A.person_name}(ρ_A(employee) ⋈_{A.salary<B.salary} ρ_B(employee))
",hard,
429,Database,"Write the following queries in SQL, using the university s
schema shown in the figure
a. Find the titles of 
courses in the Comp. Sci. department that have 3 credits.
b. Find the IDs of all students who were taught by an instru
tor named Einstein; make sure there are no dupli
ates in the result.

c. Find the highest salary of any instruc
tor.
d. Find all instructors earning the highest salary (there may be more than
one with the same salary).
e. Find the enrollment of each section that was o_x000c_ered in Fall 2017.
f. Find the maximum enrollment, a
cross all setcions, in Fall 2017.
g. Find the sections that had the maximum enrollment in Fall 2017.
","a. Find the titles of courses in the Comp. S
i. department that have 3 
redits.
select title
from 
course
where dept_name = 'Comp. Sci.' and 
credits = 3
b.Find the IDs of all students who were taught by an instru
tor named Einstein; make sure there are no dupli
ates in the result.
This query 
an be answered in several di_x000c_erent ways. One way is as follows.
select distin
ct takes.ID
from takes, instruc
tor, tea
ches
where takes.
course_id = teac
hes.
course_id and
takes.se
c_id = teac
hes.se
c_id and
takes.semester = teac
hes.semester and
takes.year = tea
ches.year and
tea
ches.id = instruc
tor.id and
instruc
tor.name = 'Einstein'
c. Find the highest salary of any instruc
tor.
selec
t max(salary)
from instruc
tor


d. Find all instru
ctors earning the highest salary (there may be more than
one with the same salary).
select ID, name
from instructor
where salary = (selec
t max(salary) from instruc
tor)
e. Find the enrollment of eac
h sec
tion that was o_x000c_ffered in Fall 2017
sele
t 
course id, sec
_id,
(sele
ct c
ount(ID)
from takes
where takes.year = se
ction.year
and takes.semester = se
ction.semester
and takes.
course id = se
tion.
course id
and takes.se
c_id = se
ction.se
c_id)
as enrollment
from se
ction
where semester = 'Fall'
and year = 2017
f. Find the maximum enrollment, a
cross all sec
tions, in Fall 2017.
One way of writing this query is as follows:
selec
t max(enrollment)
from (selec
t 
count(ID) as enrollment
from sec
tion, takes
where takes.year = sec
tion.year
and takes.semester = sec
tion.semester
and takes.
course id = sec
tion.c
ourse id
and takes.se
c_id = se
ction.sec
_id
and takes.semester = 'Fall'
and takes.year = 2017
group by takes.
course_id, takes.sec
_id)
As an alternative to using a nested subquery in the from 
lause, it is pos_x0002_sible to use a with 
lause, as illustrated in the answer to the next part of
this question.
A subtle issue in the above query is that if no se
tion had any enrollment, the answer would be empty, not 0. We 
an use the alternative using
a subquery, from the previous part of this question, to ensure the 
count is
0 in this 
case.

g. Find the sec
tions that had the maximum enrollment in Fall 2017.
The following answer uses a with 
clause, simplifying the query.

with se
_enrollment as (
selec
t takes.
course_id, takes.sec
_id, c
ount(ID) as enrollment
from sec
tion, takes
where takes.year = sec
tion.year
and takes.semester = se
ction.semester
and takes.
course id = se
tion.c
ourse id
and takes.se
c_id = se
ction.sec
_id
and takes.semester = 'Fall'
and takes.year = 2017
group by takes.c
ourse_id, takes.sec
_id)
sele
ct c
ourse_id, sec
_id
from sec
_enrollment
where enrollment = (selec
t max(enrollment) from se
c_enrollment)
It is also possible to write the query without the with 
clause, but the sub-query to fnd enrollment would get repeated twi
e in the query.
While not in
corre
t to add distinc
t in the c
ount, it is not ne
cessary in light
of the primary key 
constraint on takes.


",easy,
430,Database,What is a Database Schema and Why is It Important?,"A database schema is a blueprint or architecture of how data is organized in a database. It defines the tables, the fields in each table, and the relationships between fields and tables.

A schema is important because it provides a clear structure for the data, ensuring consistency, clarity, and integrity. It helps developers and database administrators understand how data is connected and how to retrieve and manipulate it efficiently.",easy,Top 50 Database Interview Questions and Answers for 2025 - GeeksforGeeks
431,Database,Explain the Difference Between a Primary Key and a Foreign Key.,"Primary Key: Uniquely identifies each record in a table and ensures data integrity. Each table can have only one primary key, and it ensures that each record in the table is unique.
Foreign Key: A foreign key, on the other hand, links one table to another by referencing the primary key in the related table. This relationship helps maintain referential integrity between the tables, ensuring that the link between them is valid and that the data is consistent.",,
432,Database,What is CRUD Operations?,"CRUD stands for Create, Read, Update, Delete, which are the four fundamental operations in database management:

Create: Use the INSERT INTO statement to add new records to a table.
Read: Use the SELECT statement to retrieve data from a table.
Update: Use the UPDATE statement to modify existing records.
Delete: Use the DELETE FROM statement to remove records.",,
433,Database,What are the Different Types of Joins and How do They Work?,"Inner Join: Retrieves records with matching values in both tables.
Left Join (Left Outer Join): Retrieves all records from the left table and matched records from the right table. Unmatched records from the right table will be NULL.
Right Join (Right Outer Join): Retrieves all records from the right table and matched records from the left table. Unmatched records from the left table will be NULL.
Full Join (Full Outer Join): Retrieves records when there is a match in either left or right table. Unmatched records from both tables will be NULL.",,
434,Database,How to Ensure Data Integrity in a Relational Database?,"Ensuring data integrity involves using constraints and rules:

Primary Keys: To ensure unique records.
Foreign Keys: To enforce relationships between tables.
Unique Constraints: To ensure all values in a column are distinct.
Not Null Constraints: To prevent empty fields.
Check Constraints: To validate data against defined rules.
Transactions: To guarantee the successful execution of a group of operations.",,
435,Database,Explain the Difference Between OLTP and OLAP Databases.,"OLTP (Online Transaction Processing): Databases designed for managing transaction-oriented applications. They are optimized for a large number of short online transactions (insert, update, delete). Example: Retail sales systems.
OLAP (Online Analytical Processing): Databases designed for querying and reporting, often used for data analysis and business intelligence. They are optimized for read-heavy operations on large volumes of data. Example: Data warehousing.",,
436,Database,What are the ACID Properties in a Database and Why are They Important?,"ACID properties ensure reliable transaction processing, guarantee data reliability and integrity in databases.

Atomicity: Ensures that all operations within a transaction are completed successfully; otherwise, the transaction is aborted.
Consistency: Ensures that a transaction brings the database from one valid state to another.
Isolation: Ensures that transactions are executed independently without interference.
Durability: Ensures that the results of a transaction are permanently stored in the database, even in case of a system failure.",,
437,Database,"Describe the Process of ETL (Extract, Transform, Load).","ETL is a process used to move data from various sources into a data warehouse:

Extract: Collecting data from different source systems.
Transform: Converting the extracted data into a suitable format or structure for querying and analysis. This might involve cleaning the data, removing duplicates, and ensuring data consistency.
Load: Inserting the transformed data into the target data warehouse or database.",,
438,Database,What is a Data Warehouse and How is it Different from a Traditional Database?,"A data warehouse is a central repository for storing large volumes of data from multiple sources, designed for query and analysis rather than transaction processing. It supports complex queries, data mining, and business intelligence.
Unlike traditional databases optimized for day-to-day operations and transaction processing (OLTP), data warehouses are optimized for read-heavy operations, historical data analysis, and large-scale data aggregation (OLAP).",,
439,Database,How to Handle Data Migration Between Different Databases?,"Steps for Data Migration:

Planning: Assess the source and target databases, and create a detailed migration plan.
Mapping: Define how data from the source will map to the target database, including any transformations needed.
Extracting: Extract data from the source database.
Transforming: Convert the data to match the target schema, clean, and validate it.
Loading: Load the transformed data into the target database.
Testing: Verify the migration to ensure data integrity and consistency.
Monitoring: Monitor the new system to ensure it is functioning correctly.",,
440,Database,What is a Relational Database and How does it Differ from a NoSQL Database?,"A relational databases uses structured tables to store data, with predefined schemas and relationships (usually using SQL). It ensures data integrity through ACID properties and is suitable for complex queries and transactions.

A NoSQL database, on the other hand, is designed for unstructured or semi-structured data and can store data in various formats like key-value pairs, documents, or graphs. NoSQL databases are often more flexible and scalable, suitable for big data and real-time web applications, but they might not provide the same level of ACID compliance as relational databases.",,
441,Database,Explain the Importance of Data Normalization.,"Data normalization is the process of organizing data to minimize redundancy and improve data integrity. It involves dividing a database into smaller tables and defining relationships between them. Normalization is important because it:

Reduces data duplication.
Ensures data consistency.
Simplifies the structure, making it easier to maintain and update.
Improves query performance by eliminating unnecessary data.",,
442,Database,How to Perform Data Cleaning and Preprocessing?,"Data Cleaning and Preprocessing in SQL can Involve Several Steps:

Removing duplicates: Use the DISTINCT keyword or ROW_NUMBER() window function.
Handling missing values: Use functions like COALESCE to replace NULL values.
Correcting data types: Use the CAST or CONVERT functions.
Standardizing formats: Use string functions like LOWER, UPPER, TRIM, etc.",,
443,Database,What are the Common SQL Functions Used for Data Aggregation?,"SUM(): Calculates the total sum of a numeric column.
AVG(): Calculates the average value of a numeric column.
COUNT(): Counts the number of rows that match a specified condition.
MIN(): Finds the minimum value in a column.
MAX(): Finds the maximum value in a column.",,
444,Database,Describe the Process of Connecting a Database to a Data Analysis Tool.,"Connecting a database to a data analysis tool generally involves the following steps:

Choose the Data Source: Select the type of database you want to connect to (e.g., MySQL, PostgreSQL, SQL Server).
Install the necessary drivers: Ensure the data analysis tool has the correct drivers to connect to the database.
Configure the Connection: Provide the connection details such as database server address, port number, database name, username, and password.
Test the Connection: Verify that the connection settings are correct and that the tool can successfully connect to the database.
Load Data: Import or query the data within the tool for analysis.
Analyze Data: Use the tool’s features to perform data analysis, create visualizations, and generate reports.",,
445,Database,Explain the Concept of Database Transactions and Their Importance in Application Development.,"A database transaction is a sequence of operations performed as a single logical unit of work. These operations must adhere to the ACID properties:

Atomicity: All operations must succeed or none are applied.
Consistency: Ensures the database remains in a valid state.
Isolation: Prevents interference from other concurrent transactions.
Durability: Guarantees the results are permanently stored.
Transactions are important in application development because they help maintain data consistency, especially in scenarios involving multiple, concurrent users. For example, if a transaction involves transferring money from one bank account to another, it ensures that either both accounts are updated correctly or neither is, preventing any inconsistency in the financial records.",Medium,
446,Database,How to Optimize Database Queries for Performance?,"Optimizing database queries involves several strategies:

Indexing: Create indexes on columns that are frequently used in WHERE, JOIN, and ORDER BY clauses to speed up data retrieval.
Avoiding Select : Only select the columns you need to reduce the amount of data processed.
Query Refactoring: Rewrite complex queries for better performance, such as breaking them into simpler subqueries or using joins efficiently.
Analyzing Execution Plans: Use tools to analyze and understand the query execution plan, identifying bottlenecks.
Database Configuration: Ensure the database is configured correctly with adequate resources (memory, CPU).
Archiving Old Data: Regularly archive or delete old, unused data to keep tables manageable.",,
447,Database,What are Stored Procedures and When would we Use Them?,"Stored procedures are precompiled collections of SQL statements stored in the database. They :

Encapsulate complex SQL queries and business logic.
Improve performance by reducing network traffic (client-server round trips).
Enhance security by controlling access to data through parameterized queries.
Ensure consistency and reusability across multiple applications.
Stored procedures are particularly useful when performing repetitive tasks such as data validation, business rule enforcement, or batch processing.",,
448,Database,Describe the Process of Database Normalization and Denormalization.,"Normalization involves organizing database tables to reduce redundancy and improve data integrity. It typically follows these steps:

First Normal Form (1NF): Ensure each table column contains atomic (indivisible) values.
Second Normal Form (2NF): Ensure that all non-key columns are fully dependent on the primary key.
Third Normal Form (3NF): Ensure that all columns are only dependent on the primary key and not on other non-key columns.
Denormalization is the process of combining normalized tables to improve read performance, often at the expense of write performance and increased redundancy. Denormalization is used when read performance is critical, and the application can handle data redundancy and potential update anomalies.",,
449,Database,How to Handle Concurrent Data Access and Prevent Deadlocks?,"Handling concurrent data access and preventing deadlocks involves:

Locking Mechanisms: Using appropriate locking strategies (e.g., row-level locks) to prevent conflicts.
Transaction Isolation Levels: Adjusting isolation levels (e.g., Read Committed, Repeatable Read) to balance consistency and concurrency.
Deadlock Detection: Implementing deadlock detection mechanisms provided by the database to automatically identify and resolve deadlocks.
Optimizing Transactions: Keeping transactions short and simple to reduce the likelihood of deadlocks.
Ordering Access: Ensuring that transactions access resources in a consistent order to minimize deadlock risk.",,
450,Database,Explain the Concept of Database Indexing and its Importance in Query Performance.,"Database indexing involves creating a data structure that improves the speed of data retrieval operations on a table at the cost of additional writes and storage space. Indexes are important because they:

Speed Up Queries: Significantly reduce the time required to retrieve data by allowing the database to find rows more efficiently.
Support Sorting and Searching: Improve performance of operations involving sorting and searching, such as ORDER BY and WHERE clauses.
Enhance Join Performance: Speed up joins between tables by quickly locating matching rows.",,
451,Database,What are the Different types of Database Partitioning and When would we Use Each Type?,"Horizontal Partitioning: Divides a table into multiple tables with the same structure, distributing rows based on a range or list of values. Used to improve performance and manageability by spreading the data across multiple storage locations.
Vertical Partitioning: Divides a table into multiple tables based on columns. Commonly used to separate frequently accessed columns from less frequently accessed ones, improving query performance for the former.
Range Partitioning: Divides data based on a range of values in a specific column, useful for date-based partitions (e.g., monthly partitions).
Hash Partitioning: Distributes data across partitions using a hash function, ensuring an even distribution of data. Used when data distribution needs to be uniform.
List Partitioning: Divides data based on a predefined list of values, useful for categorizing data into distinct groups.",,
452,Database,Describe the Role of a Data Lake in a Big Data Architecture.,"A data lake is a centralized repository that allows us to store all your structured and unstructured data at any scale. Data lakes are essential for big data projects because they provide a flexible and cost-effective way to manage and analyze vast amounts of data. In a big data architecture, a data lake:

Stores Raw Data: Allows for the storage of raw, unprocessed data from various sources.
Supports Multiple Data Types: Handles structured, semi-structured, and unstructured data.
Enables Advanced Analytics: Facilitates data exploration, machine learning, and advanced analytics.
Scales Easily: Provides scalable storage and processing power.",,
453,Database,How to Ensure Data Quality and Integrity During Data Ingestion?,"Ensuring data quality and integrity during data ingestion involves:

Data Validation: Implementing validation checks to ensure data conforms to predefined rules and formats.
Data Cleansing: Removing duplicates, correcting errors, and handling missing values before data is ingested.
Schema Enforcement: Ensuring the incoming data matches the schema of the target database or data warehouse.
Consistency Checks: Verifying data consistency across different data sources.
Error Handling: Implementing robust error handling mechanisms to address data ingestion failures and anomalies.
Monitoring and Auditing: Continuously monitoring data ingestion processes and maintaining audit logs to track data quality issues.",,
454,Database,What are the Common Data Storage Formats Used in Big Data Processing?,"Common data storage formats in big data processing include:

CSV (Comma-Separated Values): Simple text format for tabular data.
JSON (JavaScript Object Notation): Lightweight data interchange format, good for semi-structured data.
Parquet: Columnar storage format optimized for query performance and efficient storage.
Avro: Row-based storage format, excellent for data serialization.
ORC (Optimized Row Columnar): Columnar storage format that provides high compression and fast query performance.
These formats are chosen based on factors like data structure, storage efficiency, and read/write performance.",,
455,Database,How to Join Multiple Tables to Create a Comprehensive Dataset for Analysis?,"Joining multiple tables in SQL is typically done using different types of joins:

Inner Join: Returns rows with matching values in both tables.
Left Join: Returns all rows from the left table and matched rows from the right table, with NULL for unmatched rows.
Right Join: Returns all rows from the right table and matched rows from the left table, with NULL for unmatched rows.
Full Outer Join: Returns rows when there is a match in either table, with NULL for unmatched rows.",,
456,Database,Explain the Concept of Window Functions and Their Applications.,"Window functions perform calculations across a set of table rows related to the current row, unlike aggregate functions that group rows into a single output row. They are used for

Ranking: Assigning ranks to rows (RANK(), DENSE_RANK()).
Running totals: Calculating cumulative sums (SUM() OVER).
Moving averages: Computing averages over a range of rows (AVG() OVER).
Lag/Lead: Accessing data from previous or subsequent rows.",,
457,Database,How to Handle Missing Data in a Database?,"Handling missing data in a database can involve:

Ignoring: Skipping rows with missing values during analysis.
Imputing: Replacing missing values with a default value, mean, median, or a value derived from other data.
Deletion: Removing rows or columns with a high percentage of missing values.
Using Placeholders: Marking missing values with a specific placeholder (e.g., NULL).",,
458,Database,Describe the Process of Feature Engineering using SQL.,"Feature engineering involves creating new features or modifying existing ones to improve the performance of machine learning models. Using SQL:

Aggregations: Creating summary features like total, average, count.
Transformations: Applying mathematical transformations (log, square root) to existing features.
Bin/Group Data: Categorizing continuous variables into bins.
Date Features: Extracting parts of dates (year, month, day).",,
459,Database,What are the Performance Considerations When Qerying Large Datasets?,"When querying large datasets, consider

Indexing: Ensure appropriate indexes are in place to speed up query execution.
Partitioning: Use table partitioning to manage large tables more efficiently.
Query Optimization: Write efficient queries, avoid unnecessary calculations and joins.
Avoiding Select : Select only necessary columns to reduce data volume.
Batch Processing: Process data in batches to avoid overloading the system.
Caching: Use caching mechanisms to store frequently accessed data.
Database Configuration: Ensure the database is properly configured with adequate resources.",,
460,Database,How to Design a Database Schema for a Highly Scalable Web Application?,"Designing a database schema for a highly scalable web application involves several key considerations:

Normalization and Denormalization: Start with a normalized schema to reduce redundancy and improve data integrity, then denormalize selectively for read-heavy operations to improve performance.
Sharding: Distribute data across multiple database instances (shards) to handle large volumes of data and high transaction rates.
Indexing: Create indexes on frequently queried columns to speed up data retrieval.
Read/Write Separation: Use master-slave replication to separate read and write operations, with writes going to the master and reads going to replicated slaves.
Partitioning: Use horizontal or vertical partitioning to manage large tables and improve query performance.
Caching: Implement caching strategies to reduce database load (e.g., using Redis or Memcached).
Use of NoSQL: For certain use cases, consider NoSQL databases (e.g., MongoDB, Cassandra) which can offer better scalability for specific data types and access patterns.",Hard,
461,Database,Explain the Use of Caching Strategies to Improve Database Performance.,"Caching strategies improve database performance by storing frequently accessed data in a temporary storage layer to reduce load on the database:

In-Memory Caching: Tools like Redis store data in memory for quick access, reducing the need to query the database.
Query Caching: Cache the results of complex queries that don’t change often.
Page Caching: Cache entire web pages or parts of pages to avoid hitting the database for every page load.
Object Caching: Cache objects in the application layer to avoid repeated database calls.
Write-Through Cache: Data is written to both the cache and the database simultaneously, ensuring consistency.
Write-Back Cache: Data is written to the cache first, then asynchronously to the database, improving write performance but requiring mechanisms to ensure eventual consistency.",Hard,
462,Database,Describe the Process of Implementing Database Security and Encryption.,"Implementing database security and encryption involves several steps:

Authentication and Authorization: Ensure strong authentication mechanisms are in place and assign least privilege access to users.
Encryption in Transit: Use TLS/SSL to encrypt data transmitted between the database and clients.
Encryption at Rest: Encrypt data stored on disk using database-native encryption features or file system encryption.
Access Controls: Implement role-based access controls to restrict access to sensitive data.
Audit Logs: Maintain audit logs of database access and changes to monitor suspicious activities.
Data Masking: Mask sensitive data in non-production environments to protect privacy.
Backup Security: Ensure backups are encrypted and stored securely.",Hard,
463,Database,How to Handle Database Migrations in a Continuous Deployment Environment?,"Handling database migrations in a continuous deployment environment involves:

Version Control: Use a version control system for database schema changes.
Migration Tools: Utilize migration tools (e.g., Flyway, Liquibase) to automate the application of schema changes.
Backward Compatibility: Design migrations to be backward compatible to ensure the application remains functional during the deployment.
Schema Versioning: Maintain schema versioning to track changes and allow rollbacks if necessary.
Staging Environment: Test migrations in a staging environment before deploying to production.
Transactional Migrations: Use transactions to apply migrations to ensure atomicity and consistency.
Monitoring: Monitor the deployment for issues and have a rollback plan in place.",Hard,
464,Database,What Are the Best Practices for Database Testing and Ensuring Data Consistency?,"Best practices for database testing and ensuring data consistency include:

Unit Testing: Write unit tests for database functions and stored procedures.
Integration Testing: Test the database as part of the application integration to ensure it works correctly with other components.
Data Validation: Validate data integrity constraints (e.g., foreign keys, unique constraints).
Automated Testing: Use automated testing tools to run tests regularly.
Mock Databases: Use mock databases for testing to avoid affecting production data.
Data Consistency Checks: Regularly check for data consistency using tools or custom scripts.
Rollback Testing: Test rollback procedures to ensure that data can be restored in case of a failed migration or update.",Hard,
465,Database,Explain the Concept of Data Replication and Its Importance in a Distributed Database System.,"Data replication involves copying data from one database server to another to ensure consistency and availability across distributed systems. Its importance includes:

High Availability: Ensures that data is available even if one server fails.
Load Balancing: Distributes the load across multiple servers, improving performance.
Disaster Recovery: Provides a backup in case of a data loss or corruption.
Geographical Distribution: Allows data to be closer to users in different regions, reducing latency.",Hard,
466,Database,How to Design a Database for High Availability and Disaster Recovery?,"Designing a database for high availability and disaster recovery involves:

Replication: Implement master-slave or master-master replication to ensure data redundancy.
Failover Mechanisms: Set up automatic failover to switch to a standby database in case of a failure.
Regular Backups: Perform regular backups and store them securely.
Geographical Redundancy: Distribute data across multiple geographical locations to protect against regional failures.
Monitoring: Continuously monitor database health and performance.
Disaster Recovery Plan: Develop and test a comprehensive disaster recovery plan.
Use of Cloud Services: Leverage cloud database services that offer built-in high availability and disaster recovery features.",Hard,
467,Database,Describe the Architecture of a NoSQL Database and Its Use Cases.,"NoSQL databases are designed to handle large volumes of unstructured or semi-structured data. Common architectures include:

Document Stores: Store data as documents (e.g., JSON, BSON). Example: MongoDB. Use cases: Content management, user profiles.
Key-Value Stores: Store data as key-value pairs. Example: Redis. Use cases: Caching, session storage.
Column-Family Stores: Store data in columns rather than rows. Example: Cassandra. Use cases: Time-series data, real-time analytics.
Graph Databases: Store data as nodes and edges. Example: Neo4j. Use cases: Social networks, recommendation engines.",Hard,
468,Database,What Are the Best Practices for Optimizing ETL Processes in a Large-Scale Data Environment?,"Best practices for optimizing ETL processes include:

Incremental Loading: Only process new or changed data to reduce load.
Parallel Processing: Use parallel processing to speed up ETL jobs.
Efficient Data Transformations: Optimize transformation logic to minimize processing time.
Data Partitioning: Partition large datasets to improve performance.
Batch Processing: Process data in batches to manage resource usage.
Monitoring and Logging: Monitor ETL processes and maintain logs to identify and resolve issues quickly.
Resource Allocation: Allocate sufficient resources (CPU, memory) to ETL processes.",Hard,
469,Database,How Do You Handle Real-Time Data Streaming and Processing?,"Handling real-time data streaming and processing involves:

Streaming Frameworks: Use frameworks like Apache Kafka, Apache Flink, or Apache Spark Streaming to process real-time data.
Data Ingestion: Ingest data from various sources (e.g., IoT devices, social media) in real time.
Data Processing: Apply transformations, aggregations, and enrichments in real time.
Low-Latency Storage: Store processed data in low-latency databases (e.g., Redis, Cassandra).
Scalability: Ensure the system can scale horizontally to handle varying data loads.
Fault Tolerance: Implement fault-tolerant mechanisms to ensure continuous data processing.
Monitoring: Continuously monitor the streaming process for performance and errors.",Hard,
470,Database,How to Design a Scalable and High-Performance Database for an E-Commerce Application?,"To design a scalable and high-performance database for an e-commerce application:

Normalize the database to reduce redundancy and maintain integrity.
Sharding: Distribute data across multiple servers to manage high traffic and storage.
Indexing: Optimize queries by indexing key fields like product names and user IDs.
Caching: Use Redis or Memcached to store frequently accessed data.
NoSQL Databases: Leverage NoSQL solutions like MongoDB for flexibility in specific use cases.
Cloud-based Services: Utilize scalable cloud platforms for efficient data storage and management.",Hard,
471,Database,How to Diagnose and Resolve Slow Database Queries?,"Steps to diagnose and resolve slow queries:

Use tools like EXPLAIN to analyze query execution plans and identify inefficiencies.
Ensure indexes are created on columns used in WHERE, JOIN, and ORDER BY clauses.
Monitor server resources (CPU, memory, disk usage) to identify bottlenecks.
Rewrite and simplify complex queries to minimize joins and reduce data retrieval volume
.
Optimize database configurations and consider upgrading hardware if needed.",Hard,
472,Database,What Are the Key Steps for Migrating Data From On-Premise to a Cloud Database?,"To migrate data from an on-premise database to a cloud database:

Assessment: Evaluate the current schema, data volume, and compatibility with the cloud database.
Cloud Selection: Choose a provider and database type that aligns with your application needs.
Encryption: Secure data transfer using encryption protocols.
Migration Tools: Use cloud-native or third-party tools for efficient data transfer.
Validation: Test the migration in a staging environment to detect and resolve issues.
Scheduled Migration: Perform migration during off-peak hours to minimize disruption.
Monitoring: Track the cloud database’s performance post-migration.",Hard,
473,Database,How to Implement a Backup and Recovery Strategy for a Mission-Critical Database?,"Implementing a backup and recovery strategy for a mission-critical database involves several critical steps.

Regularly schedule full and incremental backups to minimize data loss in case of failures.
Store backups securely, both on-site and off-site or in the cloud, to protect against physical disasters.
Utilize automated backup solutions to ensure consistency and reliability.
Test backup and recovery procedures regularly to verify their effectiveness.
Implement point-in-time recovery options to restore the database to a specific point before an incident occurred.
Train staff on recovery processes to respond swiftly during emergencies.",Hard,
474,Database,How to Ensure Data Consistency Across Multiple Distributed Databases?,"Ensuring data consistency across multiple distributed databases requires careful planning and implementation.

Employ distributed transaction management protocols that support ACID (Atomicity, Consistency, Isolation, Durability) properties.
Implement data replication strategies with conflict resolution mechanisms to synchronize data changes across databases.
Monitor and audit data consistency regularly using automated tools to detect and resolve discrepancies promptly.
Design applications with eventual consistency in mind, where temporary inconsistencies are acceptable and resolve over time based on application requirements and use cases.",Hard,
475,Database,How to Manage Database Schema Changes to Minimize Downtime and Avoid Data Loss?,"Managing database schema changes to minimize downtime and avoid data loss involves several best practices.

Begin by thoroughly planning and testing schema changes in a development or staging environment.
Use tools that support schema versioning and migration, allowing for rollback capabilities if needed.
Implement changes during maintenance windows or off-peak hours to minimize disruption to users.
Communicate changes effectively with stakeholders and ensure backup procedures are in place before making any modifications.
Monitor the deployment closely and be prepared to quickly revert changes if unforeseen issues arise to maintain data integrity.",Hard,
476,Database,How to Design a Database for Real-Time Analytics on Transactional Data?,"Designing a database for real-time analytics on transactional data involves creating a hybrid architecture that supports both OLTP (Online Transaction Processing) and OLAP (Online Analytical Processing) capabilities.
Use a real-time data streaming platform like Apache Kafka to capture and ingest transactional data continuously.
Load data into a data warehouse optimized for analytics, using columnar storage and indexing for fast query performance.
Implement caching mechanisms for frequently accessed analytical data.
Ensure the database schema is designed to handle complex queries and aggregations efficiently.
Utilize in-memory databases or caching solutions for rapid data retrieval and analysis.",Hard,
477,Database,How to Secure Sensitive Data Within a Database?,"Securing sensitive data within a database requires implementing robust security measures. Start by using strong authentication and authorization mechanisms to control access to sensitive data based on roles and privileges. Encrypt sensitive data both at rest and in transit using encryption standards like AES (Advanced Encryption Standard).

Implement data masking techniques to obfuscate sensitive information in non-production environments. Regularly audit database access logs for unauthorized activities and anomalies. Utilize database security features such as fine-grained access controls, Transparent Data Encryption (TDE), and key management services provided by cloud providers.",Hard,
478,Database,"How to Optimize a Complex SQL Query, and What Was the Outcome?","Optimizing Steps:

Analyze the execution plan to identify bottlenecks (e.g., missing indexes, expensive joins).
Refactor queries to reduce the number of operations or simplify logic.
Create or modify indexes on frequently queried columns.
Optimize the schema design if necessary.
Outcome: Query execution time was reduced from several seconds to milliseconds, resulting in improved application performance and user experience.",Hard,
479,Database,How to Implement a Logging Mechanism for Database Changes?,"Implementing a logging mechanism for database changes involves using database triggers to capture data manipulation language (DML) events such as INSERT, UPDATE, and DELETE operations.
Store captured change data in dedicated audit tables within the database, including details like timestamps, user IDs, and affected rows.
Use technologies like Apache Kafka for streaming change logs to external systems for further analysis or archival purposes.
Ensure the logging mechanism is designed to be lightweight and efficient to minimize impact on database performance.
Regularly review and analyze change logs to monitor database activity and maintain data integrity.",Hard,
480,Database," SSDs can be used as a storage layer between memory and magnetic disks, with some parts of the database (e.g., some relations) stored on SSDs and the rest on magnetic disks. Alternatively, SSDs can be used as a buffer or cache for magnetic disks; frequently used blocks would reside on the SSD layer, while infrequently used blocks would reside on magnetic disk.
 a. Which of the two alternatives would you choose if you need to support real-time queries that must be answered within a guaranteed short period of time? Explain why.
 b. Which of the two alternatives would you choose if you had a very large customer relation, where only some disk blocks of the relation are accessed frequently, with other blocks rarely accessed?","In the first case, SSD as storage layer is better since performance is guaranteed. With SSD as cache, some requests may have to read from magnetic disk, causing delays.
 In the second case, since we don't know exactly which blocks are frequently accessed at a higher level, it is not possible to assign part of the relation to SSD. Since the relation is very large, it is not possible to assign all of the relation to SSD. The SSD as cache option will work better in this case.",,
481,Database," Some databases use magnetic disks in a way that only sectors in outer tracks are used, while sectors in inner tracks are left unused. What might be the benefits of doing so?","The disk's data-transfer rate will be greater on the outer tracks than the inner tracks. This is because the disk spins at a constant rate, so more sectors pass underneath the drive head in a given amount of time when the arm is positioned on an outer track than when on an inner track. Even more importantly, by using only outer tracks, the disk arm movement is minimized, reducing the disk access latency. This aspect is important for transaction-processing systems, where latency affects the transaction-processing rate.",,
482,Database," Flash storage:
 a. How is the flash translation table, which is used to map logical page numbers to physical page numbers, created in memory?
 b. Suppose you have a 64-gigabyte flash storage system, with a 4096-byte page size. How big would the flash translation table be, assuming each page has a 32-bit address, and the table is stored as an array?
 c. Suggest how to reduce the size of the translation table if very often long ranges of consecutive logical page numbers are mapped to consecutive physical page numbers.","a. It is stored as an array containing physical page numbers, indexed by logical page numbers. This representation gives an overhead equal to the size of the page address for each page.
 b. It takes 32 bits for every page or every 4096 bytes of storage. Hence, it takes 64 megabytes for the 64 gigabytes of flash storage.
 c. If the mapping is such that every p consecutive logical page numbers are mapped to p consecutive physical pages, we can store the mapping of the first page for every p pages. This reduces the in-memory structure by a factor of p. Further, if p is an exponent of 2, we can avoid some of the least significant digits of the addresses stored.",,
483,Database," Consider the following data and parity-block arrangement on four disks:
 Disk 1 Disk 2 Disk 3 Disk 4
 B1 P1 B8 ...
 B2 B5 P2 ...
 B3 B6 B9 ...
 B4 B7 B10 ...
 The Bi's represent data blocks; the Pi's represent parity blocks. Parity block Pi is the parity block for data blocks B(4i-3) to B(4i). What, if any, problem might this arrangement present?","This arrangement has the problem that Pi and B(4i-3) are on the same disk. So if that disk fails, reconstruction of B(4i-3) is not possible, since data and parity are both lost.",,
484,Database," A database administrator can choose how many disks are organized into a single RAID 5 array. What are the trade-offs between having fewer disks versus more disks, in terms of cost, reliability, performance during failure, and performance during rebuild?","Fewer disks has higher cost per unit of storage, but with more disks, the chance of two disk failures, which would lead to data loss, is higher. Further, performance during failure would be poor since a block read from a failed disk would result in a large number of block reads from the other disks. Similarly, the overhead for rebuilding the failed disk would also be higher, since more disks need to be read to reconstruct the data in the failed disk.",,
485,Database," A power failure that occurs while a disk block is being written could result in the block being only partially written. Assume that partially written blocks can be detected. An atomic block write is one where either the disk block is fully written or nothing is written (i.e., there are no partial writes). Suggest schemes for getting the effect of atomic block writes with the following RAID schemes. Your schemes should involve work on recovery from failure.
 a. RAID level 1 (mirroring)
 b. RAID level 5 (block interleaved, distributed parity)","a. RAID level 1 (mirroring):
 To ensure atomicity, a block write operation is carried out as follows:
  i. Write the information onto the first physical block.
  ii. When the first write completes successfully, write the same information onto the second physical block.
  iii. The output is declared completed only after the second write completes successfully.
 During recovery, each pair of physical blocks is examined. If both are identical and there is no detectable partial write, then no further actions are necessary. If one block has been partially rewritten, then we replace its contents with the contents of the other block. If there has been no partial write, but they differ in content, then we replace the contents of the first block with the contents of the second, or vice versa. This recovery procedure ensures that a write to stable storage either succeeds completely (updates both copies) or results in no change.
 The requirement of comparing every corresponding pair of blocks during recovery is expensive. We can reduce the cost greatly by keeping track of block writes that are in progress, using a small amount of nonvolatile RAM. On recovery, only blocks for which writes were in progress need to be compared.
 
 b. RAID level 5 (block interleaved, distributed parity):
 The idea is similar here. For any block write, the information block is written first, followed by the corresponding parity block. At the time of recovery, each set consisting of the nth block of each of the disks is considered. If none of the blocks in the set have been partially written, and the parity block contents are consistent with the contents of the information blocks, then no further action need be taken. If any block has been partially written, its contents are reconstructed using the other blocks. If no block has been partially written, but the parity block contents do not agree with the information block contents, the parity block's contents are reconstructed.",,
486,Database," Storing all blocks of a large file on consecutive disk blocks would minimize seeks during sequential file reads. Why is it impractical to do so? What do operating systems do instead, to minimize the number of seeks during sequential reads?","Reading data sequentially from a large file could be done with only one seek if the entire file were stored on consecutive disk blocks. Ensuring availability of large numbers of consecutive free blocks is not easy, since files are created and deleted, resulting in fragmentation of the free blocks on disks. Operating systems allocate blocks on large but fixed-sized sequential extents instead, and only one seek is required per extent.",,
487,Database,Can you explain what ACID properties in a transaction are and why they are important?,"ACID properties, an acronym for Atomicity, Consistency, Isolation, and Durability, are fundamental to database transactions.

Atomicity ensures that a transaction is treated as a single unit, either fully completed or not executed at all, preventing partial updates which could lead to data inconsistency.

Consistency guarantees that a transaction brings the database from one valid state to another, maintaining overall system integrity. It enforces business rules and constraints ensuring data correctness.

Isolation allows concurrent transactions without interference. Each transaction operates on a consistent snapshot of the database, providing illusion of serial execution and avoiding conflicts.

Durability assures once a transaction is committed, its effects persist even in case of system failures. This is typically achieved through logging and recovery mechanisms.

These properties are crucial because they ensure reliable processing in a multi-user and multitasking environment, safeguarding against potential data corruption, inconsistencies, and system crashes.",,Top 25 Database Transactions Interview Questions and Answers - InterviewPrep
488,Database,How would you handle deadlock situations in a transactional database?,"Deadlock situations in transactional databases can be managed through several strategies. One approach is deadlock prevention, which involves ordering the resources numerically and ensuring that each transaction requests resources in increasing order. This prevents circular wait conditions.

Another strategy is deadlock avoidance, where a system maintains information about resource allocation and future requests. The Banker’s algorithm is an example of this method.

Deadlock detection and recovery is another technique. Here, the system periodically checks for deadlocks using a wait-for graph. If a cycle is detected, it implies a deadlock situation. Recovery methods include killing one or more transactions to break the deadlock.

Lastly, we have the ‘Ostrich Algorithm’, which ignores the problem altogether considering that deadlocks occur infrequently and the overhead of handling them isn’t worth it. However, this may not be suitable for all systems.",,
489,Database,Can you discuss the differences between optimistic and pessimistic concurrency control?,"Optimistic Concurrency Control (OCC) and Pessimistic Concurrency Control (PCC) are two methods used to handle simultaneous transactions in a database system.

OCC assumes that multiple transactions can complete without affecting each other. It allows concurrent transactions, checks for conflicts at the end of the transaction. If any conflict is detected, it rolls back the transaction. This method is beneficial when there’s low contention for data as it reduces the overhead of locking resources.

On the contrary, PCC assumes that conflicts will occur and prevents them by locking the resources before a transaction begins. Other transactions cannot access these locked resources until they’re released. While this approach ensures data integrity, it may lead to reduced throughput due to waiting times if there’s high contention for resources.",,
490,Database,Could you describe the two-phase commit protocol and how it ensures data consistency across distributed systems?,"The two-phase commit protocol (2PC) is a distributed systems algorithm that ensures data consistency across multiple nodes. It operates in two stages: the prepare phase and the commit phase.

In the prepare phase, the coordinator node sends a query to all participant nodes asking if they can commit or abort the transaction. Each participant executes the transaction up to the point where it will be asked to commit. They then reply with an agreement (Yes) if the transaction executed successfully, or disagreement (No) if it encountered any issues.

During the commit phase, if all participants agreed in the first phase, the coordinator sends a commit request to all nodes. If any participant disagreed, the coordinator sends an abort request. On receiving the commit request, each participant completes its part of the transaction and releases all the locks held during execution. In case of an abort request, each participant undoes the changes made during the transaction execution and informs the coordinator about completion of undo operation.

This process guarantees atomicity and consistency even in distributed environments by ensuring either all nodes commit the transaction or none do, preventing partial commits which could lead to inconsistent states.",,
491,Database,Can you explain how nested transactions work and provide a situation where you might use them?,"Nested transactions are a series of transactions where each transaction has a defined scope within the main transaction. They allow for partial commits and rollbacks, providing flexibility in managing complex operations.

Consider an e-commerce application processing an order. The main transaction is the entire order process, while nested transactions handle individual tasks like payment authorization, inventory check, and shipping details update.

If payment fails, only that nested transaction rolls back without affecting others. If all nested transactions succeed, the main transaction commits, completing the order process. However, if any nested transaction fails, the main transaction can rollback entirely, ensuring data consistency.",,
492,Database,How would you handle transaction failures and ensure rollback is conducted appropriately?,"Database transaction failures can be handled using a combination of techniques. The primary method is implementing Atomicity, Consistency, Isolation, and Durability (ACID) properties in the database management system.

Atomicity ensures that all operations within a transaction are completed successfully; if not, the transaction is aborted at the failure point and previous operations are rolled back to their former state. This rollback mechanism is crucial for maintaining data integrity during transaction failures.

Consistency guarantees that only valid data following predefined rules will be written into the database. If a transaction results in invalid data, it’s rolled back.

Isolation keeps transactions separated from each other until they’re finished. It prevents concurrent transaction issues like dirty reads or lost updates which could lead to inconsistent states.

Durability assures that once a transaction has been committed, it will remain so, even in the event of power loss, crashes, or errors.

In addition to ACID, savepoints can be used to set markers in a list of transactions. In case of failure, rollbacks can occur to these savepoints instead of the entire transaction, saving resources.",,
493,Database,Discuss how checkpoints play a role in database transactions.,"Checkpoints are crucial in database transactions as they help maintain data integrity and facilitate recovery. They work by periodically saving the state of a transaction to disk, marking a point where all previous logs are saved. In case of system failure, instead of rolling back entire transactions, the system only needs to roll back to the last checkpoint, reducing recovery time.

During normal operation, checkpoints write dirty pages (modified pages) from buffer cache to disk. This minimizes the amount of data loss that could occur due to sudden failures. Checkpoints also truncate the transaction log by freeing up space occupied by committed transactions, preventing it from becoming excessively large.

In addition, checkpoints can be used to manage concurrency control. By ensuring that only one transaction is active at any given time, checkpoints prevent conflicts and ensure consistency.

However, frequent checkpoints can degrade performance as disk I/O operations are expensive. Therefore, balancing between recovery time and system performance is essential when determining checkpoint frequency.",,
494,Database,What is a transaction log and how is it used in managing transactions?,"A transaction log is a sequential record of all changes made to the database during a transaction. It’s crucial for ensuring data integrity and recovery. Each entry in the log contains information about the transaction, like its start time, end time, and what operations it performed.

Transaction logs are used in several ways. They enable rollback of transactions, where changes can be undone if a transaction fails or is aborted. This ensures that the database remains consistent even when errors occur.

They also facilitate recovery from system crashes. By replaying the actions recorded in the log, the database can be restored to a consistent state after a failure. This process involves redoing completed transactions and undoing incomplete ones.

Lastly, they assist in concurrency control by helping resolve conflicts between simultaneous transactions. The DBMS uses the log to determine which transaction accessed a piece of data first, aiding in maintaining isolation among concurrent transactions.",,
495,Database,Can you explain the concept of savepoints in database transactions?,"Savepoints in database transactions are markers within a transaction that allow for partial rollback. They provide flexibility by dividing a transaction into smaller parts, which can be independently undone without affecting the entire transaction. This is particularly useful when executing long or complex transactions where an error may occur at any point. If an error occurs after a savepoint, changes made after that savepoint can be discarded, allowing the transaction to continue from the savepoint instead of being entirely aborted. Savepoints thus enhance efficiency and reliability of database operations.",,
496,Database,What are some strategies for handling long-running transactions in a busy database to prevent blocking other tasks?,"Long-running transactions can be managed effectively in a busy database through several strategies. One approach is to use optimistic concurrency control (OCC), which allows multiple transactions to access the same record simultaneously, reducing blocking. OCC assumes conflicts are rare and only checks for them when committing changes.

Another strategy involves partitioning data into smaller chunks that can be processed independently, minimizing contention. This technique, known as sharding, distributes load across different servers or databases, enhancing performance.

Additionally, implementing priority queues can help manage long-running transactions. High-priority tasks get precedence over lower ones, ensuring critical operations aren’t blocked by less important ones.

Using non-blocking algorithms where possible also helps. These algorithms allow other processes to continue even if one process is slow or stalled.

Lastly, consider using asynchronous processing for non-critical tasks. This defers execution until system resources are available, preventing these tasks from blocking more urgent ones.",,
497,Database,"How does transaction isolation work, and what are the four levels of isolation in SQL Server?","Transaction isolation in SQL Server controls how and when the changes made by one transaction are visible to others. It’s a critical aspect of maintaining database integrity, preventing conflicts between simultaneous transactions.

The four levels of isolation in SQL Server are:

1. Read Uncommitted: The lowest level where a transaction can read data changed by another running but not yet committed transaction (dirty read).

2. Read Committed: Default level that prevents dirty reads. A transaction can only read data committed before it started.

3. Repeatable Read: Prevents dirty and non-repeatable reads. Once a transaction reads data, no other transaction can change that data until the first transaction completes.

4. Serializable: Highest level that provides strictest isolation. It prevents dirty, non-repeatable reads, and phantom reads. Transactions are executed sequentially.",,
498,Database,"What is a dirty read in the context of database transactions, and how can it be avoided?","A dirty read occurs when a transaction reads data written by another uncommitted transaction. This can lead to inconsistencies if the other transaction rolls back, making the read data invalid.

To avoid this, we use isolation levels in DBMS which determine how and when the changes made by one transaction are visible to others. The SQL standard defines four levels: Read Uncommitted, Read Committed, Repeatable Read, and Serializable. To prevent dirty reads, at least ‘Read Committed’ level should be used. In this level, a transaction may only read data committed before it started, preventing it from seeing uncommitted changes.

Another method is using locks. Two types of locks are shared (S) and exclusive (X). Shared lock allows concurrent transactions to read (but not write) the locked object. Exclusive lock prohibits other transactions from reading/writing the locked object. By properly implementing these locks, dirty reads can be avoided.",,
499,Database,"Can you explain what a phantom read is, and how it can be prevented?","A phantom read occurs in a database when a transaction re-executes a query and the rows that satisfy the query have changed due to another recently committed transaction. This inconsistency happens because of non-repeatable reads or dirty reads.

To prevent phantom reads, we can use serialization which ensures transactions are executed one after the other, eliminating concurrency issues. However, this method may lead to performance degradation as it doesn’t allow parallel execution of transactions.

Another approach is implementing ‘Snapshot Isolation’. It allows concurrent executions while maintaining consistency by creating a virtual snapshot of data for each transaction. If any changes occur during the transaction, they’re not reflected in the snapshot, preventing phantom reads.

Database management systems (DBMS) also provide isolation levels to handle such scenarios. Setting the isolation level to ‘Serializable’ prevents phantom reads. In SQL Server, setting the isolation level to ‘Read Committed Snapshot Isolation’ (RCSI) or using ‘Repeatable Read’ isolation level in MySQL can help avoid phantom reads.",,
500,Database,How do you manage distributed transactions and ensure consistency across all database systems involved?+,"Distributed transactions are managed using a two-phase commit protocol. In the first phase, the coordinator node sends a prepare message to all participant nodes and waits for their response. If all participants respond with an agreement, the second phase begins where the coordinator sends a commit request. If any participant disagrees, the transaction is rolled back.

Ensuring consistency across all database systems involved in distributed transactions requires implementing ACID properties (Atomicity, Consistency, Isolation, Durability). Atomicity ensures that either all changes made during a transaction are committed or none at all. Consistency guarantees that only valid data will be written to the database. Isolation ensures that concurrent execution of transactions results in a system state as if transactions were executed serially. Durability guarantees that once a transaction has been committed, it will remain so even in case of subsequent failures.",,
501,Database,What are some common problems you might encounter with large-scale transactions and how would you handle them?,"Large-scale transactions can encounter issues such as deadlocks, data inconsistency, and performance degradation.

Deadlocks occur when two or more transactions indefinitely wait for each other to release resources. To handle this, implement a deadlock detection algorithm that periodically checks for circular waiting conditions. If detected, abort one transaction to free up resources.

Data inconsistency arises from concurrent transactions modifying the same data. Use isolation levels to manage this. For instance, serializable isolation ensures transactions execute in an order equivalent to running them sequentially, preventing inconsistencies.

Performance degradation is due to resource contention among numerous large transactions. Optimizing database design, like proper indexing, can enhance query performance. Also, consider partitioning large databases into smaller, manageable chunks to reduce contention.",,
502,Database,Can you explain the process of transaction chaining and its benefits?,"Transaction chaining is a process in database management where multiple transactions are linked together, forming a chain. This method allows for the execution of several operations as one unit, enhancing efficiency and consistency.

The primary benefit of transaction chaining is atomicity, ensuring that all operations within a chained transaction either succeed or fail as a whole. If an error occurs during any operation, the entire transaction can be rolled back to its initial state, maintaining data integrity.

Another advantage is isolation. Chained transactions are executed independently from other processes, preventing interference and potential conflicts. This feature enhances system stability and reliability.

Moreover, transaction chaining improves performance by reducing the overhead associated with initiating and terminating individual transactions. By grouping related operations, it minimizes resource usage and speeds up processing time.

Lastly, this technique simplifies error handling and recovery procedures. In case of failure, only the affected chain needs to be addressed rather than each separate transaction, making troubleshooting more manageable.",,
503,Database,What is the role of a transaction manager in a database system?,"A transaction manager in a database system is responsible for managing the execution of transactions. It ensures that the database remains consistent and correct even when multiple transactions are executed concurrently. The manager uses protocols like two-phase locking (2PL) or timestamp ordering to prevent conflicts between transactions.

The manager also handles recovery from failures, using techniques such as logging and checkpoints. If a failure occurs during a transaction, the manager can roll back changes made by that transaction to restore the database to a consistent state.",,
504,Database,How would you handle a scenario where a database transaction violates business rules?,"In a scenario where a database transaction violates business rules, I would implement a robust error handling mechanism. This involves using Transaction Control Language (TCL) commands like COMMIT and ROLLBACK to manage transactions in the database.

Firstly, I’d ensure that all business rules are encapsulated within stored procedures or triggers. These will automatically check each transaction for compliance with business rules before it’s committed to the database.

If a violation is detected, the transaction should be rolled back immediately. The ROLLBACK command undoes all changes made in the current transaction, returning the database to its previous state before the transaction began.

Additionally, an appropriate error message should be returned to the user or application initiating the transaction. This informs them of the rule violation and allows corrective action to be taken.

Finally, regular audits can help identify recurring violations and areas where business rules may need to be revised or clarified.",,
505,Database,What is the difference between implicit and explicit transaction modes?,"Implicit and explicit transaction modes differ in their initiation and termination. In implicit mode, the system automatically starts a transaction when certain SQL statements are executed and ends it when no more data manipulation is detected or an error occurs. This mode doesn’t require user intervention but can lead to unintended results if not carefully managed.

Explicit mode, on the other hand, requires manual start and end commands from the user. The BEGIN TRANSACTION command initiates the process, while COMMIT or ROLLBACK terminates it based on whether changes need to be saved or discarded respectively. This mode offers greater control over transactions, allowing for complex operations and better error handling.",,
506,Database,Can you explain what a transaction schedule is and its importance in concurrency control?,"A transaction schedule refers to the chronological order in which instructions from concurrent transactions are executed. It’s crucial for concurrency control as it ensures data consistency and integrity during simultaneous operations. Two types of schedules exist: serial, where transactions execute one after another, and non-serial, where transactions overlap.

Serializability is a key concept here. A schedule is serializable if its outcome matches that of its corresponding serial schedule, ensuring equivalent results despite different execution orders. This prevents conflicts and anomalies like dirty reads, unrepeatable reads, or phantom reads.

Two techniques help achieve this: conflict serializability and view serializability. Conflict serializability checks whether conflicting operations can be reordered without changing the final result. View serializability considers the overall effect on the database rather than individual operations.",,
507,Database,How does a database system use a write-ahead log in the context of transactions?,"A database system uses a write-ahead log (WAL) to ensure data integrity and consistency during transactions. When a transaction is initiated, the changes are first recorded in the WAL before being written into the actual database. This process is known as logging. The WAL serves two main purposes: recovery and atomicity.

In terms of recovery, if a crash occurs during a transaction, the database can be restored to its previous state using the WAL. It contains all modifications made by incomplete transactions, allowing for rollback operations.

Regarding atomicity, the WAL ensures that either all changes from a transaction are applied or none at all. If a failure happens after some but not all changes have been written to the database, the system can use the WAL to undo partial transactions, maintaining atomicity.",,
508,Database,"What is serializability in the context of transactions, and why is it important?","Serializability in transactions refers to the property that ensures concurrent transaction execution results are equivalent to some serial execution. It’s crucial for maintaining database consistency, as it prevents conflicts when multiple users access or modify data simultaneously. Without serializability, data integrity can be compromised due to issues like dirty reads, non-repeatable reads, and phantom reads.",,
509,Database,How do you ensure the atomicity of a transaction in a distributed database system?,"In a distributed database system, atomicity of transactions is ensured through the two-phase commit protocol (2PC). The 2PC has two stages: the voting phase and the decision phase. In the voting phase, the coordinator sends a query to all participants asking if they can commit or abort the transaction. Each participant executes the transaction up to the point where it will be ready to commit, then votes ‘yes’ or ‘no’. In the decision phase, if all participants vote ‘yes’, the coordinator sends a global ‘commit’ message; otherwise, it sends an ‘abort’ message. Participants follow the coordinator’s decision ensuring atomicity.",,
510,Database,Can you explain how versioning is used in the context of database transactions?,"Versioning in database transactions is a technique used to manage data concurrency and maintain consistency. It involves creating different versions of each data item, allowing multiple transactions to occur simultaneously without conflict.

In optimistic concurrency control (OCC), versioning is employed to avoid conflicts during transaction execution. Each transaction operates on a private copy of the database objects, generating new versions. Upon commit time, if no other transaction has modified the same data, changes are applied; otherwise, a rollback occurs.

Similarly, in Multi-Version Concurrency Control (MVCC), each write operation creates a new version of a data item. Read operations access the most recent committed version that was valid at the start of the transaction. This ensures isolation between concurrent transactions, preventing read-write and write-write conflicts.

Snapshot Isolation, another variant, provides each transaction with a snapshot of the entire database at the beginning of its execution, ensuring consistent views while permitting concurrent updates.",,
511,Database,How would you handle a situation where a transaction needs to be cancelled but it has already triggered other dependent transactions?,"In such a situation, the concept of Atomicity in ACID properties of database transactions is applied. If a transaction needs to be cancelled but has already triggered other dependent transactions, we use a process called ‘Rollback’. Rollback ensures that if a transaction cannot be completed fully, all operations within it are undone, returning the database to its previous state before the transaction began.

This involves keeping track of all changes made during a transaction using a transaction log. When a rollback is initiated, the system refers to this log and undoes each operation in reverse order. This includes any dependent transactions that were triggered by the original one.

However, there can be complications when dealing with concurrent transactions. In such cases, concurrency control techniques like locking or timestamping are used to ensure data integrity while rolling back. Locking prevents other transactions from accessing the same data until the rollback is complete, whereas timestamping orders transactions based on their start time to resolve conflicts.",,
512,Database, Is a multiuser system necessarily a parallel system? Why or why not?,"No. A single processor with only one core can run multiple processes to manage multiple users. Most modern systems are parallel, however.",,https://www.db-book.com/Practice-Exercises/PDF-practice-solu-dir/20.pdf
513,Database," Atomic instructions such as compare-and-swap and test-and-set also execute a memory fence as part of the instruction on many architectures. Explain what is the motivation for executing the memory fence, from the viewpoint of data in shared memory that is protected by a mutex implemented by the atomic instruction. Also explain what a process should do before releasing a mutex.","The memory fence ensures that the process that gets the mutex will see all updates that happened before the instruction, as long as processes execute a fence before releasing the mutex. Thus, even if the data was updated on a different core, the process that acquires the mutex is guaranteed to see the latest value of the data.",,
514,Database," Instead of storing shared structures in shared memory, an alternative architecture would be to store them in the local memory of a special process and access the shared data by interprocess communication with the process. What would be the drawback of such an architecture?","The drawbacks would be that two interprocess messages would be required to acquire locks, one for the request and one to confirm grant. Interprocess communication is much more expensive than memory access, so the cost of locking would increase. The process storing the shared structures could also become a bottleneck. The benefit is that the lock table is protected better from erroneous updates since only one process can access it.",,
515,Database, Explain the distinction between a latch and a lock as used for transactional concurrency control.,Latches are short-duration locks that manage access to internal system data structures. Locks taken by transactions are taken on database data items and are often held for a substantial fraction of the duration of the transaction. Latch acquisition and release are not covered by the two-phase locking protocol.,,
516,Database," Suppose a transaction is written in C with embedded SQL, and about 80 percent of the time is spent in the SQL code, with the remaining 20 percent spent in C code. How much speedup can one hope to attain if parallelism is used only for the SQL code? Explain.","Since the part which cannot be parallelized takes 20% of the total running time, the best speedup we can hope for is 5. By Amdahl's law, speedup is 1 / ((1 - p) + p/n); here p = 0.8, and as n approaches infinity, the maximum speedup approaches 1 / 0.2 = 5.",,
517,Database," Consider a pair of processes in a shared memory system such that process A updates a data structure, and then sets a flag to indicate that the update is completed. Process B monitors the flag, and starts processing the data structure only after it finds the flag is set. Explain the problems that could arise in a memory architecture where writes may be reordered, and explain how the sFence and lFence instructions can be used to ensure the problem does not occur.","The goal is that the consumer process B should see the data structure state after all updates have been completed. But out-of-order writes to main memory can result in the consumer process seeing some but not all the updates to the data structure, even after the flag has been set. To avoid this problem, the producer process A should issue an sFence after the updates, but before setting the flag. It can optionally issue an sFence after setting the flag, to push the update to memory with minimum delay. The consumer process B should correspondingly issue an lFence after the flag has been found to be set, before accessing the data structure.",,
518,Database," In a shared-memory architecture, why might the time to access a memory location vary depending on the memory location being accessed?","In a NUMA architecture, a processor can access its own memory faster than it can access shared memory associated with another processor due to the time taken to transfer data between processors.",,
519,Database," Most operating systems for parallel machines (i) allocate memory in a local memory area when a process requests memory, and (ii) avoid moving a process from one core to another. Why are these optimizations important with a NUMA architecture?","In a NUMA architecture, a processor can access its own memory faster than it can access shared memory associated with another processor. Thus, if the data of a process resides in local memory, the process execution would be faster than if the memory is non-local. Further, if a process moves from one core to another, it may lose the benefits of local allocation of memory and be forced to carry out many memory accesses from other cores, so operating systems avoid moving processes between cores wherever possible.",,
520,Database," Some database operations such as joins can see a significant difference in speed when data (e.g., one of the relations involved in a join) fits in memory as compared to the situation where the data do not fit in memory. Show how this fact can explain the phenomenon of superlinear speedup, where an application sees a speedup greater than the amount of resources allocated to it.","For example, suppose we double the amount of main memory and as a result one of the relations now fits entirely in main memory. We can now use a nested-loop join with the inner-loop relation entirely in main memory and incur disk accesses for reading the input relations only once. With the original amount of main memory, the best join strategy may have had to read a relation from disk more than once. Thus, doubling memory can lead to more than a 2x speedup, i.e., superlinear speedup.",,
521,Database,20.10 What is the key distinction between homogeneous and federated distributed database systems?,"The key difference is the degree of cooperation among the systems and the degree of centralized control. Homogeneous systems share a global schema, run the same database-system software, and actively cooperate on query processing. Federated systems may have distinct schemas and software, and may cooperate in only a limited manner.",,
522,Database, Why might a client choose to subscribe only to the basic infrastructure-as-a-service model rather than to the services offered by other cloud service models?,A client may wish to control its own applications and thus may not wish to subscribe to a software-as-a-service model; or the client might further wish to be able to choose and manage its own database system and thus not wish to subscribe to a platform-as-a-service model.,,
523,Database," Why do cloud-computing services support traditional database systems best by using a virtual machine, instead of running directly on the service provider's actual machine, assuming that data is on external storage?","By using a virtual machine, if a physical machine fails, virtual machines running on that physical machine can be restarted quickly on one or more other physical machines, improving availability. This assumes that data remains accessible, either by storing multiple copies of data, or by storing data in a highly available external storage system.",,
524,Algo & DS,,,,
525,Algo & DS,"Given a sorted array of n integers and a target value, implement binary search to find the target’s index (or –1 if not found).",,Easy,https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/pages/lecture-notes/
526,Algo & DS,Union of two sorted arrays (unique).,,Easy,https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/pages/lecture-notes//
527,Algo & DS,Topological sort of a DAG,,Easy,https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/pages/lecture-notes
528,Algo & DS,Describe how Selection Sort works and analyze its time complexity.,,Easy,"Cormen et al., Introduction to Algorithms,"
529,Algo & DS,What is the time complexity of inserting an element at the end of an array?,,Easy,
530,Algo & DS,"Given an unsorted array, design an algorithm to find the second largest element.",,Easy,"CLRS, Ch. 9"
531,Algo & DS,Reverse an array in-place without using extra memory.,,Easy,MIT OCW 6.006
532,Algo & DS,Determine whether two strings are anagrams of each other.,,Easy,GeeksforGeeks
533,Algo & DS,Count the number of occurrences of an element in a sorted array.,,Easy,MIT OCW 6.006
534,Algo & DS,Find the maximum sum of any two consecutive elements in an array.,,Easy,CLRS
535,Algo & DS,Check if a given number is prime.,,Easy,Algorithm Design Manual
536,Algo & DS,Compute the sum of digits of an integer using recursion.,,Easy,GeeksforGeeks
537,Algo & DS,Remove duplicates from an unsorted array.,,Easy,MIT OCW 6.006
538,Algo & DS,Compute factorial using iteration.,,Easy,CLRS
539,Algo & DS,Find the smallest element in a rotated sorted array.,,Easy,CP-Algorithms
540,Algo & DS,Count vowels in a string.,,Easy,Standard String Algorithms
541,Algo & DS,Convert decimal number to binary.,,Easy,Discrete Math Algorithms
542,Algo & DS,Check if a number is a palindrome.,,Easy,GeeksforGeeks
543,Algo & DS,Merge two unsorted arrays into one.,,Easy,MIT OCW
544,Algo & DS,Determine if a year is a leap year.,,Easy,Gregorian Calendar Rules
545,Algo & DS,Find the index of the first negative number in an array.,,Easy,CLRS
546,Algo & DS,Convert a string to uppercase without built-in functions.,,Easy,Cormen Appendix
547,Algo & DS,Generate Fibonacci sequence up to n terms.,,Easy,MIT OCW
548,Algo & DS,Count the number of even numbers in an array.,,Easy,Standard Array Algorithms
549,Algo & DS,Determine if array is sorted in ascending order.,,Easy,CLRS
550,Algo & DS,Find the index of maximum value in an array.,,Easy,MIT OCW
551,Algo & DS,Compute power x^n using naive multiplication.,,Easy,Algorithm Design Manual
552,Algo & DS,Count characters in a string excluding spaces.,,Easy,GeeksforGeeks
553,Algo & DS,Check whether a number is divisible by 3.,,Easy,Number Theory Basics
554,Algo & DS,Find common elements between two arrays.,,Easy,CLRS
555,Algo & DS,Apply dynamic programming to compute the length of the Longest Increasing Subsequence (LIS).,,Medium,"CLRS, Ch. 15"
556,Algo & DS,Design an algorithm to find the k-th smallest element using QuickSelect.,,Medium,"CLRS, Ch. 9"
557,Algo & DS,Determine shortest path in an unweighted graph using BFS.,,Medium,MIT OCW 6.006
558,Algo & DS,"Given a matrix, find the path with maximum sum from top-left to bottom-right moving only right or down.",,Medium,CLRS
559,Algo & DS,Design an algorithm to detect if a graph is bipartite.,,Medium,"CLRS, Ch. 22"
560,Algo & DS,Explain how heap sort produces a sorted array.,,Medium,"CLRS, Ch. 6"
561,Algo & DS,Compute edit distance between two strings.,,Medium,"CLRS, Ch. 15"
562,Algo & DS,Implement topological sorting using Kahn’s algorithm.,,Medium,MIT OCW
563,Algo & DS,Determine if a permutation is lexicographically next.,,Medium,CP-Algorithms
564,Algo & DS,Find cycle in directed graph using DFS.,,Medium,CLRS
565,Algo & DS,Apply greedy method to schedule activities with maximum count.,,Medium,CLRS
566,Algo & DS,"Given a sequence, find the longest palindromic subsequence.",,Medium,CP-Algorithms
567,Algo & DS,Implement Dijkstra algorithm for weighted graph with adjacency list.,,Medium,CLRS
568,Algo & DS,Solve coin change problem to minimize number of coins.,,Medium,CLRS
569,Algo & DS,Determine connected components in an undirected graph.,,Medium,MIT OCW
570,Algo & DS,Analyze time complexity of recursive merge sort.,,Medium,CLRS
571,Algo & DS,Detect redundant connections in an undirected graph.,,Medium,CP-Algorithms
572,Algo & DS,Determine order of growth of nested loops.,,Medium,CLRS
573,Algo & DS,Compute matrix multiplication for two square matrices.,,Medium,CLRS
574,Algo & DS,Implement DFS traversal on graph.,,Medium,MIT OCW
575,Algo & DS,"Given an array, find maximum subarray sum using divide-and-conquer.",,Medium,CLRS
576,Algo & DS,Solve rod cutting problem using dynamic programming.,,Medium,CLRS
577,Algo & DS,Implement topological sorting using Kahn’s algorithm.,,Medium,MIT OCW
578,Algo & DS,"Given a sequence of tasks with deadlines and profits, design an algorithm to maximize total profit.",,Medium,"CLRS, Ch. 16"
579,Algo & DS,Design an algorithm to detect majority element in an array.,,Medium,CLRS
580,Algo & DS,Find the longest substring without repeating characters.,,Medium,CP-Algorithms
581,Algo & DS,Compute minimum spanning tree using Prim’s algorithm with adjacency matrix.,,Medium,CLRS
582,Algo & DS,Determine whether a graph contains a Hamiltonian path.,,Medium,Graph Theory
583,Algo & DS,Design a greedy algorithm for interval covering.,,Medium,CLRS
584,Algo & DS,Compute shortest distance between two nodes in weighted DAG.,,Medium,CLRS
585,Algo & DS,Find minimum difference between any two elements in array.,,Medium,CP-Algorithms
586,Algo & DS,Calculate number of inversions in array using BIT.,,Medium,CP-Algorithms
587,Algo & DS,Implement merge k sorted lists.,,Medium,CLRS
588,Algo & DS,Design an algorithm to compute all biconnected components using DFS low-link values.,,Hard,CLRS Ch. 22
589,Algo & DS,Develop a DP algorithm for optimal binary search tree with actual reconstruction of tree.,,Hard,CLRS Ch. 15
590,Algo & DS,Design an algorithm to compute minimum number of edges to add to make a directed graph strongly connected.,,Hard,CP-Algorithms
591,Algo & DS,Prove that Max-Cut has a polynomial-time 0.878-approximation using semidefinite programming.,,Hard,Goemans & Williamson 1995
592,Algo & DS,Show that deciding if a Turing machine halts on empty input is undecidable.,,Hard,Sipser – Theory of Computation
593,Algo & DS,Design an algorithm for minimum-cost maximum-flow in directed graph.,,Hard,CLRS Ch. 29
594,Algo & DS,Derive the time complexity of recursive Strassen’s algorithm.,,Hard,"CLRS, Ch. 4"
595,Algo & DS,Design an algorithm for weighted interval scheduling.,,Hard,CLRS
596,Algo & DS,Prove correctness of Dijkstra using greedy stays optimal.,,Hard,CLRS
597,Algo & DS,Prove that subset sum is NP-complete.,,Hard,Garey & Johnson
598,Algo & DS,Explain Hopcroft-Karp algorithm.,,Hard,CLRS
599,Algo & DS,"Given a string, find the minimum number of cuts to divide it into palindromic substrings.",,Hard,GeeksforGeeks
600,Algo & DS,Prove that merge sort’s recursion T(n)=2 T(n/2)+Θ(n) solves to Θ(n log n).,,Hard,Introduction to Algorithms CLRS 4ed
601,Algo & DS,Bellman–Ford + negative-cycle detection.,,Hard,https://cp-algorithms.com/graph/bellman_ford.html
602,Algo & DS,Prove that any comparison-based sorting algorithm has a lower bound of Ω(n log n).,,Hard,CLRS Ch. 8
603,Algo & DS,Design a polynomial-time approximation for the Vertex Cover problem.,,Hard,CLRS Ch. 35
604,Algo & DS,Explain why the Traveling Salesman Problem is NP-complete.,,Hard,Garey & Johnson
605,Algo & DS,Derive the DP formulation for bitonic TSP.,,Hard,CLRS Ch. 15
606,Algo & DS,Design a randomized algorithm for selecting median in expected linear time.,,Hard,CLRS Ch. 9
607,Algo & DS,Explain A* search and its optimality condition.,,Hard,AI: Russell & Norvig
608,Algo & DS,Construct an algorithm to find strongly connected components.,,Hard,CLRS Ch. 22
609,Algo & DS,Prove correctness of Huffman Coding’s greedy strategy.,,Hard,CLRS Ch. 16
610,Algo & DS,Explain how the Ford–Fulkerson method computes maximum flow.,,Hard,CLRS Ch. 26
611,Algo & DS,Apply Min-Cut Max-Flow theorem to network balancing.,,Hard,CLRS Ch. 26
612,Algo & DS,Show how dynamic programming solves matrix-chain multiplication.,,Hard,CLRS
613,Algo & DS,Explain amortized analysis using potential method.,,Hard,CLRS Ch. 17
614,Algo & DS,Describe algorithm for finding articulation points in graph.,,Hard,CP-Algorithms
615,Algo & DS,Explain algorithm for detecting bridges in a graph.,,Hard,CP-Algorithms
616,Algo & DS,Analyze Strassen’s algorithm for matrix multiplication.,,Hard,CLRS
617,Algo & DS,Prove the Master Theorem formally.,,Hard,CLRS
618,Algo & DS,Explain prefix-function computation in KMP.,,Hard,CLRS Ch. 32
619,Algo & DS,Show correctness of greedy interval scheduling.,,Hard,CLRS
620,Algo & DS,Develop algorithm for longest path in DAG.,,Hard,CLRS
621,Algo & DS,Formulate DP for minimum edit script with traceback.,,Hard,CLRS
622,Algo & DS,Prove that Max-Cut has a polynomial-time 0.878-approximation using semidefinite programming.,,Hard,Goemans & Williamson 1995
623,Algo & DS,Show that deciding if a Turing machine halts on empty input is undecidable.,,Hard,Sipser – Theory of Computation
624,Algo & DS,Design an algorithm for minimum-cost maximum-flow in directed graph.,,Hard,CLRS Ch. 29
625,Algo & DS,Give a divide-and-conquer algorithm to find closest pair of points in 2D and analyze correctness.,,Hard,Computational Geometry – de Berg et al.
626,Algo & DS,,,,
627,Algo & DS,,,,
628,Algo & DS,Stack with push/pop/top,,Easy,https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/pages/lecture-notes
629,Algo & DS,Binary Search Trees basics (insert/find/min).,,Easy,https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/resources/lecture-5-binary-search-trees-bst-sort/
630,Algo & DS,Queue with circular array,,Easy,https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/pages/lecture-notes/?
631,Algo & DS,Describe the difference between an array and a linked list.,,Easy,"CLRS, Ch. 10"
632,Algo & DS,What is a queue and how does it process elements?,,Easy,MIT OCW 6.006
633,Algo & DS,Define a binary tree and list its main properties.,,Easy,CLRS
634,Algo & DS,What is the purpose of a hash table?,,Easy,MIT OCW
635,Algo & DS,Define a heap and its core property.,,Easy,CLRS
636,Algo & DS,What distinguishes a max heap from a min heap?,,Easy,CLRS
637,Algo & DS,Describe concept of pointer in linked structures.,,Easy,GeeksforGeeks
638,Algo & DS,Explain adjacency matrix in graph representation.,,Easy,CLRS
639,Algo & DS,What is an adjacency list?,,Easy,MIT OCW
640,Algo & DS,Describe a circular linked list.,,Easy,CLRS
641,Algo & DS,What is a priority queue?,,Easy,CLRS
642,Algo & DS,Explain how a node is inserted at the end of a linked list.,,Easy,MIT OCW
643,Algo & DS,Define graph vertex degree.,,Easy,GeeksforGeeks
644,Algo & DS,Differentiate full and complete binary trees.,,Easy,CLRS
645,Algo & DS,What is a dynamic array and how does it grow?,,Easy,MIT OCW 6.006
646,Algo & DS,Define a multiset and describe how it differs from a set.,,Easy,CLRS
647,Algo & DS,What is a sentinel node in linked lists?,,Easy,GeeksforGeeks
648,Algo & DS,Explain how to find the middle of a singly linked list.,,Easy,MIT OCW
649,Algo & DS,What is the purpose of the 'parent' pointer in a tree node?,,Easy,CLRS
650,Algo & DS,How do you compute the height of a binary tree?,,Easy,GeeksforGeeks
651,Algo & DS,Explain how to check if a binary tree is empty.,,Easy,CLRS
652,Algo & DS,What is a collision in hashing?,,Easy,CLRS Hashing
653,Algo & DS,What is the difference between BFS and DFS in trees?,,Easy,MIT OCW
654,Algo & DS,Describe what a deque is and name two of its operations.,,Easy,MIT OCW
655,Algo & DS,,,,
656,Algo & DS,,,,
657,Algo & DS,,,,
658,Algo & DS,Explain how to find the lowest common ancestor (LCA) in a binary tree using parent pointers.,,Medium,CLRS
659,Algo & DS,Implement a min-stack supporting getMin() in O(1).,,Medium,CLRS
660,Algo & DS,Explain lazy deletion in hash tables.,,Medium,CLRS Hashing
661,Algo & DS,Describe how to merge two binary max heaps.,,Medium,CP-Algorithms
662,Algo & DS,Implement level-order traversal using only a stack.,,Medium,MIT OCW
663,Algo & DS,Explain how to count leaf nodes in a binary tree.,,Medium,CLRS
664,Algo & DS,Design algorithm to convert a BST into a sorted linked list.,,Medium,CLRS
665,Algo & DS,Describe how to validate if a binary tree is a BST.,,Medium,MIT OCW
666,Algo & DS,Explain how to compress paths in a trie.,,Medium,GeeksforGeeks
667,Algo & DS,Explain difference between stable and unstable sorting using examples.,,Medium,CLRS
668,Algo & DS,Explain how an LRU cache works using a hashmap + doubly linked list.,,Medium,CLRS
669,Algo & DS,Implement a prefix sum array and describe its use.,,Medium,CLRS
670,Algo & DS,Explain how a doubly linked list allows bidirectional traversal.,,Medium,"CLRS, Ch. 10"
671,Algo & DS,Describe insertion operation in a Binary Search Tree.,,Medium,MIT OCW 6.006
672,Algo & DS,How does rehashing improve hash table performance?,,Medium,CLRS
673,Algo & DS,Implement level-order traversal of a binary tree.,,Medium,CLRS
674,Algo & DS,Explain how a circular queue avoids wasted space.,,Medium,MIT OCW
675,Algo & DS,Describe how heapify operation restores heap property.,,Medium,CLRS
676,Algo & DS,Compare chaining and open addressing in hash tables.,,Medium,CLRS
677,Algo & DS,How does Union-Find with path compression work?,,Medium,CLRS
678,Algo & DS,Describe stack implementation using linked list.,,Medium,MIT OCW
679,Algo & DS,Describe delete operation in a Binary Search Tree.,,Medium,CLRS
680,Algo & DS,Implement priority queue using binary heap.,,Medium,CLRS
681,Algo & DS,Explain disjoint set structure for connected components.,,Medium,CLRS
682,Algo & DS,Implement inorder traversal iteratively.,,Medium,MIT OCW
683,Algo & DS,Explain time complexity of search in AVL tree.,,Medium,CLRS
684,Algo & DS,Differentiate between internal and external nodes in tree.,,Medium,CLRS
685,Algo & DS,How does open addressing handle collisions?,,Medium,MIT OCW
686,Algo & DS,Describe the structure of a complete binary tree.,,Medium,CLRS
687,Algo & DS,Explain implicit data structures in arrays.,,Medium,CLRS
688,Algo & DS,Implement preorder traversal of a tree iteratively.,,Medium,MIT OCW
689,Algo & DS,Explain amortized cost of dynamic array resizing.,,Medium,CLRS
690,Algo & DS,Explain how to flatten a binary tree into a linked list following preorder.,,Medium,GeeksforGeeks
691,Algo & DS,Implement deletion from a min-heap.,,Medium,CLRS
692,Algo & DS,How do you detect if a binary tree is height-balanced?,,Medium,CLRS
693,Algo & DS,Explain how to find k-th smallest element in a BST.,,Medium,MIT OCW
694,Algo & DS,Design a method to check if two binary trees are identical.,,Medium,CLRS
695,Algo & DS,Describe memory layout differences between array-based heap and pointer-based heap.,,Medium,Algorithm Design Manual
696,Algo & DS,Explain how to find diameter of a binary tree.,,Medium,CLRS
697,Algo & DS,Describe method to clone a graph with cycles.,,Medium,CLRS
698,Algo & DS,Explain how to evaluate a postfix expression using a stack.,,Medium,MIT OCW
699,Algo & DS,Design a function to delete a node in a singly linked list when only pointer to node is given.,,Medium,GeeksforGeeks
700,Algo & DS,Explain how to compute width of a binary tree.,,Medium,CLRS
701,Algo & DS,Describe algorithm to find intersection point of two linked lists.,,Medium,CLRS
702,Algo & DS,Explain how to perform zigzag level-order traversal in a tree.,,Medium,CP-Algorithms
703,Algo & DS,,,,
704,Algo & DS,Prove that perfect hashing achieves O(1) worst-case lookups using two-level hashing.,,Hard,Randomized Algorithms – Motwani & Raghavan
705,Algo & DS,Design a persistent segment tree that supports versioned range queries.,,Hard,CP-Algorithms (Persistent Trees)
706,Algo & DS,Design a dynamic 2D segment tree for rectangle sum queries.,,Hard,Advanced Data Structures – MIT 6.851
707,Algo & DS,Implement a red-black tree insertion and show how rotations restore balance.,,Hard,https://web.stanford.edu/class/archive/cs/cs166/cs166.1206/lectures/06/Small06.pdf
708,Algo & DS,What is the worst-case complexity of splay tree access?,,Hard,https://epubs.siam.org/doi/10.1137/0216022
709,Algo & DS,What is the expected insertion cost in a cuckoo hash table?,,Hard,Introduction to Algorithms CLRS 4ed
710,Algo & DS,Prove that insertion in a red-black tree preserves logarithmic height.,,Hard,"CLRS, Ch. 13"
711,Algo & DS,Design the deletion algorithm for a red-black tree and explain how violations are fixed.,,Hard,"CLRS, Ch. 13"
712,Algo & DS,Explain how skip list maintains probabilistic balance.,,Hard,CLRS
713,Algo & DS,Implement a double hashing collision resolution scheme.,,Hard,CLRS
714,Algo & DS,Demonstrate how linear probing causes primary clustering.,,Hard,MIT OCW
715,Algo & DS,Analyze complexity of cuckoo hashing insertion.,,Hard,CLRS
716,Algo & DS,Explain how segment tree supports lazy propagation.,,Hard,CP-Algorithms
717,Algo & DS,Implement Fenwick tree and analyze update logic.,,Hard,CP-Algorithms
718,Algo & DS,Explain structure of van Emde Boas tree.,,Hard,CLRS
719,Algo & DS,Implement a B+-Tree node split algorithm and prove correctness.,,Hard,Database System Concepts – Silberschatz
720,Algo & DS,Prove that sparse table RMQ queries are O(1) after O(n log n) preprocessing.,,Hard,Competitive Programming Handbook
721,Algo & DS,Design a Union-Find supporting rollback operations.,,Hard,CP-Algorithms – DSU Rollback
722,Algo & DS,Explain how a Link-Cut Tree supports path queries on dynamic trees.,,Hard,Sleator & Tarjan Dynamic Trees
723,Algo & DS,Construct a compressed trie (radix tree) and prove its lookup time bound.,,Hard,Algorithms on Strings – Gusfield
724,SWE,"Consider the following problem that we call YHC. (As a side note, it's related to the problem of choosing
an item at random with a likelihood proportional to its frequency.) Given:
1. a list L = [(i1, c1), . . . ,(in, cn)] of n > 0 pairs, where each i is an item and each c is that item's
(positive integer) count, and
2. a number t ∈ [1, C], where C is the total count of the items Pn
j=1 cj ,
produce the smallest number j for which the sum of the _x001c_rst j items' counts is at least t. That is, the _x001c_rst
j such that (
Pj
k=1 ck) ≥ t.
For instance, given the list L = [(a, 2),(b, 1),(c, 1),(d, 4)] and t = 1, we would choose j = 1 (item a)
since 2 ≥ 1 but 0 is not. Given t = 4 instead, we would choose j = 3 (item c) since 2 + 1 + 1 ≥ 4 but 2 + 1
is not. Given t = 5, we would choose j = 4 (item d) since 2 + 1 + 1 + 4 ≥ 5 but 2 + 1 + 1 is not.
1. Complete the pseudocode function below with a worst-case O(n) _x0010_brute force_x0011_ algorithm to solve
YHC. 

procedure FindJ(L, t)

end procedure","procedure FindJ(L, t)
sum ← 0
for j = 1 to n do
sum ← sum +L[j].count
if sum ≥ t then
return j
end if
end for
note: cannot reach this point
end procedure",Medium,"https://blogs.ubc.ca/cpsc3202017w1/files/2016/10/cpsc-320-2016W2-midterm-indiv-raw.pdf

https://blogs.ubc.ca/cpsc3202017w1/files/2016/10/cpsc-320-2016W2-midterm-sample-soln-draft.pdf"
725,SWE,"It isn't really the individual counts that we need to solve this problem but the running sums of the
counts. That is, for item i, we don't want ci but Pi
j=1 cj . In the example list above, for index 3 (item
c), we don't want its count 1 but the total count up to index 3: 2 + 1 + 1 = 4.
Complete the logarithmic-time algorithm below that_x0016_given a non-empty list L
0 of pairs of items and
their running sums (rather than their counts) and a number t ∈ [1, C] where C is the _x001c_nal running
sum in L
0_x0016_produces the _x001c_rst index j at which the running sum is at least as large as t. NOTE: We
assume 1-based indexing, i.e., that the indexes of L
0 are 1, 2, . . . , n. [5 marks]
procedure FindJ(L
0
, t)
n ← Length(L
0
)
if n = 1 then
return _
else
mid ← bn
2
c
if _ then
j
0 ← FindJ(L
0
[1 . . . mid], t)
return _
else
j
0 ← FindJ(L
0
[mid+1 . . . n], t)
return
end if
end if
end procedure","procedure FindJ(L
0
, t)
n ← Length(L
0
)
if n = 1 then
return 1
else
mid ← bn
2
c
if L
0
[mid].running_sum ≥ t then
j
0 ← FindJ(L
0
[1 . . . mid], t)
return j
0
else
j
0 ← FindJ(L
0
[mid+1 . . . n], t)
return j
0 + mid
end if
end if
end procedure",Medium,'
726,SWE,"You have been asked to help design the ""CPSC 211 Student Transcript System"", whose purpose
is to display student transcripts. A transcript lists the courses a student took, sorted by session.
For each session, the transcript lists all courses taken by the student; both UBC courses for term
1 and term 2, and transfer courses (courses taken at another college or university, and whose
credit can be used towards a UBC degree). Finally, each object listed on a transcript may render
itself (i.e., may prepare to write itself out) if it is given a Renderer object. Each Renderer object
knows how to print tables, lines, string, etc… in a specific output format. For the moment we are
interested in HTML documents and Java GUI formats.
Suppose we have already determined that we likely need the following classes and interfaces for
this problem:
 Transcript - a student transcript
 Session – an academic session for the transcript ( i.e. 2007s, 2008w)
 Term – a term of an academic session ( term1, term2)
 Course – a university course that appears in a term of a session in the transcript
 UBCCourse – a course taken at UBC
 TransferCourse – a course taken outside UBC and transferred to UBC
 Renderer – the interface of a renderer that can render a transcript
 JavaGUIRenderer – a renderer for Java applications
 HTMLRenderer – a renderer for Web applications
 Renderable – an interface for any object that can be rendered by a renderer
Draw a UML class diagram to describe the basic design for the Student Transcript System. Your
diagram should include the given classes and interfaces and should show the relationships (with
appropriate multiplicities) among them. Interfaces and classes must show the most important
methods that are required for the functionality mentioned in the problem description. Make sure
that your design satisfies the design principles we discussed in class.",,Hard,"https://www.cs.ubc.ca/~gabrielm/211/exams/MidtermPracticeExercises-09wTerm2.pdf
https://www.cs.ubc.ca/~gabrielm/211/exams/MidtermPracticeExercises-Solutions-09wTerm2.pdf"
727,SWE,"Consider the following partial class specifications:
class GroceryOrder {
 // Each order includes a map of
 // items which have been ordered.
 protected GroceryBill bill;
 protected Map<GroceryItem,Integer>
 itemCount;
 protected double totalAmount;
 protected int totalItems;
 /**
 * Add an item to the map.
 * @pre newItem != null
 * @post newItem’s count incremented
 * @post totalItems incremented
 */
 public void addItem(
 GroceryItem newItem) {…}
 /**
 * Compute current bill.
 * @pre true
 * @post getAmount() >= 0
 */
 public void computeBill() {…}
 /**
 * Finalize order.
 * @pre totalItems > 0
 * @post getAmount >= 0
 */
 public void checkOut() {…}
 /**
 * Gets total amount of order.
 * @pre true
 * @returns totalAmount
 */
 public double getAmount() {…}
}
class DeliveredGroceryOrder
 extends GroceryOrder {
 // orders which will be delivered to
 // customer’s home use a special
 // delivery inventory, have a minimum
 // order and a delivery charge is added.
 private static final double
MinDeliveryCharge = 5.00;
 private static final double
MinOrderAmount = 25.00;
 private List<GroceryItem> delivInventory;
 // list of deliverable items
 /**
 * @pre newItem != null &&
 * delivInventory.contains( newItem )
 * @post newItem's count incremented
 * @post totalItems incremented
 */
 public void addItem(GroceryItem newItem) {…}
 /**
 * Compute bill including delivery charge.
 * @pre true
 * @post getAmount() >= MinDeliveryCharge
 */
 public void computeBill()
 {…}
 /**
 * Finalize order.
 * @pre totalItems > 0
 * @pre getAmount() >= MinOrderAmount
 * @post getAmount() >= MinOrderAmount
 * + MinDeliveryCharge
 */
 public void checkOut() {…}
}
a) Complete the following table inserting the word ""same"", ""weaker"" or ""stronger"" for the preand postcondition of each method of the DeliveredGroceryOrder class to indicate
whether the condition is the same, weaker or stronger than the corresponding condition in
the super class.
precondition postcondition
addItem
computeBill
checkOut
 b) Is DeliveredGroceryOrder a proper subtype of GroceryOrder according to the Liskov
Substitution Principle? Briefly explain your answer.","a)
precondition postcondition
addItem stronger same
computeBill same stronger
checkOut stronger stronger
b) DeliveredGroceryOrder is not a proper subtype of GroceryOrder according to the LSP because the
preconditions on addItem and checkout are stronger. For the LSP to hold, preconditions in the
subclass must be weaker (or the same) and postconditions must be stronger (or the same).",Medium,'
728,SWE,"Consider a class that represents a ticket purchased for an event at a theatre.
class TheatreTicket {
 // The price of the ticket
 private double price;
 // The location of the seat for which the ticket has been bought
 private int row;
 private int seat;


 /**
 * Set the price of a ticket
 * @pre true
 * @post the ticket’s price = amount
 * @throws IllegalValueException (a runtime exception) when price <= 0
 */
 public void setPrice( double amount ) { … }
 /**
 * Set the location of the seat for which the ticket is purchased
 * @pre 0 < theRow <= 50 AND 0 < theSeat <= 100
 * @post the ticket’s row = theRow AND the ticket’s seat = theSeat
 */
 public void setLocation( int theRow, int theSeat ) { … }
 // The rest of the class is not shown
}
a. List the equivalence classes for the amount parameter of the setPrice method.
b. Write four test cases that result from applying the equivalence class partitioning and
boundary condition technique to the setLocation method. Your test cases must include at
least one typical case and at least one boundary case. For each test case, indicate the type of
the test case (i.e. typical or boundary).","a. amount > 0
amount <= 0
b. Some sample test cases (others were possible):
 1) theRow=25, theSeat = 50; typical
 2) theRow=1, theSeat = 1; boundary
 3) theRow=50, theSeat = 10; boundary
 4) theRow=49, theSeat = 1; boundary",Medium,'
729,SWE,"Using the methods in the Java Collection Framework, write a method
public static <E> void deleteAll(List<E> list, E obj)
which iterates through the list using an Iterator and deletes all the occurrences of the
object obj (i.e. all objects that are equals to obj). What is the time complexity of your
implementation in the cases that the method is passed an ArrayList and a LinkedList?","public static <E> void deleteAll(List<E> list, E obj ){
Iterator<E> itr = list.iterator();
while ( itr.hasNext() ) {
if ( obj.equals( itr.next() )
itr.remove();
}
}
This operation take O(n) time for LinkedList and O(n2
) for an ArrayList. ",Easy,'
730,SWE,"Using the methods in the Java Collection Framework, write a method
public static <E> List<Integer> getIndices(List<E> col, E obj)
which returns a list of the indices of the list that contain an occurrence of the object obj. ","public static <E> List<Integer> getIndices(List<E> lst, E obj) {
List<Integer> result = new ArrayList<Integer>();
ListIterator<E> itr = lst.listIterator();
while ( itr.hasNext() ) {
if ( obj.equals( itr.next() ) )
result.add(itr.previousIndex());
}
return result;
}
This operation take O(n) time. ",Easy,'
731,SWE,"Using the methods in the Java Collection Framework, write a method
public static <E> List<E> subst(List<E> list,E old,E new)
which accepts a list list, and two objects of type E and returns a new list containing the
elements in ","public static <E> List<E> subst(List<E> list,E old, E new) {
List<E> newlist = new ArrayList<E>();
Iterator<E> itr = list.iterator();
while ( itr.hasNext() ) {
 E nextElt = itr.next();
 if (nextElt.equals(old))
 newlist.add(new);
 else
 newlist.add( nextElt );
}
return newlist;
}",Easy,'
732,SWE,"Based on the class structure on page 2, implement
 public void addItem(GroceryItem newItem)
 which increments the count for newItem in the map itemCount. (Hint: you need to do
something different when newItem is in the map and when it isn’t).","public void addItem(GroceryItem newItem){
Integer count = itemCount.get(newItem);
if(count == null){
itemCount.put(newItem,1);
}
else
itemCount.put(newItem,count++);
totalItems++;
}",Easy,'
733,SWE,"Assume that a Dog class is defined as following:
public class Dog {
private String breed;
private String name;
private String gender;
public Dog(String aBreed, String aName, String aGender)
{ … }
public String getBreed() { … }
public String getName() { … }
public String getGender() { … }
/* Two Dog objects are equal if they have equal breeds,
genders, and names.
 */
public boolean equals(Object o) {…)
public int hashCode() { … }
…
}
Write the code for the equals method of this class.","public boolean equals( Object o ) {
if ( o == null )
return false;
if ( getClass() != o.getClass() )
return false;
Dog d = (Dog) o ;
return breed.equals(d.breed) && name.equals(d.name)
 && gender.equals(d.gender);
}",Easy,
734,SWE,"Given an arraylist of objects that are in a class that implement the Comparable interface,
suppose the elements of the arraylist are sorted in ascending order according to
compareTo. Write a recursive method to determine whether a give object is a member of
the arraylist. Your method should run in O(log n) time, where n is the length of the
arraylist. [In the exam, the API for standard classes used will be given in the appendix].
Hint: think about when to stop. Think about dividing the arraylist in half; if the element is
in the arraylist, which half would it be in? [First write a non-generic version, for example,
using String. Then write a generic version; note that the generic version is more difficult
than would be asked in an exam.]","Here is a solution that works on lists of strings
public static boolean findElt(List<String> sortedList, String elt){
int midpoint = sortedList.size()/2;
// base case
if (elt.equals(sortedList.get(midpoint)))
return true;
else if (sortedList.size()==1)
return false;
else if (elt.compareTo(sortedList.get(midpoint)) <0)
// recursive step
return findElt(sortedList.subList(0,midpoint),elt);
else
return
findElt(sortedList.subList(midpoint,sortedList.size()),elt);
}
Or a more generic answer:
public static <E extends Comparable<? super E>> boolean findElt
(List<E> sortedList, E elt) {
int midpoint = sortedList.size()/2;
// base case
if (elt.equals(sortedList.get(midpoint)))
return true;
else if (sortedList.size()==1)
return false;
else if (elt.compareTo(sortedList.get(midpoint)) <0)
// recursive step
return findElt(sortedList.subList(0,midpoint),elt);
else
return
findElt(sortedList.subList(midpoint,sortedList.size()),elt);
}",Medium,"https://www.cs.ubc.ca/~gabrielm/211/exams/FinalPracticeExercises-10w.pdf
https://www.cs.ubc.ca/~gabrielm/211/exams/FinalPracticeExercises-Solutions-10w.pdf"
735,SWE,"Provide an implementation for the following utility method named removeValuesFromMap
that takes a Map<K,V> and an item of type V as its only parameters and that removes all the
key-value pairs for which the value is equal to item. Assume that the equals() method has
been overridden for objects of type V.
public static <K,V> void removeValuesFromMap(Map<K,V> data, V item)
{
Write a method that is like the previous method, but returns a new map that contains all keyvalue of the original map except those where the value is item. The map that is the argument
must not be modified.","public static <K,V> void removeValuesFromMap( Map<K,V> data, V item )
 {
Set<K> keys = data.keySet();
Iterator<K> itr = keys.iterator();
while( itr.hasNext() )
{
K next = itr.next();
if( data.get( next ).equals( item ) )
itr.remove();
}
}


3. public static <K,V> Map<K,V> removeValuesInNewMap(Map<K,V> data, V item)
 {
 Map<K, V> newData = new HashMap<K, V>();

 Set<K> keys = data.keySet();
 Iterator<K> itr = keys.iterator();

 while(itr.hasNext())
 {
 K next = itr.next();
 V nextValue = data.get(next);
 if (nextValue.equals(item) == false)
 newData.put(next, nextValue);

 }
 return newData;
 }
 Or, you can do it with a foreach loop: 

public static <K,V> Map<K,V> removeValuesInNewMap(Map<K,V> data, V item)
 {
 Map<K, V> newData = new HashMap<K, V>();

 Set<K> keys = data.keySet();

 for (K next : keys)
 {
 V nextValue = data.get(next);
 if (nextValue.equals(item) == false)
 newData.put(next, nextValue);
}
 return newData;
 }",Medium,'
736,SWE,"After learning about threads, John decided to use them in a sorting program he was writing
for another assignment. His idea is to create a thread that will sort an array of numbers at the
same time that the main program is executing. He came up with the following program.
public class Sorter extends Thread {
private int[] data = null;
public Sorter( int[] data) {
this.data = data;
}
public void run() {
// Sort the data; This code is correct
for (int i = 0; i < data.length – 1; i++)
for (int j = 0; j < data.length – 1; j++)
if (data[j] < data[i]) {
int tmp = data[i];
data[i] = data[j];
data[j] = tmp;
}
}
public static void main( String args[] ) {
int[] data = new int[10];
// generate some random data to test
for (int i = 0; i < data.length ; i++)
data[i] = (int) (Math.random() * 100);
Sorter x = new Sorter(data);
x.start();
for (int i = 0; i < data.length ; i++)
System.out.println( data[i] );
}
}
The program is acting weird. The numbers printed out are sometimes sorted, sometimes are
partially sorted, and sometimes are not sorted at all. Find out what is wrong with this
program and what you need to do to fix it. Note that since sometimes the program prints the
numbers sorted, you can assume that the sort routine is working correctly.","The problem with the code is that the main thread doesn’t necessarily wait until the other thread
finishes before it begins printing the data. If we put a join statement for the sorting thread before
printing the data then the main thread will wait until the sorting is done to print the values in the arrays. 
7
Therefore we insert the following statements after the x.start() call (and before the print) in the
main method:
try {
x.join();
}
catch( InterruptedException e ) { } ",Medium,'
737,SWE,"In this question we imagine that we are trying to model a network connection between two
machines and that multiple threads are making connections between machines. In the
simplified example below, we have only two machines and two threads – one thread for each
machine. Each thread tries to repeatedly establish a connection from its machine to the other
machine and send a message. To establish the connection, we call connect() on one
machine and give it a reference to the other machine. The other machine must then
acknowledge() the request before a message can be sent. The code below represents an
attempt to model this problem. Note that the detail of how to send a message between the
machines is omitted.
public class Machine {
 private Lock machineLock;
 private String name;

 public Machine( String name ) {
 this.name = name;
 machineLock = new ReentrantLock();
 }

 public void connect( Machine other ) {
 machineLock.lock();
 try {
 System.out.println( ""Connecting "" + name + "" to "" + other.name );
 other.acknowledge();
 System.out.println( ""Connection established."" );
 }
 finally {
 machineLock.unlock();
 }
 }

 public void acknowledge() {
 machineLock.lock();
 try {
 System.out.println( name + "" acknowledged connection."" );
 }
 finally {
 machineLock.unlock();
 }
 }
}
public class NetworkAdmin extends Thread {
 private Machine machine;
 private Machine other;

 public NetworkAdmin( Machine m1, Machine m2 ) {
 machine = m1;
 other = m2; 
}

 public void run() {
 while( true ) {
 machine.connect( other );
 //send message
 //...
 //drop connection
 }
 }
}
public class NetworkApp {
 public static void main( String[] args ) {
 Machine m1 = new Machine( ""Machine 1"" );
 Machine m2 = new Machine( ""Machine 2"" );

 NetworkAdmin na1 = new NetworkAdmin( m1, m2 );
 NetworkAdmin na2 = new NetworkAdmin( m2, m1 );

 na1.start();
 na2.start();
 }
}
When the application runs, the following is displayed on the console:
Connecting Machine 2 to Machine 1
Machine 1 acknowledged connection.
Connection established.
Connecting Machine 1 to Machine 2
Connecting Machine 2 to Machine 1
after which there is no further output on the console.
a) What is the formal name given to the problem illustrated in this code?
b) Explain why this problem has arisen but do not attempt to explain how to fix it. Your
explanation must include a possible sequence of method calls (starting with
machine.connect( other );) run by each thread (na1 and na2) that gives rise to the
last two lines of output above. You should provide your explanation in point form – one
point for each method call. Your explanation must include the calls to lock() and
unlock() and the effect that these calls have on the ability to execute the enclosed critical
section(s) of code. Assume that no lock is held at the start of your sequence of method calls.","a) DEADLOCK
b)
• thread na1 calls connect( other ) on m1
• na1 locks m1's lock preventing any other thread from executing
critical sections of code in connect() or acknowledge() on m1.
• ""Connecting Machine 1 to Machine 2"" is printed on the console
• na1 is interrupted
• na2 calls connect( other ) on m2
• na2 locks m2's lock preventing any other thread from executing
critical sections of code in connect() or acknowledge() on m2
8
• ""Connecting Machine 2 to Machine 1"" is printed on the console
• na2 is interrupted
• na1 calls other.acknowledge() on m2 but cannot lock m2's lock
because na2 holds the lock on m2, so na1 waits for the lock on m2
• na2 calls other.acknowledge() on m1 but cannot lock m1's lock
because na1 holds the lock on m1, so na2 waits for the lock on m1
• we're now in a deadlock situation as each thread is waiting for
the other to release a lock",Hard,'
738,SWE,"What output is printed by the following program:
/*
* File: Problem2b.java
* --------------------
* This program doesn't do anything useful and exists only to test
* your understanding of method calls and parameter passing.
*/
import acm.program.*;
public class Problem2b extends ConsoleProgram {
public void run() {
int num1 = 2;
int num2 = 13;
println(""The 1st number is: "" + Mystery(num1, 6));
println(""The 2nd number is: "" + Mystery(num2 % 5, 1 + num1 * 2));
}
private int Mystery(int num1, int num2) {
num1 = Unknown(num1, num2);
num2 = Unknown(num2, num1);
return(num2);
}
private int Unknown(int num1, int num2) {
int num3 = num1 + num2;
num2 += num3 * 2;
return(num2);
}
}","The 1st number is: 78
The 2nd number is: 73",Easy,"https://see.stanford.edu/materials/icspmcs106a/28-practice-midterm.pdf
https://see.stanford.edu/materials/icspmcs106a/29-practice-midterm-solutions.pdf"
739,SWE,"In the early part of the 20th century, there was considerable interest in both England and the
United States in simplifying the rules used for spelling English words, which has always been a
difficult proposition. One suggestion advanced as part of this movement was the removal of all
doubled letters from words. If this were done, no one would have to remember that the name of
the Stanford student union is spelled ―Tresidder,‖ even though the incorrect spelling ―Tressider‖
occurs at least as often. If double letters were banned, everyone could agree on ―Tresider.‖
Write a method removeDoubledLetters that takes a string as its argument and returns a new
string with all doubled letters in the string replaced by a single letter. For example, if you call
removeDoubledLetters(""tresidder"")
your method should return the string ""tresider"". Similarly, if you call
removeDoubledLetters(""bookkeeper"")
your method should return ""bokeper"".
In writing your solution, you should keep in mind the following:
• You do not need to write a complete program. All you need is the definition of the method
removeDoubledLetters that returns the desired result.
• You may assume that all letters in the string are lower case so that you don’t have to worry
about changes in capitalization.
• You may assume that no letter appears more than twice in a row. (It is likely that your
program will work even if this restriction were not included; we’ve included it explicitly only
so that you don’t even have to think about this case.)","/*
* Removes any doubled letters from a string.
*/
private String removeDoubledLetters(String str) {
String result = """";
for (int i = 0; i < str.length(); i++) {
char ch = str.charAt(i);
if (i == 0 || ch != str.charAt(i - 1)) {
result += ch;
}
}
return result;
}",Easy,'
740,SWE,"The GoogleTM search engine (which was developed here at Stanford by Larry Page and Sergey
Brin) has rapidly become the search engine of choice for most users of the World Wide Web. A
couple of years ago, it also gave rise to a pastime called Googlewhacking that quickly became
quite popular among web surfers with far too much time on their hands. The goal of the game is
to find a pair of English words so that both appear on exactly one Web page in Google’s vast
storehouse containing billions of pages. For example, before they were listed on the
Googlewhacking home page, there was only one web page that contained both the word
ambidextrous and the word scallywags.
Suppose that you have been given a method
public String[] googleSearch(String word)
that takes a single word and returns an array of strings containing the URLs of all the pages on
which that word appears. For example, if you call
googleSearch(""scallywags"")
you would get back a string array that looks something like this:
http://www.scallywags.ca/
http://www.effect.net.au/scallywags/
http://www.scallywags1.freeserve.co.uk/
http://www.scallywagsbaby.com/
http://www.sfsf.com.au/ScallywagsCoaches/
http://www.theatlantic.com/unbound/wordgame/wg906.htm
http://www.maisemoregardens.co.uk/emsworth.htm
Each of the strings in this array is the URL for a page that contains the string scallywags. If you
were to call
googleSearch(""ambidextrous"")
you would get a different array with the URLs for all the pages containing ambidextrous.
Your job in this problem is to write a method
public boolean isGooglewhack(String w1, String w2)
that returns true if there is exactly one web page containing both w1 and w2. It should return
false in all other cases, which could either mean that the two words never occur together or that
they occur together on more than one page. Remember that you have the googleSearch method
available and therefore do not need to write the code that actually scans the World Wide Web
(thankfully!). ","/** Method: isGooglewhack(word1, word2)
 *
 * Returns true if word1 and word2 appear on exactly one web page,
 * as reported by googleSearch.
 */
 private boolean isGooglewhack(String word1, String word2) {
 String[] pages1 = googleSearch(word1);
 String[] pages2 = googleSearch(word2);
 int matches = 0;
 for (int i = 0; i < pages1.length; i++) {
 if (findStringInArray(pages1[i], pages2) != -1) {
 matches++;
 if (matches > 1) return false;
 }
 }
 return (matches == 1);
 }
/** Method: findStringInArray(key, array)
 *
 * Returns the index of the first occurrence of key in the array.
 * If key does not appear in the array, findStringInArray
 * returns -1.
 */
 private int findStringInArray(String key, String[] array) {
 for (int i = 0; i < array.length; i++) {
 if (key.equals(array[i])) return i;
 }
 return -1;
 } ",Medium,"https://see.stanford.edu/materials/icspmcs106a/46-practice-final-exam.pdf
https://see.stanford.edu/materials/icspmcs106a/47-practice-final-solutions.pdf"
741,SWE,"With respect to Distributed Transactions at Scale in Amazon DynamoDB by Idziorek et al., imagine
that a read-only transaction (TransactGetItems) and a read-write transaction (TransactWriteItems)
execute concurrently. The read-write transaction updates multiple items stored on different storage
nodes; the read-only transaction reads the same set of items. Serializability requires that the readonly transaction see all of the items as they were before the read-write transaction, or all as they
are after the read-write transaction (but not a mix of before and after).
6. [5 points]: For the above scenario, which mechanisms help to ensure this all-before or
all-after property? Refer to the design as described in the paper’s Sections 2 and 3 (but not
Section 4). Circle all that apply.
A. The item.timestamp < input.timestamp check in Listing 3.
B. Multiple time-stamped versions stored for each key.
C. Log sequence numbers (LSNs).
D. Two-phase locking.
E. item.ongoingTransactions","C and E are correct. A is not correct because read-only transactions do not involve
the time-stamps. B is not correct because DynamoDB doesn’t store multiple versions of a
given record. D is not correct because read-only transactions don’t use two-phase locking.",Medium,https://pdos.csail.mit.edu/6.824/quizzes/q25-2-sol.pdf
742,SWE,"Consider the paper, and guest lecture about, On-demand container loading in AWS Lambda by
Brooker et al. For each of the following statements, indicate whether it is true or false.
7. [8 points]:
True / False : AWS Lambda is attractive to customers because the customer can spawn many
lambdas in response to a load spike without having to provision machines in advance.
True / False : Replication of chunks in the AZ-level cache is important to ensure that chunks
are not lost forever when a cache node fails.
True / False : Erasure coding of cached chunks helps improve tail latency, because a worker
can reconstruct a chunk without having to download all stripes of the chunk.
True / False : The convergent encryption scheme described in Section 3.1 helps protect
against an attacker who compromises a worker and attempts to read containers of any customer","1. True; customers can spawn many Lambdas in response to a spike in load. 2. False;
AWS Lambda replicates for low latency instead of durability. 3. True; erasure coding allows the
client to reconstruct the data with a few stripes without having to wait for all stripes. 4. True; the
goal is that a worker can access only the data that it needs to run the function sent to it, but because
“any” is ambiguous we accepted False too.",Medium,'
743,SWE,"Consider the following Ray program, which creates a sqrt task task for each number in the list
mylist. The creation yields a DFut and the caller waits for the tasks to complete by calling get
on each future. The code is as follows:
# A call to sqrt_task yields a DFut
@ray.remote
def sqrt_task(n):
# sqrt is a python function, which returns the square root of its argument
return sqrt(n)
@ray.remote
def sum_task(f):
# sum is a python function, which takes a future and returns the sum
l = get(f) # collect the list l
return sum(l) # return the sum of the numbers in list l
# A call to sqrt_list_task yields a shared DFut
@ray.remote
def sqrt_list_task(n_list):
# start tasks and collect futures
l = [ ] # list holding DFuts
for i in n_list: # iterate over list of numbers
l.append(sqrt_task(i))
r = [ ]
for f in l:
r.append(get(f)) # collect the result
return r # return a SharedDFut for r
# invoke sqrt_list_task with a large list of numbers, sum, and print result
f = sqrt_list_task(mylist)
s = sum_task(f)
print(s)
Assume Ray behaves in the way described in Ownership: a distributed futures system for finegrained tasks by Wang et al., and Ray is running on a cluster of computers.
For each of the following statements, indicate whether it is true or false.
9. [8 points]:
True / False : a Ray worker may start running sum task before sqrt list task has
finished
True / False : the driver that invokes sum task receives the list with square-rooted numbers
from the worker that ran sqrt list task.
True / False : the driver is the owner for each future that sqrt task returns.
True / False : the driver is the owner for the shared future returned by sqrt list task.","1. True, since remote invocations are asynchronous. 2. False; the worker running sum task will fetch the data from the worker that ran sqrt list task. 3. False; the
worker who runs sqrt list task is the owner of these futures; 4. True; the driver starts
sqrt list task and is thus the owner.",Medium,'
744,SWE,"Bitcoin: A Peer-to-Peer Electronic Cash System, by Nakamoto, mentions in Section 4 that the
cryptographic hash of a valid block must start with a certain number of zero bits. Assume that the
hash algorithm is SHA-256, which returns a 256-bit hash.
11. [3 points]: You are trying to mine a new block. The required number of zero bits is
seven. You set the block’s 32-bit nonce field to a random value, and compute the SHA-256
hash of the block. What’s the probability that the first seven bits of the hash are zeros? Circle
the one best answer.
A. 1/2
B. 1/7
C. 1/128
D. 1/256
E. 1/249
F. 1/(2^32)",C (1/128) is correct.,Easy,'
745,SWE,"Ben runs a Bitcoin node. A few hours ago Ben’s node learned about block B747, which is a valid
block. Ben sees a transaction T27 in B747 that pays some money to a certain public key, signed by
the correct private key. Ben would like to steal the money involved in T27. He modifies his copy
of block B747 so that the payee’s public key in T27 is Ben’s own public key. He doesn’t change
anything else in B747. He modifies his Bitcoin node software to announce the block to other nodes
as if it were a valid block.
12. [3 points]: Which of the following will cause other Bitcoin nodes to decide that Ben’s
B747 is invalid? Circle all that apply.
A. The “Prev Hash” field in the next block in the chain doesn’t refer to Ben’s B747.
B. Other peers will already know about the real B747.
C. The “Prev Hash” field in Ben’s B747 isn’t valid.
D. The hash of Ben’s B747 won’t start with enough zeroes.
E. The signature in T27 in Ben’s B747 isn’t correct.","D and E are correct. A and B are not correct: peers have to at least temporarily
accept otherwise-valid blocks with no successor because they might turn out to be the start
of a new winning fork. C is not correct because Ben didn’t modify the Prev Hash field, so it
continues to refer to the predecessor of the original B747. D is correct because modifying the
block will modify its cryptographic hash; the real B747’s hash started with enough zeroes,
but a modified B747 is fantastically unlikely to happen also to start with enough zeroes. E is
correct because the signature was correct for T27’s original payee public key, so the signature
won’t be correct with Ben as the payee.",Medium,'
746,SWE,"Now Ben is designing a new crypto-currency system, identical to Bitcoin, except with a different
agreement scheme to resolve forks in the block-chain: instead of the longest fork winning, nodes
compute the hash of the last block in each fork, and the fork with the lowest last-block hash value
wins. Ben reasons that all nodes will compute the same hashes, and thus all nodes will agree about
which fork wins.
13. [3 points]: Why is Ben’s fork-resolution idea a disaster? Explain briefly.","In real Bitcoin, if an attacker wants to eliminate a transaction that occurs many
blocks in the past by creating a fork from before that transaction, the attacker has to sustain a
block mining rate faster than the main chain long enough to catch up, which requires compute
power believed to be too expensive for most attackers. But with Ben’s scheme, an attacker
only needs to mine a single block that happens to have a hash smaller than the corresponding
block in the main chain; then all nodes will switch to the attacker’s new short fork. The
attacker needs relatively little compute power to mine this single block.",Medium,'
747,SWE,"The MapReduce paper (MapReduce: Simplified Data Processing on Large Clusters, by Dean and
Ghemawat) says in Section 3.1 that the intermediate key space is partitioned among the R reduce
tasks using hash(key) mod R.
Thea is running the word-count MapReduce job (pseudo-code in the paper’s Section 2.1) on a
cluster with 10 worker machines. M is 20 and R is 40. There are no failures, the network is
reliable, no machines are slower than expected, and there is no competing work on any of the
machines or networks involved. The Map input is divided into 20 pieces of 16 megabytes each.
1. [5 points]: By mistake, the hash(key) function Thea is using with MapReduce always
returns 1. What effect will that have on the execution of the word-count job, compared to
using a well-behaved hash function? Circle the single best answer.
A. the job will produce incorrect final output
B. 10 times as much total CPU time will be needed for Reduce phase
C. 10 times as much total wall-clock time will be needed for Reduce phase
D. 40 times as much total CPU time will be needed for Reduce phase
E. 40 times as much total wall-clock time will be needed for Reduce phase
F. the job will never complete","C. The total amount of computation is unchanged, but it’s all done by one worker rather
than divided up in parallel among 10 workers. B is not correct because the total amount of work
doesn’t change; the only thing that the hash function changes is which worker does the work.",Medium,https://pdos.csail.mit.edu/6.824/quizzes/q25-1-sol.pdf
748,SWE,"Alyssa is experimenting with a linearizable put/get key/value storage service. Unlike Lab 2, her
key/value service has no versions; put calls look like put(key, value).
Alyssa has two clients. Client C1 executes this:
t = get(""x"")
put(""x"", t + 1)
At about the same time, client C2 executes this:
t = get(""x"")
put(""x"", t * 2)
Before either client starts, the value for key “x” in the storage system is 10. Both clients’ calls
complete without error. There is no other activity involving the storage system, and there are no
failures.
Suppose the history of the execution, in the style of Lecture 4, with values omitted, looks like this:
C1: |--Rx?--| |--Wx?--|
C2: |--Rx?--| |--Wx?--|
3. [5 points]: After both clients have finished, what could the resulting value of x be in the
storage system? (Circle all that apply)
A. 10
B. 11
C. 20
D. 21
E. 22","11 and 20. Both C1’s read and C2’s read see the initial value of x (10), so C1 writes
11 and C2 writes 20. The writes are concurrent, so linearizability allows either write to appear to
execute last, and thus provide the final value.",Medium,
749,SWE,"Alyssa has a database that supports serializable transactions. Records “x” and “y” both start out
containing the value 1. Alyssa starts three transactions at the same time:
T1:
BEGIN-X
temp1 = get(""x"")
temp2 = get(""y"")
put(""x"", temp1 + temp2)
END-X
T2:
BEGIN-X
temp1 = get(""y"")
put(""x"", temp1 * 2)
END-X
T3:
BEGIN-X
put(""y"", 3)
END-X
BEGIN-X marks the start of a transaction, and END-X marks the end. All three transactions
commit and finish. There are no aborts, deadlocks, or failures. There is no other activity in the
database.
When Alyssa looks at record “x” in the database after the transactions complete, she sees the value
5.
Briefly explain how the value 5 could have resulted from these transactions.","The database system could have executed the transactions one at a time, in the order T2,
T3, T1.",Easy,'
750,SWE,"Prof. Gale is developing a new Facebook app called “Yellow Brick Road” for maintaining a user’s
timeline, here represented as a time-ordered list e0, e1, . . . , en−1 of n (unchanging) events. (In
Facebook, events can never be deleted, and for the purposes of this problem, don’t worry about
insertions either.) The app allows the user to mark an event ei as yellow (important) or grey
(unimportant); initially all events are grey. The app also allows the user to jump to the next yellow
event that comes after the event ei currently on the screen (which may be yellow or grey). More
formally, you must support the following operations:
1. MARK-YELLOW(i): Mark ei yellow.
2. MARK-GREY(i): Mark ei grey.
3. NEXT-YELLOW(i): Find the smallest j > i such that ej is yellow.
Give the fastest data structure you can for this problem, measured according to worst-case time.
The faster your data structure, the better. ","Initialization takes O(n lg(lg(n))) time to insert all the yellow elements into a VEB
tree, V .
More importantly, each operation takes O(lg lg(n)) time. When a user asks to MARK-YELLOW(i),
then call V.insert(i) which takes O(lg lg(n)) time. When a user asks to MARK-GREY(i), then
call V.delete(i) which takes O(lg lg(n)) time. When a user asks to NEXT-YELLOW(i), then call
V.successor(i) which takes O(lg lg(n)) time.
Another slower solution used an AVL tree in place of a vEB for an O(lg(n)) runtime for the
operations. ",Hard,https://ocw.mit.edu/courses/6-046j-design-and-analysis-of-algorithms-spring-2015/resources/mit6_046js15_quiz1sols/
751,SWE,"You are in charge of the salary database for Meancorp, which stores all employee salaries in a 2-3
tree ordered by salary. Meancorp compiles regular reports to the Department of Fairness about the
salary for low-income employees in the firm. You are asked to implement a new database operation
AVERAGE(x) which returns the average salary of all employees whose salary is at most x.
(a) What extra information needs to be stored at each node? Describe how to

answer an AVERAGE(x) query in O(lg n) time using this extra information.
Describe how to modify INSERT to maintain this information. Briefly
justify that the worst-case running time for INSERT remains O(lg n). 
 ","(a) Each node x should store x.size — the size of the subtree rooted at x —
and x.sum — the sum of all the key values in the subtree rooted at x. For a value
x > 0, let Sx be the set of all keys less than or equal to x. Let Ax and Bx be the sum
and the size of Sx.
We can compute Ax as follows. Let u be the leaf with smallest key larger than x.
Finding u from the root only takes O(lg n) time by using SEARCH in a 2-3 tree. Now
consider the path from the root of the tree to u. Clearly, Ax is the sum of all leaves
that are on the left of this path. Therefore, Ax can be computed by summing up all
y.sum’s for every node y that is a left sibling of a node in the path. Since there are
only lg n such nodes y’s, computing Ax only takes O(lg n) time.
Computing Bx is similar: instead of summing up y.sum, we sum up y.size. Therefore, it also takes O(lg n) time to compute Bx.

Therefore, AVERAGE(x) which is Ax can be answered in O(lg n)) time.

(b) Maintaining x.size is similar to what was covered in recitation and homework. Maintaining x.sum is exactly the same: when a node x gets inserted, we simply
increase y.sum for every ancestor y of x by the amount x.key. When a node splits,
we recompute the x.sum attribute for the split nodes and its parent. Hence, INSERT
still runs in worst-case time O(lg n). ",Medium,https://ocw.mit.edu/courses/6-046j-design-and-analysis-of-algorithms-spring-2015/resources/solutions-to-final-exam/
752,SWE,"For your new startup company, Uber for Algorithms, you are trying to assign projects to employees.
You have a set P of n projects and a set E of m employees. Each employee e can only work on
one project, and each project p ∈ P has a subset Ep ⊆ E of employees that must be assigned to p
to complete p. The decision problem we want to solve is whether we can assign the employees to
projects such that we can complete (at least) k projects.
(a)	 [5 points] Give a straightforward algorithm that checks whether any subset of k

projects can be completed to solve the decisional problem. Analyze its time complexity in terms of m, n, and k.

(b)	 [5 points] Is your algorithm in part (a) fixed-parameter tractable? Briefly explain. 
","(a) For each n
k subsets of k projects, check whether any employee is required
by more than one project. This can be done simply by going each of the k projects p,
marking the employees in Ep as needed, and if any employee is marked twice, then
this subset fails. Output “yes” if any subset of k project can be completed, and “no”
otherwise.
 The time complexity is n
k ·m because there are n
k subsets of size k and we pay O(m)
time per subset (because all but one employee will be marked only once). Asymptotically, this is (n/k)km.

(b) No. An FPT algorithms requires a time complexity of nO(1)f(k). By contrast, in our running time, the exponent on n increases with k. ",Medium,'
753,SWE,"You are working on an enterprise software system written in Java. Your system
communicates with other systems at your company via an API that passes POJOs (Plain Old
Java Objects, which have no methods besides getters and setters for their fields) to the other
systems. One of your coworkers, Taylor, who is responsible for one of these other systems asks
you to implement a method on one of these POJOs that has some real functionality. Another
coworker, Blake, proposes implementing the functionality as a static method in a separate
utility class. Which implementation strategy would you choose, and why?
Complete the memo below.
Dear Taylor and Blake,
I think we should implement the feature
Circle one: as a member method / as a static method in a utility class
because","Dear Taylor and Blake,
I think we should implement the feature
as a static method in a utility class
because
we don’t want to change the whole architecture of how systems commu_x0002_nicate at your company. It’s better to work within the current design
to achieve this functionality, and to keep all systems consistent with the
current conventions.",Medium,https://gitlab.cs.washington.edu/cse403/old-exams/-/blob/master/2019wi-final-solution.pdf?ref_type=heads
754,SWE,"Your coworker, Casey, has discovered a bug in the open-source FancySoft project
that you’ve been using as part of your system. Casey suggests sending the following report to
the maintainers of FancySoft:
We’re having trouble with FancySoft. We ran it with -a foo, and it crashed. This
is really blocking us, which is super annoying. Pls help.
You don’t think you should send this bug report as-is. Complete the following email to your
coworker which describes the four most important distinct mistakes that your coworker has
made. (One sentence each.)
Dear Casey,
This bug report is a good start. Here are the four most important distinct things
you could improve","Dear Casey,
This bug report is a good start. Here are the four most important distinct things
you could improve:
(a) Describe your goal. What were you trying to achieve?
(b) Give enough information for reproducibility: the complete command
line, input files, the version of FancySoft, and any other relevant
environmental information. Just “-a foo” isn’t enough.
(c) Describe exactly what went wrong. What is the full output? Can
you attach the core dump file?
(d) Say what you have tried so far to understand or solve the problem.
(e) Tone is both informal and condescending — you’re asking them to
do something for you. Be nice about it.
(f) The language is not professional, such as use of “Pls”. This is a
problem and should be corrected, but it is not one of the most im_x0002_portant things wrong with the bug report.
Keep up the good work!",Medium,'
755,SWE,"Give three reasons it is more expensive to fix a bug that a customer encounters in
production than a bug that a developer discovers during development.","the developer has code paged in
• don’t build on a faulty foundation, which can cause redesign/reimplementation
of code built on the buggy code
• reputation: bad will from customers
• redeploying to customers costs money
• partial credit: harder to reproduce",Easy,'
756,SWE,"Usually, you should not commit generated files to a version control repository —
that is, those created by its build system. (Two reasons are that the file can be regenerated in
each clone, and generated files can contain conflicts that people cannot resolve.)
Give two reasons to commit generated files to a version control repository. Give a specific
goal or purpose","• You are using a non-hermetic tool that produces different binaries or other
generated files, and you want all members of your team to use identical
artifacts.
• The build process takes a very long time to run. (Say, hours to weeks.)
• The build tools are not available on some systems, or team members don’t
want to have to install them.
• You are deploying (say, populating a website) directly from your version
control repository, such as from the gh-pages branch of a GitHub repository",Easy,
757,SWE,"Your boss asks you to implement two unrelated features in your code. After
implementing the first feature, you test your code and discover a bug. You realize that this is
a deep bug and it might take an uncertain amount of time to fix. On the other hand, you are
sure that implementing the second feature is straightforward.
Explain why it is usually a better idea to fix the bug first.","Bugs in feature 1 may mask bugs in feature 2: if tests fail, you don’t know whether
it is due to a problem in the code for feature 1 or for feature 2. Feature 1 is still
fresh in your mind. Introducing another feature might change the behavior of the
bug or introduce more bugs (this is unlikely, but possible, given that the features
are unrelated).
Some common correct but not best answers:
• It is costlier to fix the bug later than earlier.
• It is better to prioritize uncertain tasks first.
• The bug is fresh in the developer’s mind and therefore easier to fix.
• If the bug is not fixed now, developer might forget about the bug or lose
context",Medium,https://gitlab.cs.washington.edu/cse403/old-exams/-/blob/master/2018sp-final-solution.pdf?ref_type=heads
758,SWE,"Frequently, the number of components in a project’s architecture diagram is the
same as the number of members of the team, and each member is responsible for one part.
Give a reason that this may be a good choice. Give a reason that this may be a bad choice.","• Clear division of tasks and responsibilities
• Sense of ownership encourages good work

• It’s harder to get feedback or help from others (including code review) if you are working on
your own.
• The bus number is 1.
• This may not distribute work fairly, or to people who are good at the specific work (eg, 2 UI
designers should work together on the UI rather than one being assigned to the back end).",Easy,'
759,SWE,"Some build systems use file timestamps to determine whether to rebuild other files
that depend on them. Give two reasons that using file checksums (hashcodes) is better than
using timestamps.","• The file dates might not be correct — they might be tampered with, or changed by copy
operations, or created on a machine whose clock is incorrect.
• Better build avoidance. If a previous step creates an identical artifact, it can be recognized
as such and no more building done, even though the dates have been updated.",Easy,'
760,SWE,"Partition testing runs just a subset of all possible tests. It splits up the input into
partitions, then executes one input from each partition. What property needs to be true, in
order for partition testing not to miss test failures?","In each partition, the program should behave the same: correctly on every input,
or erroneously on every input.",Easy,'
761,SWE,"Consider this function:
public int compute(int x, int y, int z) {
if (x > 0) {
return 2 * y + z;
} else if (x == 0) {
return 2 * y;
} else {
return z;
}
}
Your coworker proposes the following tests:
x = 1, y = 2, z = 3
x = 0, y = 2, z = 3
x = -1, y = 2, z = 3
Explain what is wrong with your coworker’s proposal.","Those aren’t actually tests, they’re just test inputs. They lack an oracle.",Easy,'
762,SWE,"State reasons that pair programming may deliver code with less functionality than
the same two people working independently.","(a) Some people don’t work and/or communicate effectively with another person
present. For instance, stopping to explain may interrupt flow.
(b) Need to explain/discuss tradeoffs and get consensus, preventing people from
going at their own pace. They might even over-discuss issues that aren’t all
that important in the big picture.
(c) For a straightforward task that these two developers can do relatively easily
(calling the developers “experienced” is a weak way of saying this), you
don’t need two people to mitigate risks in the design and coding, but pair
programming suffers a keyboard bottleneck.
(d) Two developers, not one, have to come up to speed on the problem and the
codebase; the learning period is amortized over fewer developer-hours.",Medium,https://gitlab.cs.washington.edu/cse403/old-exams/-/blob/master/2014sp-final-solutions.pdf?ref_type=heads
763,SWE,"State reasons that pair programming may deliver code with more functionality
code than the same two people working independently","(a) Creativity: more ideas to choose from, more likely to choose a good one and
not get stuck.
(b) Quick feedback, avoid poor design/implementation decisions. There are fewer
bugs because two pairs of eyes are looking at and thinking about the same
code. Catching bugs earlier is cheaper. Less need to go back and rework,
which is slow and costly.
(c) The two employees can keep each other on-task. Taking turns gives each a
break or change of pace without stopping work.",Medium,'
764,SWE,"The primary purpose of code review is to improve the code (or design, or tests —
whatever is being reviewed). State benefits of code review that do not improve such artifacts.","(a) Increases the bus number. Ensures that more people know the code. Teaches
(new) employees about the abstractions, techniques, and patterns used by the
system.
(b) Teaches every team member about design and programming practices and
tricks they might not know.
“Improve the documentation” is not a correct answer. That’s part of the code,
or else is a separate thing that is being reviewed in its own right.",Medium,
765,SWE,"If you discover a bug or other issue, you should fix it to improve your code quality.
What are other engineering practices are essential to improving the code quality, typically
after fixing the bug)?","(a) Look for similar problems in other parts of your code.
(b) Perform a postmortem; change your process/practice to avoid that kind of
mistake in the future.
(c) Write tests and/or add monitoring in case you do commit this or a similar
error in the future.
We did not accept “put the bug in the issue tracker, because not all bugs (for
example, those found during development) need to be added to the issue tracker,
and because that practice is not as important as the ones listed above.",Easy,
766,SWE,"Give two disadvantages of the direct instantiation model that can be solved by using the factory method or
factory class patterns.","(a) It creates a new thing, whereas you might want an existing one.
(b) It creates an object of a specified class (Date), whereas you might want a subclass.",Easy,'
767,SWE,"A computer screen displays a set of nested elements (such as windows, panes, and buttons). Cocoa dispatches
events from the inside out (visiting the smallest component first), whereas browsers dispatch events from the outside in
(visiting the largest component first).
State a design requirement that is convenient to implement in one of the models, but difficult or impossible in the other
model.
Model:","Model: Outside-in model
An outer component that must always run even if the inner component is also allowed to do some additional
work. An outer component pre-empting an inner component, such as when an entire pane is grayed out or
inactive.
Another answer:
Model: Inside-out model
An inner component completely pre-empting an outer component.
Three other common types of answers were accepted: When an event that comes before the other in the
dispatch order suppresses or overrides later events, when the results of handlers later in the dispatch order
are dependent on the results of previous handlers, and if a global or local handler always handles the event
and passing to other handlers is inefficient (this is a weaker answer).",Medium,'
768,SWE,"Suppose that component A depends on component B. State Java code constructs that could cause
this dependence. The answer should be English text, not code examples.","(a) a method of A takes a B as a parameter or returns a B as a result
(b) code in A calls a method in B, or reads or writes a field of B
(c) A subtypes or subclasses B
(d) A has a field of type B",Medium,'
769,SWE,"The dependency injection design pattern adds (“injects”) a dependency. Describe, in one phrase
each, where/when the dependency does not exist and where/when it does exist.","Does not exist: at compile time
Does exist: at run time
A few answers that clearly described how dependency injection changes or moves dependencies in
other ways were also accepted.",Easy,'
770,SWE,"Give an example of a design pattern whose use is obvious from a class diagram but not
from a sequence diagram. (Don’t choose one that is built into (some) programming languages, such
as inheritance.) Explain why, in 1 sentence.","Composite: the members of a class are of a type that allows similar operations (perhaps they implement an interface in common with the container class). Observer: especially easy if there’s an
hobservesi notation on an arrow.
For many patterns it’s possible to argue either way (and we were looking for your argument, not
just a name). A common pitfall here was conflating class and object diagrams.",Medium,https://gitlab.cs.washington.edu/cse403/old-exams/-/blob/master/2011sp-midterm-solutions.pdf?ref_type=heads
771,SWE,"Give an example of a design pattern whose use is obvious from a sequence diagram but not
from a class diagram. (Don’t choose one that is built into (some) programming languages, such as
iteration.) Explain why, in 1 sentence.","Factory: an actor creates an object in response to a call, and the caller subsequently sends messages
to the newly created object. Decorator: every message to the decorator object is followed by a call
to the object it decorates.",Easy,'
772,SWE,"Consider two components A and B. Two software engineers, Laurel and Hardy, measure the
dependences between A and B. Laurel uses these dependences when computing cohesion, and Hardy
uses these dependences when computing coupling. Is this possible, if both engineers are performing
a sensible and useful computation? In 1–2 sentences, explain why or why not.","Yes. Laurel is considering a larger module C that contains both A and B as implementation details.
Hardy is considering the implementation of C, and thinking of A and B as modules.",Easy,'
773,SWE,"In 1 sentence each, give two distinct reasons that you should not commit compiled code
(such as .o or .class files) to a version control repository.","• Merge conflicts cannot be resolved. Another way of saying the same thing is that binary files
are not diffable (by the standard text-based diff algorithms).
• Repetition of information in source and binary forms violates the DRY (don’t repeat yourself)
principle.
• Binary files such as .o files are architecture-dependent and may not be useful to others.
• Binary files may contain information such as timestamps that is guaranteed to create a conflict
even if generated from the same source code by others.
• Bloat in the VCS because differences are huge.
• Timestamps might not be preserved.
• If there is a check-in without compiling, then they can be inconsistent with the source code.",Medium,'
774,SWE," It is cheaper and faster to fix known bugs before you write new code. Why? In one phrase
or sentence each, give three reasons. Give reasons that are as different from one another as possible.","• You are familiar with the code now. A related reason is that the bug will be harder to find and
fix later.
• Later code may depend on this code. A related reason is that a bug may reveal a fundamental
problem.
• Leaving all bugs to the end will make it harder to understand and keep to the schedule, because
it’s hard to predict how long bug fixing will take.
• An overfull bug database is demoralizing and is likely to be ignored.
• You will be able to add tests for the bug once it’s been fixed to avoid future issues.
• Avoid feature creep.",Easy,
775,SWE,"After you find a bug but before fixing it, you should create a test case for it. In one sentence
each, give three reasons that this is a good idea. Give reasons that are as distinct as possible.","• Ensures that your fix solves the problem. Don’t add a test that succeeded to begin with! A
related reason is to avoid writing a test for a bug that you fixed, but that isn’t the problem
indicated by the original bug fix.
• It helps you understand the bug and define the desired system behavior. (“It documents the
bug” or “it informs others of the bug” is wrong, because it is the purpose of your bug tracking
system to document your bugs. If you meant something different, such as the good answers
listed here, then please be more specific.)
• It helps you know when you are done with bug fixing. A related reason is repeatability, and
efficiency when debugging: the test is easy to run in an automated way to determine whether
your fix works.
Here are some more answers we accepted, even though they are really just reasons to write a test
at all, and not reasons to write the test before you fix the bug:
• Helps to populate test suite with good tests. The test case may reveal other problems also, that
would make sense to fix at the same time.
• Protects against reversions that reintroduce bug. It happened at least once, and it might
happen again",Medium,
776,SWE,"Consider a wrapper whose implementation logs each call that occurs.
In no more than 2 sentences each, explain when the wrapper should be considered a decorator (and
why), and when that same wrapper should be considered a proxy (and why).","• Decorator: A decorator has different functionality but the same interface as the delegate.
If the wrapper’s specification requires it to do the logging, then it should be considered a
decorator.
• Proxy: A proxy has the same functionality and the same interface as the delegate. If the
wrapper has a lenient specification that permits but does not require it to perform logging,
then it should be considered a proxy.",Medium,https://gitlab.cs.washington.edu/cse403/old-exams/-/blob/master/2011sp-final-solutions.pdf?ref_type=heads
777,SWE,"Under what circumstances does a GUI show an hourglass/clock/spinning ball? Answer in
one phrase or sentence. Be specific.","When the program is not taking enough events off the event queue. The program may or may not
still be making progress, but it is not being responsive to the user.",Easy,'
778,SWE,"Your goal is to build a highly reliable system, so you run three independently-developed
programs (each developed to the same spec) on three separate computers, and use the majority answer.
Why doesn’t this significantly improve your reliability? Explain in one sentence","The different versions are likely to contain the same bugs. A study by Leveson and Knight showed
that programmers tend to make the same programming errors, and to misunderstand or misinterpret the spec in the same ways",Easy,'
779,SWE,To implement the singleton pattern often (but not always) requires using what other pattern?,factory pattern,Easy,'
780,SWE,"Suppose that each procedure in my program has a specification. I wish to
prove the whole program is correct; that is, each procedure satisfies its specification.
If the program has no recursion, it is easy to reason modularly — that is, one procedure
at a time. Here is how you could do that.
(a) First, prove correctness of each procedure at the leaves of the procedure call tree
(the ones that call no other procedure).
(b) Next, prove correctness of the procedures that call only the leaf procedures. During this process, it is valid to rely on the specifications of the leaf procedures, and
assume that each leaf procedure call does exactly what its specification says.
(c) Now, continue up the procedure call tree.
Now, suppose that the program contains recursion. When reasoning about a procedure
call (including a self-call) it would be circular reasoning to assume that the procedure
is correct if I have not already proved it — that is, to assume that the procedure is
correct in order to prove it correct.
What approach do you suggest in this circumstance? Explain why it works and any
potential downside. Use no more than 5 sentences. (It is possible for a 1- or 2-sentence
answer to get full credit.)","Use induction over the dynamic call graph (in other words, over the length
of an execution) rather than the static call graph.
The base case is a sequence of 1 run-time call; does each procedure’s base
case behave properly (that is, obey the specification if it terminates)?
The inductive case assumes that every sequence of ≤ n run-time calls behaves correctly, and shows (via examination of each procedure’s recursive
case) that every sequence of n run-time calls behaves correctly.
You also need to prove that the program terminates.",Medium,https://gitlab.cs.washington.edu/cse403/old-exams/-/blob/master/2009sp-final-solutions.pdf?ref_type=heads
781,SWE,"State 3 distinct benefits of writing tests before writing the code. No credit for answers that are a benefit of writing tests in general, whether
before or after writing the code.","• Can be done by someone other than the coder; permits parallelizing
human effort.
• Can reveal problems with the specification early.
• If the code exists, then it can bias a tester into the same thought
processes, leading the tester to make the same mistakes as the coder.
• You are more likely to actually write the tests, and they are more
likely to be complete.
• If no specification exists, tests can provide an approximation of one",Medium,'
782,SWE,"Exhaustive testing (testing every value in the input domain reveals every
defect, but is impractical. Partition testing splits the input domain into parts, and
chooses just one test for each of the parts. Partition testing reveals every defect, under
what condition? What might happen if some of the partitions are too large? What might happen if some of the partitions are too small?","If any input in a part reveals a defect, then every input in the part does.
(“Same behavior” instead of “reveals a defect” gets partial credit.)
Testing may miss errors, also known as suffering a false negative. You
could test a good input in a partition that contains a failure, and miss the
failure.
Testing may be inefficient: the suite may contain extra (unnecessary,
redundant) tests. But, the approach is still sound and reveals every defect.",Medium,'
783,SWE,"Name the two key advantages of factory methods, when compared to constructors. (Use no more than 10 words each.)","• Can return an existing object • Can return a subtype of the declared type More minor benefits include: • Being able to choose a name for the factory method (whereas all constructors are required to have the same name). • It can return null • It can be easily replaced by another factory, at run time or compile time • A single factory can return different subtypes, choose at run time which subtype to return",Easy,'
784,SWE,"What are two aspects of a software system that are explicitly omitted from
a UML class diagram?","• Timing/ordering of calls; in fact, all dynamic information. More generally, information that appears in other UML diagrams such as sequence diagrams.
• Implementation details such as algorithms, data structures, and the actual code.
• Implementation language.
We were not looking for answers like the user manual, webpage, requirements, etc. that
are part of your project but not part of the software system per se.",Easy,'
785,SWE,"Compare incremental (per-checkin) code reviews to comprehensive (wholemodule, but now whole-system) code reviews.
Give two benefits of incremental code reviews. Give two benefits of comprehensive code reviews. Give two differences in the mechanics of how they are typically performed.","Give two benefits of incremental code reviews.
• Quicker feedback if something is wrong with the code
• Prevents bugs from ever entering the codebase.
• Low cost per review.
• Incentive to write quality code and documentation from the beginning.
Common incorrect answers include:
• Easier to see problems in a specific part of the code.
• Find different types of problems.
Give two benefits of comprehensive code reviews.
• Reviewers get the big picture, can consider high-level design as well as low-level code
issues, can find to miss buggy interactions between changed code and non-modified
code.
• Gives an opportunity for brainstorming and discussion.
• Educates other developers.
• Does not require a reviewer who is already an expert on the code.
Give two differences in the mechanics of how they are typically performed.
• Comprehensive are more often face-to-face; incremental are more often electronic
(e.g., email).
• Incremental are more often before a checkin; comprehensive are more likely to be
(but by no means universally) after checkin.
• Incremental are more likely to be done by one other person; comprehensive are
more likely to be done by a group.",Hard,'
786,SWE,"For physical objects, maintenance is required to repair the effects of wear
and tear. For non-buggy software, what is the most frequent cause that requires
“maintenance”?","Use of the software in a new environment for which it was not originally
designed, but in which it is desired to be used.
Partial credit for specific examples of this. The best such example is new
user requirements. (That does not cover all cases, because users do not
usually think of the software they depend on, such as the format of results from a given website, as part of their requirements.) New features
are another good example. A bad example is operating system and programming language upgrades: they are rare, and they do not necessarily
require software to be changed.",Medium,'
787,SWE," In extreme programming, what code do you write before you write a module? Explain why","unit tests and testing infrastructure are written before the declarative code
for each module. This focuses the programmer on meeting the specified functionality
exactly, protecting him from unbounded abstraction. Unit tests are also clearly
helpful in detecting failures later.",Easy,https://hkn.eecs.berkeley.edu/examfiles/cs169_fa04_mt1.pdf
788,SWE,What is the connection between extreme programming and refactoring?,"Refactoring is central to XP, which emphasizes working, small-scope code and frequent
iteration. such practices demand constant structural redesign, which is refactoring:
reorganizing without changing functionality. Through this process the codebase
is both flexible and robust.",Easy,'
789,SWE,"When debugging programs, do you turn compiler optimizations on or off? Why?","You first turn them off, because otherwise the debugger will not be able to correlate
the executable with the source code. Then you turn them on, to find if the bug
only appears in the optimized version (e.g., due to timing issues)",Easy,'
790,SWE,Explain why 100% path coverage is not always sufficient to ensure absence of bugs.,"There are many good answers here. One that is shorter than what we expected,
is that testing cannot prove the absence of bugs. Also good answers, is that
just because you have tried all the paths at least once, it does not mean that
you have tried them with all input values. Many people also pointed out that
in code with loops the bug may surface only in a late iteration of the loop.",Medium,'
791,SWE,Why are data races hard to debug?,"Data races may manifest themselves only in rare interleaving of instructions, and the
scheduler does not interleave the threads in exactly the same way every time (depending
on the system, the system load, the needs and priorities of other processes that are running,
etc). Because races are often rare, it is difficult to find in the first place, and difficult
to track down (and to tell when you’ve fixed it) because you cannot reproduce it predictably.",Easy,'
792,SWE,"In a multi-threaded program do you have to worry about data races on local variables?
Explain your answer.","No, you do not have to worry about data races on local variables. Local variables are
not shared between threads, only global variables are. A local variable can be a pointer
to (shared) global data, but in this case it is the global data that needs to be locked
to protect from data races not the local pointer (all access to that shared data need
to use the same global lock).",Medium,'
793,SWE,What is regression testing and how do you use it effectively?,"Regression testing is a testing strategy where every time you find a bug you write
a test case to exhibit the bug, fix the bug, and add the test case to your test
suite. Ideally you run this entire test suite regularly on the program as it
changes (at CVS checkin, at every build, etc). This way you ensure that old bugs
do not reappear without you noticing (which happens frequently)",Easy,
794,SWE,"Ben runs an online tulip shop where he accepts Bitcoin as payment, 1 BTC for 1 tulip (these are
premium tulips). Upon seeing a payment transaction appear in the blockchain, Ben waits for 6
additional blocks before treating the payment as valid and shipping tulips to the buyer by overnight
Fedex.
12. [7 points]: Suppose an attacker owns 1 BTC, and the attacker gains control of 80%
of the Bitcoin network hash power for a period of 2 hours. Describe how this attacker could
cheat Ben’s store, such that on the next day, the attacker still has their 1 BTC and also has a
tulip.","The attacker should submit a transaction paying Ben the 1 BTC. In secret, the attacker
should mine a fork of blocks from the block *before* the block containing that transaction. After
Ben has shipped (i.e. after an hour), reveal the fork. It will be longer than the real fork due to
the 80%, so everyone will switch to it. But it doesn’t contain the payment to Ben, so the attacker
still owns the 1 BTC. To prevent Ben from re-broadcasting the transaction from the shorter fork on
what is now the main chain, the attacker should include a transaction in their fork to move their
Bitcoin to a different address.
Alyssa runs a virtual tulip shop implemented as an Ethereum smart contract. Her shop sells sells
tulip “tokens” for 1 ETH (ETH is the Ethereum currency). A tulip token is a purely virtual item,
whose ownership is represented in the state of Alyssa’s smart contract; no physical goods are
involved. Here’s what Alyssa’s Ethereum tulip smart contract state and external method look like:
// track how many tulip tokens each ETH address holds
private mapping (address => uint256) tulips;
function buy() external payable {
require(msg.value >= 1 eth); // sender has to transfer >= 1 ETH
tulips[msg.sender]++; // sender gains a tulip token
}",Hard,https://pdos.csail.mit.edu/6.824/quizzes/q22-2-sol.pdf
795,SWE,"Ben runs an online tulip shop where he accepts Bitcoin as payment, 1 BTC for 1 tulip (these are
premium tulips). Upon seeing a payment transaction appear in the blockchain, Ben waits for 6
additional blocks before treating the payment as valid and shipping tulips to the buyer by overnight
Fedex.
13. [7 points]: Suppose an attacker owns 1 ETH, and the attacker gains control of 80% of
the Ethereum network hash power for a period of 2 hours. Could the attacker cheat Alyssa’s
store, such that on the next day, the attacker still has their 1 ETH and also has a tulip token?
Why or why not?","The attacker cannot cheat. The attacker could produce a longer fork (as for the above
Bitcoin question). But if the longer fork omits the ETH transfer, it must also omit the change to the
smart contract state that increments the attacker’s tulip token count.",Medium,'
796,SWE,"Alyssa P. Hacker is writing an application that stores data in a key/value server. She uses a clientside library that provides get() and put() functions using RPC calls to the server. The library
and key/value server together guarantee linearizable behavior at the level of library calls (that is,
the operations that are linearizable are put() and get() function calls as executed by the application).
Alyssa decides that, since put() does not return a value, there is no point in waiting for it to
complete. She modifies the library so that put() returns immediately after starting a separate
goroutine to send the request to the server.
For this question you should assume that there are no computer crashes and no network problems.
9. [7 points]: Will Alyssa’s modified library result in linearizable behavior? Explain why
or why not.","No. put(x,0); put(x,1); get(x) may yield zero, since put()s are executed concurrently.
Linearizability requires that the serial order obey real time; this means that the only legal serial
order is that shown above (the order in which the application performed the operations). gets are
required to see the value of the most recent put, so the get should have returned 1, not zero.",Medium,https://pdos.csail.mit.edu/6.824/quizzes/q18-1-sol.pdf
797,SWE,"Ben Bitdiddle finds the following Spark code for processing ad click logs in his company’s source
code repository:
1 // click logs: DATE,TIME,USER,AD_ID
2 clog_may = spark.textFile(""hdfs:///prod/logs/2018/05/click*.log"", 10)
3 clog_jun = spark.textFile(""hdfs:///prod/logs/2018/06/click*.log"", 10)
4 // ads: AD_ID,PRICE_PER_CLICK
5 ads = spark.textFile(""hdfs:///proc/ads/current"", 10)
6 .map(_.split("",""))
7 .map(x => (x(0), x(2).toFloat))
8 // clogs: (AD_ID, USER)
9 clogs = clog_may.union(clog_jun)
10 .map(x => { val f = x.split("",""); (f(3), f(2)) })
11 .persist()
12 // combined: (USER, PRICE_PER_CLICK)
13 combined = clogs.join(ads) // by AD_ID
14 .map(x => x._2)
15 // user_rev: (USER, aggregate click revenue)
16 user_rev = combined.reduceByKey((x, y) => x + y)
17 // save user with the maximum aggregate click revenue
18 user_rev.max().saveAsTextFile(""hdfs:///tmp/top_revenue_user"")
Note: .split("",""), x => (...), and x => {...} are all syntax for single-argument
closures in Scala; field numbers and indices into arrays are zero-based; x. 2 extracts the second
element of a tuple; and the numeric argument to textFile denotes the number of partitions to
split the input into.
3. [5 points]: Spark will generate an RDD lineage graph for this code. The graph contains
11 RDDs (one for each bold operation). For which operators will Spark perform a “shuffle”
of data?","join, reduceByKey, max",Medium,https://pdos.csail.mit.edu/6.824/quizzes/q18-2-sol.pdf
798,SWE,"V Concurrency Control
Suppose you have a storage system that provides serializable transactions, and that can abort transactions.
The database holds three objects, x, y, and z, with these initial values:
x = 1
y = 2
z = 0
Only two transactions execute, and they start at about the same time. This is what they do:
T1:
x=10
y=20
T2:
temp = x + y
z = temp
10. [8 points]: Which final values are possible (after each transaction has either aborted or
finished committing and applying all updates)? Mark each of the following as “yes” or “no”.
a. Yes / No x=1 y=2 z=0 
b. Yes / No x=1 y=2 z=30 
c. Yes / No x=1 y=20 z=21 
d. Yes / No x=10 y=20 z=3 
e. Yes / No x=10 y=20 z=30 ","a. Yes / No x=1 y=2 z=0 Answer: yes
b. Yes / No x=1 y=2 z=30 Answer: no
c. Yes / No x=1 y=20 z=21 Answer: no
d. Yes / No x=10 y=20 z=3 Answer: yes
e. Yes / No x=10 y=20 z=30 Answer: yes",Medium,https://pdos.csail.mit.edu/6.824/quizzes/q1-17-ans.pdf
799,SWE,"Suppose you have a storage system that provides serializable transactions, and that can abort transactions.
The database holds three objects, x, y, and z, with these initial values:
x = 1
y = 2
z = 0
Only two transactions execute, and they start at about the same time. This is what they do:
T1:
x=10
y=20
T2:
temp = x + y
z = temp

Suppose T2 has just executed its first line, but has not tried to commit. If
the transaction system uses pessimistic two-phase locking, can the first line of T2 see x=10
and y=2? How, or why not?","No. If x is 10, but y still has its old value, then T1 must have started committing
but not finished. Two-phase locking requires that T1 hold all its locks until it completes the
commit. Thus T2 cannot acquire either lock, and thus can’t read either value.",Medium,'
800,SWE,"Suppose you have a storage system that provides serializable transactions, and that can abort transactions.
The database holds three objects, x, y, and z, with these initial values:
x = 1
y = 2
z = 0
Only two transactions execute, and they start at about the same time. This is what they do:
T1:
x=10
y=20
T2:
temp = x + y
z = temp

Suppose T2 has just executed its first line, but has not tried to commit. If
the transaction system uses optimistic concurrency control (e.g. FaRM), can the first line of
T2 see x=10 and y=2? How, or why not?","Yes. OCC allows T2 to read whatever values x and y have, even if T1 is executing
or committing and hasn’t finished. T1 might be in the middle of committing, and have
updated x but not y; this would cause T2 to see x=10 and y=2. However, T2 would not be
allowed to commit.",Medium,'
801,SWE,"John owns one bitcoin, transferred to him in transaction T1 in block B1. He spends the coin in
transaction T2 in block B2. A few hours later John realizes that the recipient public key he put into
T2 is incorrect. He’d like to un-do transaction T2 so that he can spend his coin again. He modifies
his Bitcoin peer software to generate a block B2a that has the same predecessor block as B2, but
does not contain transaction T2. B2a is a valid block. After generating B2a, John’s peer sends the
block to other Bitcoin peers.
12. [6 points]: Explain why John’s actions are not likely to allow him to successfully spend
his coin again.","John’s fork of the blockchain will only be accepted by other Bitcoin peers if his
fork is longer than the main fork. It will likely take John so long to produce B2a that by then
the main blockchain will have many additional blocks, so no peer will accept B2a.",Medium,https://pdos.csail.mit.edu/6.824/quizzes/q2-17-ans.pdf
802,SWE,"Imagine that there are so many Bitcoin peers and miners operating on the MIT campus network
that they make up one quarter of the total Bitcoin peers and mining CPU power.
Late one Friday evening, MIT’s links to the Internet break. The links are not repaired until Monday
morning, so MIT is disconnected from the Internet for more than two days. During that time,
communication continues to work within the MIT campus net. The Bitcoin peers and miners
inside MIT can all talk to each other (i.e. they flood transactions and blocks among themselves),
so they form a functioning Bitcoin system.
On Saturday, Alyssa attempts to double-spend in the following way. She owns a single bitcoin,
which was transferred to her in a transaction that existed well before MIT’s network links failed.
She sets up two laptops, initially with their network interfaces turned off, each with a copy of her
Bitcoin private key and the Bitcoin wallet she uses.
Alyssa connects one laptop to the MIT campus network and uses her bitcoin to buy an MIT T-shirt
from a store on the campus network; the T-shirt costs an entire bitcoin. Her wallet software signs
a transaction transferring the bitcoin to the store, and floods the transaction to some MIT peers so
that they will incorporate the transaction into the next block.
Then Alyssa takes her second laptop down the street to a cafe whose connection to the main Internet
works (though of course she cannot contact any MIT computers from the cafe). She connects the
laptop to the network, and buys a Stanford T-shirt from an online store; this T-shirt also costs a
whole bitcoin. Her wallet software signs a transaction transferring her bitcoin, this time to the
Stanford store, and floods the transaction to some (non-MIT) peers reachable on the Internet.
For both stores, if they see a valid transaction in the block-chain corresponding to an order, they
wait until the transaction is a few blocks back in the block-chain before they ship anything. Both
stores ship on weekends.
13. [6 points]: Will Alyssa be able to successfully double-spend? Explain why, or why
not.
Explain what will happen to Alyssa’s bitcoin after MIT’s Internet link is
fixed.","Yes, because the peers at MIT are likely to be able to mine 6 blocks before the end
of the weekend and thus the MIT store is likely to accept Alyssa’s transaction in the chain.

The MIT blockchain will likely be shorter than the blockchain on the main Internet,
because MIT has less mining power than the main part of the Bitcoin system. Thus all MIT
peers will switch to the longer main blockchain. This will cause Alyssa’s transaction with
the MIT store to disappear, and preserve her transaction with the Stanford store.",Hard,'
803,SWE,"In at most a few sentences, explain the difference between an instance method and a class
method.","In an instance method, this is bound to the receiver object of a method called, e.g.,
in the execution of m in the call o.m(x), this is bound to o. A class method is one that can be
invoked via the class name, and this is not available in the method body",Easy,https://www.cs.tufts.edu/comp/180-2020s/exams/f-s20-soln.pdf
804,SWE,"In at most a few sentences, explain the difference between black box testing and glass box (a.k.a. clear box a.k.a. white box) testing.","Black box testing test the program based on its specification, independently (in theory)
of its implementation. Glass box testing looks at the implementation to determine test cases.",Easy,'
805,SWE,"In at most a few sentences, explain what refactoring software means. Also briefly explain
why refactoring is useful.","Refactoring means changing a program’s code without changing the program’s behavior. Refactoring is useful to help evolve the design of software over time so that future changes
are easier to make. A key feature of refactoring is that, before and after a refactoring, the same
set of test cases pass.",Easy,'
806,SWE,"n the KLEE symbolic executor, when execution reaches a branch, KLEE may potentially
fork execution to explore both branches. Suppose we were to apply KLEE to Java. In addition to if and
switch statements, list three more kinds of Java expressions and/or statements at which KLEE may possibly
fork execution (i.e., list places in Java that conditionally branch at runtime).","Loops (for, while); dynamic dispatch (o.m(...)); field access because an exception may
be raised for a null object (o.f); catch because the exception might or might not match; operations
that do comparisons and return booleans x<y, x>y, etc.; checked downcasts that may or may
not succeed ((T) e); the instanceof operation.",Medium,'
807,SWE,"In  at most a few sentences, define confidentiality and integrity.","Confidentiality means sensitive data does not leak from the program to an adversary.
Integrity means that an adversary cannot modify the sensitive data of a program.",easy,'
808,SWE,"Consider the Regex interface and implementations:
interface Regex { }
class RChar implements Regex { public final char c; RChar(char c) { ... } }
class RSeq implements Regex { public final Regex left , right ; RSeq(Regex left, Regex right ) { ... } }
class ROr implements Regex { public final Regex left , right ; ROr(Regex left, Regex right ) { ... } }
class RStar implements Regex { public final Regex re; RStar(Regex re) { ... } }
Below is the standard visitor interface. Implement the accept method for classes RChar, RSeq,
ROr, and RStar. Your code should do a postorder traversal, in which the children are visited, left-to-right,
before the parent.
interface Visitor { void visit (RChar re); void visit (RSeq re); void visit (ROr re); void visit (RStar re ); }
interface Regex { void accept( Visitor v ); }
// Here’s a start to the code you need to write
// Be sure to write all four classes !
","class RChar implements Regex { void accept(Visitor v) { v. visit ( this ); } }
class RSeq implements Regex { void accept(Visitor v) { left .accept(v ); right .accept(v ); v. visit ( this ); }
class ROr implements Regex { void accept(Visitor v) { left .accept(v ); right .accept(v ); v. visit ( this ); }
class RStar implements Regex { void accept(Visitor v) { re .accept(v ); v. visit ( this ); }",Hard,'
809,SWE,"Consider the Regex interface and implementations:
interface Regex { }
class RChar implements Regex { public final char c; RChar(char c) { ... } }
class RSeq implements Regex { public final Regex left , right ; RSeq(Regex left, Regex right ) { ... } }
class ROr implements Regex { public final Regex left , right ; ROr(Regex left, Regex right ) { ... } }
class RStar implements Regex { public final Regex re; RStar(Regex re) { ... } }
Write a visitor StarCount such that the sequence sc = new StarCount(); re.accept(sc); int x =
sc.count; sets x to the number of RStar’s in re. For example, if re were new ROr(new RStar(new RChar(’a’)),
new RStar(new RChar(’b’))), then x would be 2.
","class StarCount implements Visitor {
int count;
void visit (RChar re) { } void visit (RSeq re) { } void visit (ROr re) { }
void visit (RStar re) { count++; }
}",Hard,'
810,SWE,"Consider the Regex interface and implementations:
interface Regex { }
class RChar implements Regex { public final char c; RChar(char c) { ... } }
class RSeq implements Regex { public final Regex left , right ; RSeq(Regex left, Regex right ) { ... } }
class ROr implements Regex { public final Regex left , right ; ROr(Regex left, Regex right ) { ... } }
class RStar implements Regex { public final Regex re; RStar(Regex re) { ... } }
Write a visitor Example such that the sequence ex = new Example(); re.accept(ex); String
x = ex.str; returns one example string matched by re. For example, if re were new ROr(new RChar(’a’),
new RChar(’b’)), then x could be either a or b. Hint: If you need, you can add field(s) to the classes that
implement Regex. You can’t just add a field to the interface because such fields are public, static, and final.
You might find the following API methods useful:
class Character { public static String toString (char c ); }
class String { public String concat(String str ); }
","class Example implements Visitor {
class RChar { String str ; } class RSeq { String str ; }
class ROr { String str ; } class RStar { String str ; }
class Example implements Visitor {
String str = ””;
void visit (RChar re) { re . str = Character. toString ( re .c ); }
void visit (RSeq re) { re . str = re. left . str .concat(re . right . str ); }
void visit (ROr re) { re . str = re. left . str ; }
void visit (RStar re) { re . str = ””; }
}",Hard,'
811,SWE,"Consider the Regex interface and implementations:
interface Regex { }
class RChar implements Regex { public final char c; RChar(char c) { ... } }
class RSeq implements Regex { public final Regex left , right ; RSeq(Regex left, Regex right ) { ... } }
class ROr implements Regex { public final Regex left , right ; ROr(Regex left, Regex right ) { ... } }
class RStar implements Regex { public final Regex re; RStar(Regex re) { ... } }
The Visitor interface for the first three parts of this problem always performs a postorder
traversal. Propose an alternative design and implementation for the Visitor interface and the accept methods
so that Visitors can specify whether to do a pre- or postorder traversal (preorder means visiting the node
before the children). Describe your design concisely and precisely.","There are many possible answers. One idea is to add a method or a field to the visitor
specifying the order
interface Visitor { ... boolean preorder (); /∗ true for preorder , false for postorder ∗/ }
Then the preorder() flag can be tested inside the accept methods, e.g.,
class RSeq implements Regex {
void accept( Visitor v) {
if (v. preorder ()) { v. visit ( this ); }
left .accept(v );
right .accept(v );
if (!v. preorder ()) { v. visit ( this ); }
}
}",Medium,'
812,SWE,"In this question, you will implement an alternative design for assertions
in which assertions are objects that implement the following interface:
interface Checker<T> {
boolean check(T x); // returns true if x passes the check, false otherwise
}

Implement five classes, Null, Equals, Not, All, and Some that implement Checker<T>, with
the following constructors:
Constructor check(x) Behavior
Null() Returns true if and only if x is null
Equals(Object y) Returns true if and only if y.equals(x)
Not(Checker<T> c) Returns true if c.check(x) returns false, and vice-versa
Some(Checker<T>[] c) Returns true if at least one c[i].check(x)’s returns true, and false otherwise
For example, if c = new Some(new Checker<String>[] { new Null(), new Equals(”COMP”); }), then c.check(”COMP”)
== c.check(null) == true and c.check(”MATH”) == false.","class Null<T> implements Checker<T> {
boolean check(T x) { return x == null; }
}
class Equals<T> implements Checker<T> {
T y;
Equals(Object y) { this .y = y; }
boolean check(T x) { return y. equals(x ); }
}
class Not<T> implements Checker<T> {
Checker<T> c;
Not(Checker<T> c) { this.c = c; }
boolean check(T x) { return !c.check(x ); }
}
class Some<T> implements Checker<T> {
Checker<T>[] cs;
Some(Checker<T>[] cs) { this.cs = cs; }
boolean check(T x) {
for (Checker<T> c : cs) { if (c.check(x)) { return true; } }
return false ;
}
}
Note: I saw a lot of solutions that had code like if (something) { return true; } else { return false;
}. This can be replaced simply by return(something).",Hard,'
813,SWE,"In this question, you will implement an alternative design for assertions
in which assertions are objects that implement the following interface:
interface Checker<T> {
boolean check(T x); // returns true if x passes the check, false otherwise
}

Supporse, you implemented a fluent interface for assertions that looked like the following:
String s = ...;
Assertion .assertThat(s ). isNotNull (). startsWith (”COMP”);
From the perspective of a developer writing test cases, compare and contrast the assertion style from Project
3 with the assertion style from part a of this problem. List some advantages and disadvantages of each style.","Many answers are possible! The most obvious difference is that in project 3, an
assertion is a chain of calls whose assertions are conjoined. In fact, it is rather difficult in the
syntax of p3 to implement not and or in a simple way, and it’s essentially impossible to introduce
parentheses for grouping without extending the notation. On the other hand, the notation from
project 3 is much more compact and doesn’t scatter news all over the place, though that could
be fixed by introducing some methods to construct the checkers.",Medium,'
814,SWE,"Recall the pipe and filter software architecture, in
which filters transform input streams to output streams, and pipes connect up filters. In this problem, you
will implement a number of methods for working with pipes and filters.
In this problem, a filter is an object that implements the following interface:
interface Filter <T> {
T next (); // returns null if no next element
}
In words: A Filter is an object f such that calling f.next(); returns the next element from the filter. Notice
that a filter is parameterized by its output type.
For example, here is a filter that consumes integers from its input and returns their squares:
class Square {
Filter <Integer> g;
Square( Filter <Integer> g) { this .g = g; }
Integer next() {
Integer i = g.next ();
if ( i == null) { return null ; }
return i∗i ;
}
For example, if g is a filter such that calling g.next() successively returns 0, 1, 2, 3, null, null, . . ., then if we
set f = new Square(g), then calling f.next() will successively return 0, 1, 4, 9, null, null, . . ..
For some of the problems below, you’ll need to use the following utility class:
class Pair<K,V>
Pair(K k, V v) − construct a pair of key k and value v
getKey() − return the key
getValue() − return the value

Write a filter Ints such that f = new Ints(n) produces a filter f such that successively calling
f.next() returns 0, 1, . . ., n, null, null, . . ..
","class Ints implements Filter<Integer> {
int next, last ;
Ints (int last ) { this . last = last ; }
Integer next() {
if ( i > last) { return null ; }
int tmp = next; next++; return tmp;
} }",Hard,'
815,SWE,"Recall the pipe and filter software architecture, in
which filters transform input streams to output streams, and pipes connect up filters. In this problem, you
will implement a number of methods for working with pipes and filters.
In this problem, a filter is an object that implements the following interface:
interface Filter <T> {
T next (); // returns null if no next element
}
In words: A Filter is an object f such that calling f.next(); returns the next element from the filter. Notice
that a filter is parameterized by its output type.
For example, here is a filter that consumes integers from its input and returns their squares:
class Square {
Filter <Integer> g;
Square( Filter <Integer> g) { this .g = g; }
Integer next() {
Integer i = g.next ();
if ( i == null) { return null ; }
return i∗i ;
}
For example, if g is a filter such that calling g.next() successively returns 0, 1, 2, 3, null, null, . . ., then if we
set f = new Square(g), then calling f.next() will successively return 0, 1, 4, 9, null, null, . . ..
For some of the problems below, you’ll need to use the following utility class:
class Pair<K,V>
Pair(K k, V v) − construct a pair of key k and value v
getKey() − return the key
getValue() − return the value

Suppose f and g are filters such that f.next() and g.next() return f0, f1, . . ., and g0, g1, . . .,
respectively. Write a filter Mix such that m = new Mix(f, g) is a filter such that m.next() returns f0, g0,
f1, g1, . . ., alternating between f and g and starting with f. As soon as one of f.next() or g.next() returns
null, then m.next() should return null from then on. Hint: Don’t worry about getting the constructor type
signature exactly right.","class Mix implements Filter<Object> {
Filter <? extends Object> left, right ;
boolean which; // false = left , true = right
Object last = new Object();
Mix( Filter <? extends Object> left, <? extends Object> right) {
this . left = left ; this . right = right;
}
Object next() {
if ( last == null) { return null ; }
if (which) { last = right.next (); } else { last = left .next (); }
which = !which;
return last ;
}",Hard,'
816,SWE,"Recall the pipe and filter software architecture, in
which filters transform input streams to output streams, and pipes connect up filters. In this problem, you
will implement a number of methods for working with pipes and filters.
In this problem, a filter is an object that implements the following interface:
interface Filter <T> {
T next (); // returns null if no next element
}
In words: A Filter is an object f such that calling f.next(); returns the next element from the filter. Notice
that a filter is parameterized by its output type.
For example, here is a filter that consumes integers from its input and returns their squares:
class Square {
Filter <Integer> g;
Square( Filter <Integer> g) { this .g = g; }
Integer next() {
Integer i = g.next ();
if ( i == null) { return null ; }
return i∗i ;
}
For example, if g is a filter such that calling g.next() successively returns 0, 1, 2, 3, null, null, . . ., then if we
set f = new Square(g), then calling f.next() will successively return 0, 1, 4, 9, null, null, . . ..
For some of the problems below, you’ll need to use the following utility class:
class Pair<K,V>
Pair(K k, V v) − construct a pair of key k and value v
getKey() − return the key
getValue() − return the value

Write a filter Zip such that, if f is a filter such that f.next() returns f0, f1, . . ., and g is a filter
such that g.next() returns g0, g1, . . ., then if z = new Zip(f, g), then z.next() returns new Pair(f0, g0), new
Pair(f1, g1), . . .. If either f.next() or g.next() returns null, then z.next() should return null (not new Pair(null,
null)!).","class Zip implements Filter<Pair<T, U>> {
Filter <T> f; Filter<U> g;
Zip( Filter <T> f, Filter<U> g) { this.f = f; this .g = g; }
Pair<T, U> next() {
T left = f.next (); U right = g.next ();
if ( left == null || right == null) { return null ; }
return new Pair( left , right );
} }",Hard,'
817,SWE,"Recall the pipe and filter software architecture, in
which filters transform input streams to output streams, and pipes connect up filters. In this problem, you
will implement a number of methods for working with pipes and filters.
In this problem, a filter is an object that implements the following interface:
interface Filter <T> {
T next (); // returns null if no next element
}
In words: A Filter is an object f such that calling f.next(); returns the next element from the filter. Notice
that a filter is parameterized by its output type.
For example, here is a filter that consumes integers from its input and returns their squares:
class Square {
Filter <Integer> g;
Square( Filter <Integer> g) { this .g = g; }
Integer next() {
Integer i = g.next ();
if ( i == null) { return null ; }
return i∗i ;
}
For example, if g is a filter such that calling g.next() successively returns 0, 1, 2, 3, null, null, . . ., then if we
set f = new Square(g), then calling f.next() will successively return 0, 1, 4, 9, null, null, . . ..
For some of the problems below, you’ll need to use the following utility class:
class Pair<K,V>
Pair(K k, V v) − construct a pair of key k and value v
getKey() − return the key
getValue() − return the value

Suppose f is a Filter<Pair<T, U>> such that f.next() returns (f0, g0), (f1, g1), . . ., where
(x, y) is shorthand for new Pair(x, y). Write a method split such that if p = split(f), then p is a Pair<Filter<T>,
Filter<U>> that behaves as follows. Let k = p.getKey() and v = p.getValue(). Then k.next() returns f0, f1,
. . ., and v.next() returns g0, g1, . . .. The calls to k.next() and v.next() may be interleaved, and it should not
affect the result. For example, k.next(); v.next(); k.next(); v.next(); would return f0, g0, f1, g1, and k.next();
k.next(); v.next(); v.next(); would return f0, f1, g0, g1. Hint: You will also need to create at least one new
class.","<T, U> Pair<Filter<T>, Filter<U>> split(Filter<Pair<T, U>> f) {
return new Buffer<T,U>(f).split();
}
class Buffer<T, U> {
List<> lefts = new LinkedList<T>();
List<> rights = new LinkedList<U>();
Filter <Pair<T, U>> f;
Buffer ( Filter <Pair<T,U>> f) { this.f = f; }
void getNext() {
Pair<T, U> p = f.next();
if (p != null) { lefts .addLast(p.getKey()); rights .addLast(p.getValue ()); }
}
T nextLeft() {
if ( lefts . size () == 0) { getNext(); }
if ( lefts . size () == 0) { return null; }
return lefts . removeFirst ();
}
T nextRight() {
if ( rights . size () == 0) { getNext(); }
if ( rights . size () == 0) { return null; }
return rights . removeFirst ();
}
Pair<Filter<T>, Filter<U>> split() {
return new Pair(new Filter<T>() { T next() { return nextLeft(); } },
new Filter<U>() { U next() { return nextRight(); } });
}
}",Hard,'
818,SWE,"A future is a computation that is run in a separate thread while
the main thread continues its own work. At some time in the future, the main thread gets the result of the
future, which either returns the future’s result immediately, if the future was already finished, or it blocks
until the future is finished and then returns. Implement the following generalization of futures. You can
use threads, locks, and condition variables (wait/notifyAll or await/signalAll). You may not use
other parts of java.util.concurrent. Feel free to add comments to your code. We will give partial
credit if the comments are right, even if the code is not
// A callable is an object with a call method that returns a result .
// The callables are the computations that are run in separate threads .
interface Callable <V> { V call(); }
class Future<V> { // A Future is paramterized by the type it returns
Future( Callable <V>[] cs); // The constructor takes an array of n callables to run.
// Calling start launches n threads , one for each callable passed to the constructor . Each
// thread invokes the call methods of the callables .
void start ();
// Some time after start () has been called , the code may call getFirst (), which has the following behavior:
// ∗ If none of the threads has finished , it blocks
// ∗ As soon as one thread has finished , it returns the value computed by that thread’s callable .
// ∗ If more than one thread has finished or finishes at once, either thread’ s result may be returned.
// ∗ You don’t need to worry about stopping the threads that haven’t yet finished .
// ∗ Multiple calls to getFirst should always return the same value.
V getFirst ();
}","class Future<V> {
boolean[] done;
V[] results ;
Task<V>[] tasks;
class Task<V> extends Thread {
int i ;
Callable <V> c;
Task(int i , Callable <V> c) { this.i = i; this .c = c; }
void run() {
V v = c. call ();
synchronized(Future.this ) { done[i ] = true; results [ i ] = v; Future. this . notifyAll (); }
// could also use a ReentrantLock!
}
Future( Callable <V>[] cs) {
done = new boolean[cs.length];
results = new V[cs.length];
tasks = new Task<V>[cs.length];
for (int i = 0; i < cs.length ; i++) { tasks[i] = new Task(i, cs[ i ]); }
}
void start () { for (Task<V> t : tasks) { t. start (); } }
V synchronized getFirst () {
int j = −1;
while (true) {
for (int i = 0; i < done.length; i++} { if (done[i ]) { j = i; break; } }
if (j != −1) { break; }
wait ();
}
return results [ j ];
} }

The above solution saves all the results from the different threads, which would be useful if there
were other ways besides getFirst to look at the results. But since this particular interface only
has getFirst in it, here’s an alternative, simpler solution:
class Future<V> {
boolean done;
Callable <V>[] cs;
V result ;
Future( Callable <V>[] cs) {
this . cs = cs;
}
class Caller extends Thread {
Callable <V> callable;
public Caller ( Callable <V> callable) {
this . callable = callable ;
}
public void run() {
V res = callable . call ();
synchronized (Future. this ) {
if (!done) {
done = true;
result = res;
Future. this . notifyAll ();
} } } }
void start () {
for ( Callable <V> callable : cs) {
new Caller( callable ). start ();
} }
synchronized V getFirst () throws InterruptedException {
if (done) {
return result ;
}
this . wait ();
return result ;
} }",Hard,'
819,SWE,"Give an example of a design pattern whose use is obvious from a class diagram but not
from a sequence diagram. (Don’t choose one that is built into (some) programming languages, such
as inheritance.) Explain why, in 1 sentence.","Composite: the members of a class are of a type that allows similar operations (perhaps they implement an interface in common with the container class). Observer: especially easy if there’s an
hobservesi notation on an arrow.
For many patterns it’s possible to argue either way (and we were looking for your argument, not
just a name). A common pitfall here was conflating class and object diagrams.",Easy,https://courses.cs.washington.edu/courses/cse403/11sp/old-exams/11sp-midterm-solutions.pdf
820,SWE,"Give an example of a design pattern whose use is obvious from a sequence diagram but not
from a class diagram. (Don’t choose one that is built into (some) programming languages, such as
iteration.) Explain why, in 1 sentence","Factory: an actor creates an object in response to a call, and the caller subsequently sends messages
to the newly created object. Decorator: every message to the decorator object is followed by a call
to the object it decorates.",Easy,'
821,SWE,"Consider two components A and B. Two software engineers, Laurel and Hardy, measure the
dependences between A and B. Laurel uses these dependences when computing cohesion, and Hardy
uses these dependences when computing coupling. Is this possible, if both engineers are performing
a sensible and useful computation? In 1–2 sentences, explain why or why not.","Yes. Laurel is considering a larger module C that contains both A and B as implementation details.
Hardy is considering the implementation of C, and thinking of A and B as modules.",Medium,'
822,SWE,"In 1 sentence each, give two distinct reasons that you should not commit compiled code
(such as .o or .class files) to a version control repository.","• Merge conflicts cannot be resolved. Another way of saying the same thing is that binary files
are not diffable (by the standard text-based diff algorithms).
• Repetition of information in source and binary forms violates the DRY (don’t repeat yourself)
principle.
• Binary files such as .o files are architecture-dependent and may not be useful to others.
• Binary files may contain information such as timestamps that is guaranteed to create a conflict
even if generated from the same source code by others.
• Bloat in the VCS because differences are huge.
• Timestamps might not be preserved.
• If there is a check-in without compiling, then they can be inconsistent with the source code.",Easy,'
823,SWE,"It is cheaper and faster to fix known bugs before you write new code. Why? In one phrase
or sentence each, give three reasons. Give reasons that are as different from one another as possible.","• You are familiar with the code now. A related reason is that the bug will be harder to find and
fix later.
• Later code may depend on this code. A related reason is that a bug may reveal a fundamental
problem.
• Leaving all bugs to the end will make it harder to understand and keep to the schedule, because
it’s hard to predict how long bug fixing will take.
• An overfull bug database is demoralizing and is likely to be ignored.
• You will be able to add tests for the bug once it’s been fixed to avoid future issues.
• Avoid feature creep",Medium,'
824,SWE,"After you find a bug but before fixing it, you should create a test case for it. In one sentence
each, give three reasons that this is a good idea. Give reasons that are as distinct as possible.","• Ensures that your fix solves the problem. Don’t add a test that succeeded to begin with! A
related reason is to avoid writing a test for a bug that you fixed, but that isn’t the problem
indicated by the original bug fix.
• It helps you understand the bug and define the desired system behavior. (“It documents the
bug” or “it informs others of the bug” is wrong, because it is the purpose of your bug tracking
system to document your bugs. If you meant something different, such as the good answers
listed here, then please be more specific.)
• It helps you know when you are done with bug fixing. A related reason is repeatability, and
efficiency when debugging: the test is easy to run in an automated way to determine whether
your fix works.
Here are some more answers we accepted, even though they are really just reasons to write a test
at all, and not reasons to write the test before you fix the bug:
• Helps to populate test suite with good tests. The test case may reveal other problems also, that
would make sense to fix at the same time.
• Protects against reversions that reintroduce bug. It happened at least once, and it might
happen again.",Medium,'
825,SWE," Consider a wrapper whose implementation logs each call that occurs.
In no more than 2 sentences each, explain when the wrapper should be considered a decorator (and
why), and when that same wrapper should be considered a proxy (and why).","• Decorator: A decorator has different functionality but the same interface as the delegate.
If the wrapper’s specification requires it to do the logging, then it should be considered a
decorator.
• Proxy: A proxy has the same functionality and the same interface as the delegate. If the
wrapper has a lenient specification that permits but does not require it to perform logging,
then it should be considered a proxy.",Easy,'
826,SWE,"Recall that the interning pattern guarantees that any two objects with the same abstract
value are represented by just one concrete object. Answer each part in one sentence.
Give a usage pattern (or its characteristics) in which the interning pattern uses less memory,
compared to not using it, and explain why.","A compiler symbol table, in which most symbols are used multiple times, so eliminating duplication saves memory.",Easy,'
827,SWE,"Recall that the interning pattern guarantees that any two objects with the same abstract
value are represented by just one concrete object. Answer each part in one sentence.
Give a usage pattern (or its characteristics) in which the interning pattern uses more memory,
compared to not using it, and explain why.","A situation in which most objects have different values, so the overhead of the hash table
used by the interning implementation outweighs the reduction in memory used by duplicate
objects.",easy,'
828,SWE,"Recall that the interning pattern guarantees that any two objects with the same abstract
value are represented by just one concrete object. Answer each part in one sentence.
Give a usage pattern (or its characteristics) in which the interning pattern uses less time, compared to not using it, and explain why. Ignore effects that are really due to memory use, such as
faster allocation.","Interning makes comparisons complete faster (the equals method always first checks object
equality), so if there are many comparisons, the speedup outweighs the time cost of interning,
which is a search for an equal object.",easy,'
829,SWE,"Recall that the interning pattern guarantees that any two objects with the same abstract
value are represented by just one concrete object. Answer each part in one sentence.
Give a usage pattern (or its characteristics) in which the interning pattern uses more time, compared to not using it, and explain why. Ignore effects that are really due to memory use, such as
thrashing.","If few equality checks are performed, then the speedup does not outweigh the time cost of
performing interning. The main goal of interning is to save memory, so interning can be
worthwhile even if it slows down the program.",easy,'
830,SWE,List the stages of the waterfall software process.,"requirements gathering / analysis, specification, design, implementation / coding,
testing, integration, usage / product testing / maintenance",easy,https://hkn.eecs.berkeley.edu/examfiles/cs169_fa04_mt1.pdf
831,SWE,Describe briefly the difference between specifications and design.,"specifications are a concise and complete description of user requirements (""what"");
design is a technical plan for implementation of code which fulfills those specifications
(""how"").",easy,'
832,SWE,What is a risk of using the waterfall software process?,"risk of not catching errors (in any stage) till too late; risk of requirements
changing during development; risk of long waits before anything works.",easy,'
833,SWE,"In extreme programming, what code do you write before you write a module? Explain why.","unit tests and testing infrastructure are written before the declarative code
for each module. This focuses the programmer on meeting the specified functionality
exactly, protecting him from unbounded abstraction. Unit tests are also clearly
helpful in detecting failures later.",easy,'
834,SWE,What is the connection between extreme programming and refactoring?,"Refactoring is central to XP, which emphasizes working, small-scope code and frequent
iteration. such practices demand constant structural redesign, which is refactoring:
reorganizing without changing functionality. Through this process the codebase
is both flexible and robust.",Medium,'
835,SWE,What is one problem with informal specifications?,"Informality usually implies ambiguity, which defeats their purpose as specifications.
This problem is inherent in specifications written in natural language prose,
so we frequently use more precise means of communication, such as graphs, in the
specification process.",easy,'
836,SWE,"When debugging programs, do you turn compiler optimizations on or off? Why?","You first turn them off, because otherwise the debugger will not be able to correlate
the executable with the source code. Then you turn them on, to find if the bug
only appears in the optimized version (e.g., due to timing issues)",easy,'
837,SWE,"In the delta debugging algorithm, why can you have unresolved tests?","There may be combinations of tests for which the program does not compile, or
does not run.",easy,'
838,SWE,Explain why 100% path coverage is not always sufficient to ensure absence of bugs.,"There are many good answers here. One that is shorter than what we expected,
is that testing cannot prove the absence of bugs. Also good answers, is that
just because you have tried all the paths at least once, it does not mean that
you have tried them with all input values. Many people also pointed out that
in code with loops the bug may surface only in a late iteration of the loop.",easy,'
839,SWE,Why are data races hard to debug?,"Data races may manifest themselves only in rare interleaving of instructions, and the
scheduler does not interleave the threads in exactly the same way every time (depending
on the system, the system load, the needs and priorities of other processes that are running,
etc). Because races are often rare, it is difficult to find in the first place, and difficult
to track down (and to tell when you’ve fixed it) because you cannot reproduce it predictably.",easy,'
840,SWE,"In a multi-threaded program do you have to worry about data races on local variables?
Explain your answer.","No, you do not have to worry about data races on local variables. Local variables are
not shared between threads, only global variables are. A local variable can be a pointer
to (shared) global data, but in this case it is the global data that needs to be locked
to protect from data races not the local pointer (all access to that shared data need
to use the same global lock).",easy,'
841,SWE,"Consider the following sequence of actions taken by one thread. Fill in the two columns
corresponding to the locksets of x and y inferred by Eraser. For each action, write the lockset
inferred after seeing that action. Consider only the basic Eraser algorithm (the one that does
not handle initialization and does not distinguish between read and write locks).","          x.       y
initial { a, b} { a, b}
1. lock(a)
2. y = 0
{ a }
3. lock(b)
4. x = y
{a, b} { a }
5. unlock(a)
6. x = y + 1
{ b } {}
7. unlock(b)
8. lock(a)
9. x = 1
{} {}
10. unlock(a)",hard,'
842,SWE,"Explain what does it mean for a static analysis to be conservative? Give an example on which
type checking is conservative.","Static analysis is conservative in that it produces false positives. For example,
static type checking will complain about the following:
char x; if(!y) x = ""string"";
even when it is guaranteed in your program that y is never equal to 0 (or false).",medium,'
843,SWE,Write below some advantages of run-time monitoring.,"does not require source code
(and is language-agnostic),
can find errors that are
caused by the environment
(and thus can only be found
by running the code or by
extremely conservative static
analysis), can be used by
programmer to easily check
for an invariant or suspected
bug (e.g. asserts), does
not give false positives
about paths that are not
possible in the program or
about assignments that are
not explicitly casted (but
probably should be) but
that the programmer knows
are correct in the range of
values used by the program",medium,'
844,SWE,Write below some advantages of static analyses.,"checks all possible execution
paths even if they are not
covered by a testcase, does
not degrade performance
at runtime, does not
require running the program
(halting problem, program
might run for a long time,
etc), enables higher-level
understanding of program
(possible to have knowledge
of past, present, and future
instead of just past and
present)",medium,'
845,SWE,What is regression testing and how do you use it effectively?,"Regression testing is a testing strategy where every time you find a bug you write
a test case to exhibit the bug, fix the bug, and add the test case to your test
suite. Ideally you run this entire test suite regularly on the program as it
changes (at CVS checkin, at every build, etc). This way you ensure that old bugs
do not reappear without you noticing (which happens frequently)",easy,'
846,SWE,"Now consider the following code. A program may or may not need the value of
pi to 1000 digits. Since this is an expensive computation, it will only
compute the value if needed, and at most only compute it once, using the
following Java code. Note that the method compute_pi may be called many times by
different threads, but the body of the method is supposed to compute the value of pi only
one time.
 
1 protected Object _my_lock = new Object ();
2 protected BigDecimal _cached_value;
3 public BigDecimal compute_pi () {
4 if (_cached_value == null) {
5 synchronized (_my_lock) {
6 if (_cached_value == null) {
7 // do actual computation, putting result in
8 // the variable _cached_value
9 }
10 }
11 }
12 return _cached_value;
13 } 

Will the code compute pi more than once? Why or why not?","No. It will only compute pi once. Even though more than one thread may reach line 5, the
check inside the synchronized block will ensure that only one thread performs the
calculation. ",Medium,https://hkn.eecs.berkeley.edu/examfiles/cs169_fa02_mt1.pdf
847,SWE,"You are given the following code. (You can scroll down to see the all the code) In this question, we consider the entire program
when calculating coverage.
void coverage(bool a, bool b){
 if (a || b) {
 std::cout << ""1"";
 }
 if (!b || !b || !b || !b) {
 std::cout << ""2"";
 }
}
What is the minimum number of test cases required for 100% statement coverage? Enter a whole number.",1,easy,https://eecs481.org/exams/f24-exam1-key.pdf
848,SWE,"You are given the following code. (You can scroll down to see the all the code) In this question, we consider the entire program
when calculating coverage.
void coverage(bool a, bool b){
 if (a || b) {
 std::cout << ""1"";
 }
 if (!b || !b || !b || !b) {
 std::cout << ""2"";
 }
}
What is the minimum number of test cases required for 100% branch coverage? Enter a whole number",2,easy,'
849,SWE,"You are given the following code. (You can scroll down to see the all the code) In this question, we consider the entire program
when calculating coverage.
void coverage(bool a, bool b){
 if (a || b) {
 std::cout << ""1"";
 }
 if (!b || !b || !b || !b) {
 std::cout << ""2"";
 }
}
What is the minimum number of test cases required for 100% path coverage? Enter a whole number.",3,easy,'
850,SWE,"Now consider the silly_goose function. Answer the following questions.
void silly_goose(bool a, bool b, bool c){
 if ((a || !b) || (c && !a)) {
 STMT_1;
 }
 if ((c && !b) || (a || b)) {
 STMT_2;
 }
 if ((!a && !b) && c){
 STMT_3;
 }
}
How many of the STMT statements does the test case (true, true, true) cover? Write your answer as a whole number. (We
are asking for the statement coverage without the denominator.)",2,Medium,'
851,SWE,"Now consider the silly_goose function. Answer the following questions.
void silly_goose(bool a, bool b, bool c){
 if ((a || !b) || (c && !a)) {
 STMT_1;
 }
 if ((c && !b) || (a || b)) {
 STMT_2;
 }
 if ((!a && !b) && c){
 STMT_3;
 }
}
How many of the branch directions does the suite [(false, false, true), (false, true, false), (false, false,
false)] cover? Write your answer as a whole number. (We are asking for the branch coverage without the denominator.)",6,Medium,'
852,SWE,"Consider the following code.
int func2(int n) {
 if (n <= 1) {
 return n;
 }
 int a = 1;
 int b = 4;
 for (int i = 1; i < n; ++i)
 {
 int c = b - (2 * a);
 a = b;
 b = c;
 }
 return b;

Your mutants can swap between the operators <, == and <= (but no other operators). Your mutants can swap
between the numbers 1, 0 and -1 (but no other numbers). If you are only allowed to mutate the base (line 2), how many
mutants are killed by the test case with input n = 3?",0,Medium,'
853,SWE,"Consider the following code.
int func2(int n) {
 if (n <= 1) {
 return n;
 }
 int a = 1;
 int b = 4;
 for (int i = 1; i < n; ++i)
 {
 int c = b - (2 * a);
 a = b;
 b = c;
 }
 return b;

Your mutants can swap between the operators <, == and <= (but no other operators). Your mutants cannot
change anything else. If you are only allowed to mutate the loop guard (line 7), how many mutants are killed by the test case
with input n = 2?",2,Medium,'
854,SWE,"Compare and contrast two approaches for race condition detection: the dynamic analysis tool Eraser and static code
inspection. Describe one situation in which the former would work well and the latter would not, then describe a situation in
which the latter would work well and the former would not. Reference some of the human factors associated with code
inspection from the lectures and reading. (Use at most six sentences.)","Answers may vary. Dynamic Analysis (e.g., Eraser using Lockset Algorithm): detects race conditions during program execution
with high accuracy which results in performance overhead and limited path coverage. Static analysis provides broader code
coverage without runtime impact but can often create false positives and lacks runtime context. The lecture slides discussed a
number of human factors. For example, on the positive side for formal code inspection, some report that formal code
inspection meetings uncover deeper, more important bugs. On the negative side, formal code inspection can typically only
handle a small number of lines before attention wanes. Perhaps most critically, formal code inspection does not require any
inputs to the program and does not require the code to be working correctly (e.g., to compile). By contrast, Eraser requires the
program to compile and run, and it requires a good set of inputs, but after that it is automatic.",Hard,'
855,SWE,"You are developing a real-time trading system that must process market data and be able to execute trades with low latency.
Describe how dynamic analysis can help ensure the performance and the reliability of your system. What is the relationship
between dynamic analysis utility and test suite coverage? (Use at most 3 sentences.)","Answers may vary. Dynamic analysis can be useful for measuring runtime behavior, identifying performance bottlenecks, and
detecting concurrency issues which may not be able to be detected by static analysis. For example, dynamic analyses can
provide not only ""execution time"" profiling, but also measurements of particular events (e.g., how often a function is called or
how often a resource is allocated). However, dynamic analyses are only as good as their inputs. For example, consider a ""realtime trading system"" program that uses bubblesort. If it is only tested on small examples (e.g., two or three trades that must
be sorted before being processed), it may appear to meet real-time constraints. However, that same dynamic analysis applied
to that program with much larger, more indicative inputs would show a much slower running time. A dynamic analysis cannot
reveal information about lines of code it does not execute.",Medium,'
856,SWE,"Suppose you are interviewing at company Corp481, and you get the following technical question:
Given an array of strings called strs, group the anagrams together. Here, an ""anagram"" is a word or phrase formed by
rearranging the letters of a different word or phrase, typically using all the original letters exactly once. For example, “ate” and
“eat” are anagrams.
What are three questions you may want to ask -- e.g., to help clarify the question, or to help you better understand the task, or
to convince the interviewer that you understand relevant software engineering concepts -- before you start typing any code for
this question?","Possible answers (non-exhaustive list):
a. What letters do strs[i] consist of?
b. Does order matter in the returned anagrams?
c. What is the expected data structure to store the results?
d. What is the maximum number of strings in strs?
e. What is the maximum number of characters in each strs[i]?
f. Can strs be empty?
g. Can strs[i] be empty?",Medium,https://eecs481.org/exams/f22-exam1-key.pdf
857,SWE,"Suppose you are managing a team of software engineers at company Corp481.
After looking through the history of commits, you realized that each individual code change is quite large. You decided to
encourage developers on your team to keep each individual change small going forward.
How would you justify this decision of breaking larger changes into a series of smaller changes? Feel free to cite what you
learned from the lecture slides and/or readings to back up your justifications. Please use at most five sentences","It's easier for code review (From the Henderson’s reading: “Engineers are encouraged to keep each individual change small,
with larger changes preferably broken into a series of smaller changes that a reviewer can easily review in one go."" This also
makes it easier for the author to respond to major changes suggested during the review of each piece; very large changes are
often too rigid and resist reviewer-suggested changes”).
Note: there may be other reasons, and the response should be credited accordingly.",Medium,'
858,SWE,"Suppose you are managing a team of software engineers at company Corp481.
When developing a large project, different components in the project may take different amounts of time to be implemented.
You find that programmers who finish their work early are oftentimes blocked by the work of other programmers. For
example, programmer A cannot proceed to test her function because it requires the output of the function which programmer
B is currently still working on.
In order to improve the overall efficiency of the entire team, what single Software Engineering method can you apply and why
is it a good choice? Please use at most five sentences and include at least two reasons why your method is a good choice.","Mocking. When the full implementation of a method is not yet available, mocking can reduce the degree of dependencies and
allow simultaneous development rather than sequential.",Medium,'
859,SWE,"Suppose you are managing a team of software engineers at company Corp481.
In order to improve productivity, you plan to base developer end-of-year cash bonuses on the following metrics:
a. The number of words of documentation written.
b. The number of code changes accepted during code reviews.
Evaluate the pros and cons of each of these two metrics. Use less than 2 sentences for pros and less than 2 sentences for cons","Note: there may be other reasons, and the response should be credited accordingly.
a. (1)The amount of documentations written: makes documentations unnecessarily verbose and long
b. (2)The number of merge requests accepted during code reviews: this encourages splitting a meaningful merge/pull
request into trivial, small ones. this is also unfair to those developers who are doing tasks that don’t require creating
many merge requests.",Medium,'
860,SWE,"You need to decide whether or not to employ pair programming (i.e., two programmers code up the task together) for a series
of tasks. You will only opt in for pair programming if it leads to an overall lower cost ($$). Otherwise, you would choose to use
individual programming (i.e., one developer programs the entire task alone).
Suppose for ALL tasks, pair programming makes coding 20% slower but results in 60% fewer defects. For example, a task —
that takes one programmer 10 hours to complete — would take a pair of two programmers 12 hours to complete (i.e., two
programmers are pair programming together for the entire 12 hours). On the other hand, given a task, suppose one
programmer writes a program to solve this task that has 10 bugs. If two programmers pair programs together, they would
write a program that solves the same task and that has 4 bugs.
In the context of this question, when pair programming, we allow two programmers to write the program together, however,
when fixing bugs/defects, each programmer will do it individually. In other words, in terms of fixing defects, there is no
difference between pair programming and individual programming: a defect is always fixed by one programmer.
The hourly rate for each programmer would be $50. That is, if a task takes one individual programmer 10 hours to code up,
the cost is $500 (i.e., we need to pay the programmer $500). On the other hand, if two programmers pair program for 10
hours, the total cost would be $1,000 (i.e., each programmer gets paid $500). As for fixing defects, if a defect takes one
programmer 1 hour to fix, the programmer would get paid $50.
The following tables detail the specifications for each task. In particular, for each task, it gives:
a. Program Size (LOC): the total lines of code (LOC). Note that, for the purpose of this question, pair programming and
individual programming will produce programs of the same size.
b. Coding Speed (LOC / hour): the number of lines of code per hour that one programmer can write for the task.
c. Defect Rate (#defects / KLOC): the number of defects produced per one thousand lines of code, assuming one
programmer is working on the task alone.
d. Defect Fixing Rate (#hours / defect): the number of hours for one programmer to fix one defect.
In each answer box, enter either ""Individual"" or ""Pair"" as your answer.

Program Size (LOC) = 100,000 
Coding Speed (LOC / hour) = 50
Defect Rate (#defects / KLOC) = 20
Defect Fixing Rate (#hours / defect) = 10","As individuals: 2000 hr coding + 20000 hr fixing defects = 22000 hr As pairs: 2400 hr coding + 8000 hr fixing defects = 10400
hr Cost for individuals = 22000 hr * 50 = $1,100,000 Cost for pairs = 10,400 hr * 100 = $1,040,000 Answer: pair",Hard,'
861,SWE,"You need to decide whether or not to employ pair programming (i.e., two programmers code up the task together) for a series
of tasks. You will only opt in for pair programming if it leads to an overall lower cost ($$). Otherwise, you would choose to use
individual programming (i.e., one developer programs the entire task alone).
Suppose for ALL tasks, pair programming makes coding 20% slower but results in 60% fewer defects. For example, a task —
that takes one programmer 10 hours to complete — would take a pair of two programmers 12 hours to complete (i.e., two
programmers are pair programming together for the entire 12 hours). On the other hand, given a task, suppose one
programmer writes a program to solve this task that has 10 bugs. If two programmers pair programs together, they would
write a program that solves the same task and that has 4 bugs.
In the context of this question, when pair programming, we allow two programmers to write the program together, however,
when fixing bugs/defects, each programmer will do it individually. In other words, in terms of fixing defects, there is no
difference between pair programming and individual programming: a defect is always fixed by one programmer.
The hourly rate for each programmer would be $50. That is, if a task takes one individual programmer 10 hours to code up,
the cost is $500 (i.e., we need to pay the programmer $500). On the other hand, if two programmers pair program for 10
hours, the total cost would be $1,000 (i.e., each programmer gets paid $500). As for fixing defects, if a defect takes one
programmer 1 hour to fix, the programmer would get paid $50.
The following tables detail the specifications for each task. In particular, for each task, it gives:
a. Program Size (LOC): the total lines of code (LOC). Note that, for the purpose of this question, pair programming and
individual programming will produce programs of the same size.
b. Coding Speed (LOC / hour): the number of lines of code per hour that one programmer can write for the task.
c. Defect Rate (#defects / KLOC): the number of defects produced per one thousand lines of code, assuming one
programmer is working on the task alone.
d. Defect Fixing Rate (#hours / defect): the number of hours for one programmer to fix one defect.
In each answer box, enter either ""Individual"" or ""Pair"" as your answer.

Program Size (LOC) = 100,000 
Coding Speed (LOC / hour) = 100
Defect Rate (#defects / KLOC) = 10
Defect Fixing Rate (#hours / defect) = 2","As individuals: 1000 hr coding + 2000 hr fixing defects = 3000 hr As pairs: 1200 hr coding + 400 hr fixing defects = 1600 hr
Cost for individuals = 3000 hr * 50 = $150,000 Cost for pairs = 1600 hr * 100 = $160,000 Answer: individual",Hard,'
862,SWE,"You are working on a multi-threaded C++ codebase with many lock and unlocks. In every function or method,
there are many if statements that check for errors that result in an early return, many of which are obscure and expected to
almost never happen. You just learned that you need to call unlock before all return statements, and the only reason you’ve
not yet run into any issues is because you only forgot to unlock in some of these error checks. You want to use dynamic
analysis to identify inputs that cause these problems. Is this a good technique, or is there a better one for this scenario? In
addition, please indicate which dynamic analysis from the lecture or readings you think would be the 'best' fit for this situation.
Justify your answer. Limit your answer to no more than five sentences.","Static analysis should be preferred since whether a lock is unlocked can be traced at every `if-return`. Dynamic analysis can be
justified, but static analysis is preferred because errors that induce these early returns are rare so dynamic analysis is unlikely
to find them, and even if they do, dynamic analysis tools for lock/unlock raise many false positives.",Medium,'
863,SWE,"You are a software engineer at an app-based rideshare company with a very large codebase. Because of a recent
high-profile hack at one of your competitors, you and your coworkers decide to systematically evaluate your codebase for
security vulnerabilities. If your main concern is identifying whether a defect exists that would cause employee credentials to be
leaked, what single method would you use to evaluate the quality of your codebase, and why? If you have multiple methods in
mind, please explain a best one in your answer. Use no more than five sentences.","Probably dynamic analysis, since the program can be instrumented to record every part of the program that reads the
credentials variables. It also avoids the efficiency limitation because the main concern is employee credentials, so only a subset
of the codebase needs to be tested. Static analysis is also an acceptable answer with sufficient justification, but is impractical
because variables are read very often.",medium,'
864,SWE,"You are given the following C functions. Assume that statement coverage applies only to statements marked STMT_#. In this
question, we consider the entire program. That is, even if program execution starts from one particular method, we consider
coverage with respect to the contents of all methods shown.

void Euphoria(str a, str b, int c, int d) {
 STMT_1;
 if (c < d) {
 medicine(b, a);
 }
 STMT_2;
 apple_juice(d, c);
}
void medicine(str a, str b) {
 STMT_3;
 if (a == 'rue') {
 STMT_4;
 }
 if (b == 'jules') {
 STMT_5;
 }
}
void apple_juice(int c, int d) {
 if (c == d) {
 STMT_6;
 return;
 }
 STMT_7;
 apple_juice(c, c);
 STMT_8;
}
Provide 1 input (i.e., all four arguments) to Euphoria(str a, str b, int c, int d) such that the statement
coverage will be 50%. (We only consider statements marked STMT_#.) Use a format such as (""hello"", ""goodbye"", 123,
456) if possible.","ANSWER: not possible
Different students were presented with different coverage targest. Some example answers include:
37.5: ('hello', 'hello', 10, 10)
87.5: ('hello', 'rue', 9, 10) or ('jules', 'hello', 1, 2)
62.5: ('hello', 'hello', 10, 9)
75: ('hello', 'hello', 9, 10)
100: ('jules', 'rue', 9, 10)
A common mistake for students receiving 87.5% was missing the variable swap of a and b when calling medicine. Answers
such as ('rue', 'hello', 1, 2) are not correct in that setting.
Some students were asked about 50% coverage, which is not obtainable in the code above. The instructions do note if possible,
so 'not possible' is a full-credit answer. (Most students who asked about this were given relevant information on Piazza. A small
number of students may have been given misleading information on Piazza when asking about this; such students should file
regrade requests for this question.)",Hard,https://eecs481.org/exams/w22-exam1-key.pdf
865,SWE,"You are given the following C functions. Assume that statement coverage applies only to statements marked STMT_#. In this
question, we consider the entire program. That is, even if program execution starts from one particular method, we consider
coverage with respect to the contents of all methods shown.

void Euphoria(str a, str b, int c, int d) {
 STMT_1;
 if (c < d) {
 medicine(b, a);
 }
 STMT_2;
 apple_juice(d, c);
}
void medicine(str a, str b) {
 STMT_3;
 if (a == 'rue') {
 STMT_4;
 }
 if (b == 'jules') {
 STMT_5;
 }
}
void apple_juice(int c, int d) {
 if (c == d) {
 STMT_6;
 return;
 }
 STMT_7;
 apple_juice(c, c);
 STMT_8;
}

Give a minimum test suite to reach 100% branch coverage. Provide the test cases with their input in the form
Euphoria(str a, str b, int c, int d). For a and b, choose from only the values {'rue', 'jules'}. For c and d,
choose from only the values {1, 2}. Write each test input on a separate line, using a format such as (""hello"", ""goodbye"",
123, 456) for each input if possible.","3 test cases are required. Example set of possible test cases: {('jules', 'rue', 1, 2), ('rue', 'jules', 2, 1), ('rue', 'jules', 1, 2)}",Medium,'
866,SWE,"You are given the following C functions. Assume that statement coverage applies only to statements marked STMT_#. In this
question, we consider the entire program. That is, even if program execution starts from one particular method, we consider
coverage with respect to the contents of all methods shown.

void Euphoria(str a, str b, int c, int d) {
 STMT_1;
 if (c < d) {
 medicine(b, a);
 }
 STMT_2;
 apple_juice(d, c);
}
void medicine(str a, str b) {
 STMT_3;
 if (a == 'rue') {
 STMT_4;
 }
 if (b == 'jules') {
 STMT_5;
 }
}
void apple_juice(int c, int d) {
 if (c == d) {
 STMT_6;
 return;
 }
 STMT_7;
 apple_juice(c, c);
 STMT_8;
}
Describe a scenario in which a test suite that achieves 100% statement coverage might miss a bug in a program.
Then describe what other approach (testing, coverage, analysis, etc.) could find that bug. Use 4 sentences or fewer.","Answers will vary. In the lecture, examples such as division by zero and SQL injection were given. In a division by zero
bug, you can visit the line with a non-zero denominator value and not see the bug. One way to find such an issue would be to
use a dataflow analysis that determines if values are zero. Another example might be a race condition: you might have 100%
statement coverage but not observe the right scheduler interleavings. A tool such as Eraser or CHESS could help find the race
condition in such a situation. Student responses should not exceed 4 sentences.",Medium,'
867,SWE,"Consider the following two pairs of tools, techniques, or processes. For each pair, give a class of defects or a
situation for which the first element performs better than the second (i.e., is more likely to succeed and reduce software
engineering effort and/or improve software engineering outcomes) and explain why.
a. integration testing better than maximizing branch coverage
b. spiral development better than waterfall model","a. Maximizing branch coverage may be more useful in the early stages of software development, where test cases are
primarily focusing on testing all possible routes the code may take and testing as much as possible to ensure the base
of the code is strong. Branch coverage is also useful for error-handling code. Integration testing may be more useful in
the later stages of development, when there is already a working model and a new feature is added that needs to be
tested in how it interacts and performs with a previously-developed module, possibly using a testing framework to
simulate different scenarios. Integration testing is also relevant when the output of one module flows into another in a
meaningful way and the dependent interactions between those modules must be tested.
b. Full credit answer will discuss how spiral relies on continuous releases of prototypes to reduce risk. Waterfall is divided
into discrete phases over the course of an entire project. Spiral contains the aspects of waterfall, but Spiral is iterated
multiple times during a project. Spiral is typically better because it reiterates stages and tests multiple times throughout
the development cycle — waterfall is a simplified model used mainly to explain software processes in a classroom.",Medium,'
868,SWE,"Here are two examples of bugs that need to be triaged:
A conversion error causes integers to occasionally flip signs (e.g., 4 becomes -4 and -4 becomes 4).
A graphical error causes images to display 1.5x as large as expected, resulting in cropping.
For each bug, give an example of a situation where it would have high severity and a situation where the bug would have low
severity and explain why.","There are many answers to this question, but some examples for each:
A conversion error causes integers to occasionally display as negative (e.g., 4 becomes -4).
High: Any situation where the sign change could cause negative or dangerous effects. An example might be a trading bot
evaluating monetary decisions or a banking app's balance UI.
Low: Any situation where the sign change wouldn't cause negative effects aside from mild confusion. Think a recipe website's
ingredient measurements, or a fitness app's distance shown. In such a case the user knows that ""-2 eggs"" is not possible, so
the impact is minimized.
A graphical error causes images to display 1.5x as large as expected causing cropping.
High: Any situation where the picture change would result in a significant loss of important displayed data. An example might
be a graphing application causing part of the plot to be lost, or a blueprint application causing measurement data to be cut
out.
Low: Any situation where the picture change wouldn't result in a significant loss of important displayed data. Think of a forum
profile picture being cropped wrong. While not desireable, the partial picture (coupled with the name nearby) would reduce the
impact of the cropping.",hard,'
869,SWE,"Give an example of a software situation where fuzzing would be a better testing method than unit testing in
terms of finding many bugs. Then give a situation where unit testing would be a better testing method than fuzzing in terms of
the time or cost required. What kinds of bugs are likely to be revealed by fuzzing?","Fuzzing is likely to reveal more defects than unit testing in situations where data values flow across modules and random
values are likely to reveal defects. For example, consider a log-reading module that passes its output to a square-root module
that has a bug involving negative numbers. Unit testing might overlook corner cases and miss the square-root bug, but fuzzing
random numbers would likely find it quickly, and fuzzing random log strings would likely result in negative numbers that are
passed to the square root function to reveal the bug in a moderate time.
Unit testing is likely to be better than fuzzing in terms of time taken or cost if only a small number of values are relevant. In
HW2, many students saw that randomly-created tests for HTML or XML functions were not very effective, since random
creation rarely produced well-formed strings with correct matching brackets and syntax. Similarly, a division function with a
division-by-zero error might be an example: a fuzzer that just generates random numbers might take a very long time to
randomly generate zero. (Some fuzzers are more likely to choose numbers such as 0, 1, -1, MAX_INT and MIN_INT as a
heuristic for this reason.)
Example domains may vary, but generally any software that includes both user input and sensitive data might be relevant.
Consider medical interfaces, bank websites, stockbrokers.
Fuzzing is good at catching bugs related to overruns, overflows, error handling, and out-of-bounds accesses. Any mention of
code being broken by receiving too much data should also get points.",Hard,'
870,SWE,"You are a new team lead at Mozzarella and are in charge of leading a group of several developers. Your manager
asks you to begin collecting the following developer efficacy data:
Lines of code written per day
Pull requests accepted into the master branch per month
Peer ratings from an annual survey completed by coworkers
For each measurement, describe why it might not accurately represent a worker's efficacy and explain one way a malicious
worker might exploit it.","Lines of code per day
This metric can be an incorrect measure for a variety of reasons. Developers might be in a design-heavy period of development
or may code in a language that requires fewer lines. The developers may be focusing on software maintenance and thus
looking at or changing old code rather than creating new code. The LOC metric can be gamed with whitespace, comments, or
verbose syntax.

Pull requests accepted into the master branch per month
This metric can be inaccurate for a variety of reasons. Developers could be working on an experimental branch, could be
partner programming on a different machine, or could be working on intensive bug fixing which could result in fewer total pull
requests (but still many bugs fixed). This can be gamed by doing multiple trivial, small separate changes to inflate the number
of pull requests.
An annual survey done by coworkers
Depending on the work environment you're in, biases (e.g., race, gender, etc.) can heavily negatively affect how others might
would view you in a survey. As another example, someone who works asynchronously (and thus is not seen very often) might
receive a lower or more neutral score. If someone is seen as competent or attractive, but in reality does little, their scores
would be inflated. This can be gamed by developers only helping others and not working on their own tasks. Alternatively, two
developers might conspire to give each other perfect peer review scores on each survey regardless of their actual work.",medium,'
871,SWE,"Support or refute the following statement: ""A dynamic lockset algorithm such as Checkers is better suited than a
static analysis tool would be for race condition detection.""","Refute is possible. Dynamic lockset algorithms can be very inefficient (the Eraser algorithm reports 10x to 30x slowdowns). They may not halt on subject programs which run forever or deadlock. Some programs use concurrency control approaches other than locking. Dynamic analysis instrumentation may cause race conditions to disappear in practice (""Heisenbugs""). In addition, dynamic analyses require rich sets of test inputs. A student could describe a static analysis tool that keeps track of the set of locks held at each point, arguing that it fits in a static dataflow analysis framework (e.g., the set of locks only ever decreases, so the dataflow analysis terminates). Support is possible. Dynamic algorithms are used quite a bit in practice for this task. The CHESS reading notes that there are many possible scheduler interleavings: enumerating and reasoning about them all with a purely static technique is not likely to be feasible (or will result in too much ""I don't know"" or ""Top"" sorts of approximations). Because the Checkers algorithm is simply the Eraser lockset algorithm from the lecture, students can bring in any evidence from the reading or lecture.",Medium,'
872,SWE,"Suppose we want to test our dynamic analysis — that is, we want to gain confidence that it correctly reports a
race condition if and only if the subject program has a race condition. To do so, we need a suite of subject programs for which
we know whether each subject program has a race condition or not. Creating such a suite would be expensive. We decide to
use just one part of mutation from mutation analysis: start with a single known-good program and randomly delete a call to
lock or unlock to produce a new subject program that should now have a race condition. Support or refute the claim that using
this simple part of mutation would be a good way to produce a test suite for Checkers. (Note that in this question a test input
to the Checkers analysis is, itself, another program, which also has its own input. Note also that this question is about using a
mutation operator, but is not about standard mutation analysis.)","Both are possible, but refute is more likely. The mutation approach does reduce the cost of developing new subject programs.
However, there are a number of concerns. First, the resulting subject programs are not very diverse. For example, if the starter
""known-good"" program does not have any loops, none of the mutants will either, and so Checkers will never be tested on
looping programs. In addition, the resulting test suite is unbalanced: only the original known-good program has ""no races"" as
its expected answer, all of the others have ""race condition"" as the expected answer. Checkers could produce many false alarms
(i.e., Checkers could basically always say ""race condition"") and that would not be noticed, because almost every expected
answer is ""race condition"". Finally, a dynamic analysis relies on the quality of the input to the subject program. Nothing was
discussed about how inputs would be made to the known-good subject program or the mutants.
A support answer would have to address some of the issues above for full credit; merely indicating that it would save
development time would not be sufficient.
Much like HW3 or the in-class discussion of instrumentation, this question explicitly required students to think about notions of
""time"" or the ""stages"" of analysis. It also asked students to stretch and apply mutation in a setting other than pure mutation
testing to assess test suite quality.",Medium,'
873,SWE,"You are given the Python function below.
def awesome_grizzly (j: bool, k: bool, l: bool):
    STMT_1
    if (( j or k) and (not k and l)):
        STMT_2
    else:
        STMT_3
    if ((j and l) and not (j or k) and l):
        STMT_4
    elif ((not j and l) or not (not k)):
        STMT_5
        if (k and not l):
            STMT_6

Calculate the minimum statement coverage attainable using one test input and provide such an input (i.e.,
values of values of {var1}, {var2}, and {var3}).","4/6 = 66% with j: True, k: True, l: False",Medium,https://eecs481.org/exams/f21-exam1-key.pdf
874,SWE,"You are given the Python function below.
def awesome_grizzly (j: bool, k: bool, l: bool):
    STMT_1
    if (( j or k) and (not k and l)):
        STMT_2
    else:
        STMT_3
    if ((j and l) and not (j or k) and l):
        STMT_4
    elif ((not j and l) or not (not k)):
        STMT_5
        if (k and not l):
            STMT_6

Provide a single minimum set of test inputs(s) that achieves maximum statement AND maximum path coverage for this particular program. Consider only feasible paths and reachable statements. In one sentence, explain why this is the smallest number of test inputs that can maximize both statement and path coverage.","The minimum set of test inputs is {(True, True, True), (True, True, False), (True, False, True), (False, False, False)}. This is the smallest set of inputs to maximize path coverage because one input is necessary to cover each path, and the set of paths contains the set of paths which maximize statement coverage.",Hard,'
875,SWE,"Compare and contrast fuzz testing and constraint-based solvers for generating test inputs: what aspects do they share and
where do they differ? Give one example program for which we would expect a fuzzer to outperform a constraint-based solver.
Give one example of a program for which we would expect a constraint-based solver to outperform a fuzzer. Use at most six
sentences.","Fuzz testing and constraint-based test input generation are both interested in generating test inputs (not necessarily oracles)
to reach as much of the code as possible without requiring manual human effort. Fuzz testers do so by generating random
inputs (e.g., random integers, random strings) and are typically ""black box"" analyses (they do not need to see the code).
Constraint solvers do so by generating path predicates and solving them to reach particular targets and they are ""white box""
analyses (they do need to see the code).
A program that contains a conditional like ""if (input == 12345) ..."" is hard for a fuzz tester (because you are unlikely to ""guess""
12345 to visit the true branch) but easy for a constraint solver. By contrast, a conditional like ""if (input > length(read_file(""ondisk.txt""))) ..."" is likely to be hard for a constraint solver (which cannot reason about files in the disk or over the network or the
like) but a fuzz tester can just guess big and small numbers. Similarly, modern constraint solvers struggle with non-linear
arithmetic (e.g., ""input * input > 25""). ",Medium,'
876,SWE,"You are a software engineering manager. You are considering a proposal in which 30% of the resources currently used for
integration testing would instead be reallocated and used for a different dynamic analysis (e.g., something like Chaos Monkey
or Driver Verifier, etc.). Identify two risks associated with this proposal and one benefit associated with this proposal. For each,
identify one associated measurement that might be taken to reduce uncertainty (i.e., to determine the degree to which that
positive or negative outcome occurred).","Dynamic analysis tools such as Chaos Monkey or the Driver Verifier were covered starting on Slide 52 of the Dynamic Analysis
lecture (and it was remarked during the lecture that they would be fair game), as well as in some optional readings. Risks (e.g.,
staff illness, requirements changes, etc.) are covered in the Risk lecture and might prevent a high-quality product from
shipping on time. Measurements (covered in their own lecture) help reduce uncertainty and thus help detect and manage risk.
Benefits of the proposal relate to the use of the dynamic analysis. For example, one benefit of using a tool like the Driver
Verifier is that it can catch corruption bugs related to low-level systems code. One benefit of Chaos Monkey style tools is that
they are particularly good at findings bugs related to resilience, redundancy or even internationalization. Students could also
mention that these dynamic analyses are automated, compared to creating integration tests and oracles, so one potential
benefit is that developer time and effort is freed up for other uses.
Risks. however, abound. Integration testing is particularly good at finding bugs related to two modules working together. One
risk is that fewer such bugs might be detected before shipping. Similarly, dynamic analyses often suffer from soundness and
completeness issues: false positives and false negatives. One risk is that the dynamic analysis will produce too many false
alarms. Another is that it will miss important bugs (even of the type it is ""supposed"" to find). Other risks are possible: students might mention that dynamic analyses require you to already have a high quality test suite (remember: you have to run the
program on something) and thus may not be workable until later in the development process when many test inputs are
available.
Each associated measurement should be something that can be quantified and that could help a manager answer a question
like ""How big is this problem?"" or ""Is this really a big issue?"" If one is worried that no bugs will be detected, a metric like ""bugs
reported per line of code"" (e.g., on just one module, before deciding if the analysis should be deployed instead of 30% of
integration testing) could help with that decision. Similarly, the ""false positive rate"", the ""number of critical bugs missed"", or
even the ""coverage requirement for the test inputs for the tool to run well"" or the ""weeks into development when enough test
inputs will be available"" could all be reasonable choices for the risks above. For benefit metrics, ""bugs found"" or ""bugs found
per lines of code"" or ""developer hours saved"" or the like might all apply",Medium,'
877,SWE,"In three sentences or fewer, describe the differences between spiral development and waterfall development.","In the Waterfall Model, stages such as requirements elicitation, design, coding, testing, and operations are carried out in strict
order. As a result, information learned during testing or operations would never influence design, for example. By contrast, in
spiral development, an increasingly complex series of prototypes is constructed while accounting for risk. This allows
information learned during the testing or operation of one prototype to influence the design of the next, for example. ",Easy,'
878,SWE,"Identify a developer expectation of modern passaround code review that is commonly met. Identify a developer expectation of
modern passaround code review that is rarely met. Describe a buggy patch that modern passaround code review is unlikely to
correctly reject. Use at most six sentences.","Following Bacchelli and Bird's ""Expectations, outcomes, and challenges of modern code review"", key expectations that are met include finding defects and code improvements. Goals that are
rarely met include knowledge transfer and alternate solutions.
Consider a patch that ""does what it says"" (e.g., says it is removing a button and actually removes a button) but is doing the
wrong thing (e.g., the customer wants the button retained, not removed). Section VI-A of the Bachhelli and
Bird paper suggests, ""the most difficult thing when doing a code review is understanding the reason of the change"" and ""the
biggest information need in code review: what instigated the change"". If the code reviewers do not know why the change is
being made, they will not be able to assess it correctly, and may allow a patch that has no visible defects (but is ultimately
doing the wrong thing). In general, students should describe a patch that has no ""easy errors"" but instead has a bug ""beneath
the surface"".",Medium,'
879,SWE,"You are given the following code. (Please scroll down to see the all functions.) Assume that statement coverage applies only to
statements marked STMT_#. In this question, we consider the entire program when calculating coverage. The code starts at
main(), but even if some methods are not executed during the program execution for a given input, we still consider coverage
with respect to aallll 8 ST 8 STMMTTs.

void checkStrings(string a, string b) {
 if (a != """") {
 STMT_1;
 if (strlen(a) > 4) {
 STMT_2;
 }
 STMT_3;
 }
 else {
 return;
 }
 if (a[0] != b[0]) {
 if (a[0] == 'b') {
 STMT_4;
 }
 STMT_5;
 }
}
int sumDigits(int x) {
 int s = 0;
 while (x > 0) {
 STMT_6;
 s = s + (x % 10); // Note: '%' is the modulo operator
 x = x / 10;
 }
return s;
}
int main(string a, string b, int x, int y) {
 int s1 = sumDigits(x);
 int s2 = sumDigits(y);
 if (s1 == s2 && s1 != 0 && s2 != 0) {
 STMT_7;
 checkStrings(a, b);
 }
 STMT_8;
 return 0;
}

Give a test input for main() that achieves EXACTLY 25% statement coverage.
In the context of this question, you have to pick inputs from the following strings: { red, blue, green, black, brown,
pink } and the following ints: { 4444, 97, 790, 2462, 718, 1091 }.
TThhiiss i iss i imp mpoorrttaanntt..
Please write your answer in the following format, as a call to main(), because an auto-grader will be used to facilitate grading.
Ex: main('blue', 'blue', 97, 97)
If no such input exists, write IMPOSSIBLE (all capital letters).","ANSWER: 25%: Any input where the sum of the two ints's digits doesn't equal each other. STMT_6, STMT_8
Different students were presented with different coverage targets. Some example answers include:
25: main('red', 'green', 1091, 718)
50: IMPOSSIBLE
75: main('black', 'blue', 4444, 97)",Hard,https://eecs481.org/exams/w24-exam1-key.pdf
880,SWE,"You are given the following code. (Please scroll down to see the all functions.) Assume that statement coverage applies only to
statements marked STMT_#. In this question, we consider the entire program when calculating coverage. The code starts at
main(), but even if some methods are not executed during the program execution for a given input, we still consider coverage
with respect to aallll 8 ST 8 STMMTTs.

void checkStrings(string a, string b) {
 if (a != """") {
 STMT_1;
 if (strlen(a) > 4) {
 STMT_2;
 }
 STMT_3;
 }
 else {
 return;
 }
 if (a[0] != b[0]) {
 if (a[0] == 'b') {
 STMT_4;
 }
 STMT_5;
 }
}
int sumDigits(int x) {
 int s = 0;
 while (x > 0) {
 STMT_6;
 s = s + (x % 10); // Note: '%' is the modulo operator
 x = x / 10;
 }
return s;
}
int main(string a, string b, int x, int y) {
 int s1 = sumDigits(x);
 int s2 = sumDigits(y);
 if (s1 == s2 && s1 != 0 && s2 != 0) {
 STMT_7;
 checkStrings(a, b);
 }
 STMT_8;
 return 0;
}

Give a test input to main() that achieves the lloowweesstt statement coverage. Also, what is its coverage?
You can use any string or integer for the input parameters. No need to restrict to those in (a).
TThhiiss i iss i imp mpoorrttaanntt..
Please enter your answer as a call to main() followed by the statement coverage (as a percentage), in the following format.
Ex: main('blue', 'blue', 97, 97) 75%","ANSWER: 12.5%: Both x = 0 and y = 0.
Different students were presented with different questions. Some example answers include:
Highest: 100%. main('black', 'pink', 4444, 97) x and y's digits have the same sum, a is at least a 5 letter word starting
with 'b'. a and b start with different letters.
Lowest: 12.5%. main('black', 'blue', 0, 0) Both x and y have to be 0.",Hard,'
881,SWE,"You are given the following code. (Please scroll down to see the all functions.) Assume that statement coverage applies only to
statements marked STMT_#. In this question, we consider the entire program when calculating coverage. The code starts at
main(), but even if some methods are not executed during the program execution for a given input, we still consider coverage
with respect to aallll 8 ST 8 STMMTTs.

void checkStrings(string a, string b) {
 if (a != """") {
 STMT_1;
 if (strlen(a) > 4) {
 STMT_2;
 }
 STMT_3;
 }
 else {
 return;
 }
 if (a[0] != b[0]) {
 if (a[0] == 'b') {
 STMT_4;
 }
 STMT_5;
 }
}
int sumDigits(int x) {
 int s = 0;
 while (x > 0) {
 STMT_6;
 s = s + (x % 10); // Note: '%' is the modulo operator
 x = x / 10;
 }
return s;
}
int main(string a, string b, int x, int y) {
 int s1 = sumDigits(x);
 int s2 = sumDigits(y);
 if (s1 == s2 && s1 != 0 && s2 != 0) {
 STMT_7;
 checkStrings(a, b);
 }
 STMT_8;
 return 0;
}

n regards to path coverage, how many paths does the input you gave in (b) cover?
TThhiiss i iss i imp mpoorrttaanntt..
Please enter ONLY the number of paths (as a number, like 4) in the text box below.","ANSWER: 1, one input corresponds to one path",Medium,'
882,SWE,"You are given the following code. (Please scroll down to see the all functions.) Assume that statement coverage applies only to
statements marked STMT_#. In this question, we consider the entire program when calculating coverage. The code starts at
main(), but even if some methods are not executed during the program execution for a given input, we still consider coverage
with respect to aallll 8 ST 8 STMMTTs.

void checkStrings(string a, string b) {
 if (a != """") {
 STMT_1;
 if (strlen(a) > 4) {
 STMT_2;
 }
 STMT_3;
 }
 else {
 return;
 }
 if (a[0] != b[0]) {
 if (a[0] == 'b') {
 STMT_4;
 }
 STMT_5;
 }
}
int sumDigits(int x) {
 int s = 0;
 while (x > 0) {
 STMT_6;
 s = s + (x % 10); // Note: '%' is the modulo operator
 x = x / 10;
 }
return s;
}
int main(string a, string b, int x, int y) {
 int s1 = sumDigits(x);
 int s2 = sumDigits(y);
 if (s1 == s2 && s1 != 0 && s2 != 0) {
 STMT_7;
 checkStrings(a, b);
 }
 STMT_8;
 return 0;
}

What is the minimum number of test cases needed to get exactly 80% branch coverage?
For this question, we only consider branches created by the 5 if-statements (we do not consider branches from loops),
meaning there are 10 branches total.
TThhiiss i iss i imp mpoorrttaanntt..
Please enter ONLY the number of test cases (as a number, like 1).","ANSWER: 3 Test Cases
Different students were presented with different coverage targets. Some example answers include:
50%: 1 Test Case
60%: 2 Test Cases
80%: 3 Test Case",Hard,'
883,SWE,"For each of the two bugs below, please describe (1) an example where the bug would have high severity and (2) a scenario
where the bug would have low severity. Explain why in both cases.
Please limit your answer to at most 4 sentences, for each bug.

A bug that causes the color of text to change.","ANSWER:
Possible answers (answers may vary):
Low severity: The color of text in the ""Terms and Conditions"" section on a website changes. While the change is noticeable,
it doesn't impact the readability or understanding of critical information, making it a low-severity issue. (Answer explains how
the color of text doesn’t greatly affect main functionality 1.5 pts)
High severity: The color of text in an error message indicating a critical system failure changes. In this case, the altered
color may mislead users about the severity of the issue, potentially causing misunderstanding and hindering prompt corrective
action, making it a high-severity bug.",Medium,'
884,SWE,"For each of the two bugs below, please describe (1) an example where the bug would have high severity and (2) a scenario
where the bug would have low severity. Explain why in both cases.
Please limit your answer to at most 4 sentences, for each bug.

A bug that causes your app to occasionally close unexpectedly.","ANSWER:
Possible answers (answers may vary):
Low severity: The weather app closes. You can reopen the app and check the weather, nothing is lost, just a few seconds of
your time. Users won’t be too upset. (Answer explains how unexpectedly closing doesn’t greatly affect main functionality 1.5
pts)
High severity: Any situation where there is lost or unsaved important work or progress. For example, Microsoft Word closes
(without autosave) and you lose your essay. Another example, you are playing a video game for 3 hours without saving, and it
closes out, making you lose all that progress.",Medium,'
885,SWE,"Each of the following questions (c)-(e) gives a pair of concepts. It can be a pair of techniques, or a pair of tools, or a pair of
processes, etc. Given a pair, please explain why the first one could be better (e.g., more likely to succeed and reduce software
engineering effort, or to improve software engineering outcomes) than the second. Your explanation may depend on the
specific pair given. For full credit, please also briefly describe a situation to illustrate why the first is better than the second.
Note that your answer should not only explain why the first may be good, but also why the second may not be good. For each
question, please use no more than four sentences.",,,'
886,SWE,"Each of the following questions (c)-(e) gives a pair of concepts. It can be a pair of techniques, or a pair of tools, or a pair of
processes, etc. Given a pair, please explain why the first one could be better (e.g., more likely to succeed and reduce software
engineering effort, or to improve software engineering outcomes) than the second. Your explanation may depend on the
specific pair given. For full credit, please also briefly describe a situation to illustrate why the first is better than the second.
Note that your answer should not only explain why the first may be good, but also why the second may not be good. For each
question, please use no more than four sentences.

Integration Testing vs. Regression Testing","ANSWER:
Possible answer:
Integration Testing better: In a large e-commerce platform with numerous interconnected modules (e.g., user
authentication, inventory management, and payment processing), integration testing is superior. It excels in detecting defects
that arise from the collaboration of these diverse components. For instance, an integration test can reveal issues where a
successful user login doesn't synchronize correctly with the inventory system, ensuring a seamless end-to-end functionality
that regression testing might not fully capture.",Easy,'
887,SWE,"Each of the following questions (c)-(e) gives a pair of concepts. It can be a pair of techniques, or a pair of tools, or a pair of
processes, etc. Given a pair, please explain why the first one could be better (e.g., more likely to succeed and reduce software
engineering effort, or to improve software engineering outcomes) than the second. Your explanation may depend on the
specific pair given. For full credit, please also briefly describe a situation to illustrate why the first is better than the second.
Note that your answer should not only explain why the first may be good, but also why the second may not be good. For each
question, please use no more than four sentences.

Alpha Testing vs. A/B Testing","ANSWER:
Possible answer:
Alpha testing better: You make a major change to the structure of your product (or you develop a completely new product).
This product needs to be tested to see if it works correctly as the structure has been largely changed. Alpha testing allows the
developers to test it to make sure it works as intended before releasing it to the public. A/B testing could force an
unfinished/not working product out which might scare away customers. It also isn’t very useful, because if you spent all those
resources making this major change, you are probably not going to backtrack on those changes.",Medium,'
888,SWE,"Each of the following questions (c)-(e) gives a pair of concepts. It can be a pair of techniques, or a pair of tools, or a pair of
processes, etc. Given a pair, please explain why the first one could be better (e.g., more likely to succeed and reduce software
engineering effort, or to improve software engineering outcomes) than the second. Your explanation may depend on the
specific pair given. For full credit, please also briefly describe a situation to illustrate why the first is better than the second.
Note that your answer should not only explain why the first may be good, but also why the second may not be good. For each
question, please use no more than four sentences.

Unit Testing vs. Static Dataflow Analysis","ANSWER:
Possible answer:
Unit tests better: You already know what part of the code is buggy and have attempted to rewrite it. Static dataflow
analysis could take an unnecessary amount of time and resources, and it won’t point out if the buggy section has been fixed.",Medium,'
889,SWE,"Suppose Test A has lower statement coverage than Test B.
Support or Refute: It is impossible for Test A to expose more bugs than Test B. If supporting, explain why it is impossible. If
refuting, give a specific example or situation of where Test A could expose more bugs than Test B. Please limit your answer
to at most four sentences.","ANSWER:
Choose Refute: For a test to perform well with statement coverage, it only has to run a certain line. Even if the line is
potentially buggy on certain inputs, the test doesn’t have to expose the bug to perform well with statement coverage.
For example, let's say there is only one potential bug in a file, a division by 0 error. If test B only gives inputs that result
in dividing by a non-zero number, then that bug will never be exposed, even if test B executes that line. Test A executes
less statements, but if it executes the buggy line and the input results in a division by 0, then test A exposes that line,
and thus exposes more bugs than test B.",Medium,'
890,SWE,"As a software engineer at 481Company, you are responsible for developing rapid changing software (which requires to be
constantly updated). Your coworker Darwin Nunez suggests that the company switches from agile development to the
waterfall development model due to its simple process. Do you agree or disagree with Darwin? Explain which development
methodology you believe 481Company should follow, and explain why it is better than the other methodology. Please limit
your answer to at most four sentences.","Disagree. 481company should use Agile development. 481company deals with changes often, so we need a more
adaptable and flexible approach to be able to deal with these changes at any time in our development cycle. While the
waterfall approach is more simple, it is also more rigid and it is more costly and difficult to respond to changes down the
process. It also gives us less releases of our rapidly changing software to the public. ",Medium,'
891,SWE,"You are given the following C functions. Assume that statement coverage applies only to statements marked STMT_#.
Importantly, in this question, we consider the entire program when calculating coverage. That is, even if the program execution
starts from one particular method, we consider coverage with respect to the contents of all methods shown. Similarly, even if
some methods are not executed during the program execution, we consider coverage with respect to the contents of all
methods shown. Finally, we assume each input string (a and b) to aventura has at least one character; in other words, we do
not consider NULL or empty strings.

void aventura(str a, str b) {
 int pos = strlen(b) - 1;
 if (a[0] == b[pos]) {
 south_state(strlen(b), strlen(a));
 STMT_1;
 }
 STMT_2;
}
void south_state(int x, int y) {
 STMT_3;
 for (int i = 1; i < y; i++) {
 x += 1;
 }
 if (x < 8) {
 STMT_4;
 church_st(x, y);
} else {
 STMT_5;
 x = x / 2;
 church_st(y, x);
 }
}
void church_st(int m, int n) {
 if (m % n == 0) {
 STMT_6;
 return;
 }
 else {
 church_st(m, m);
 STMT_7;
 }
 STMT_8;
}

In this question (including this sub-question and subsequent sub-questions), we define “one input” as one pair
(a, b) of values. For example, (“this”, “that”) is one input where a is the string “this” and b is the string “that”.
TTrruuee / / F Faallssee: Suppose you can choose one input (a, b) to the function aventura. It is possible to achieve 95% or greater
statement coverage. Note that we assume that covering all of STMT_1 through STMT_8 counts as 100%.","ANSWER: False. Not all STMTs can be reached due to the if/else in the south_state function. The highest coverage that can be
reached in 87.5%",Hard,https://eecs481.org/exams/w23-exam1-key.pdf
892,SWE,"You are given the following C functions. Assume that statement coverage applies only to statements marked STMT_#.
Importantly, in this question, we consider the entire program when calculating coverage. That is, even if the program execution
starts from one particular method, we consider coverage with respect to the contents of all methods shown. Similarly, even if
some methods are not executed during the program execution, we consider coverage with respect to the contents of all
methods shown. Finally, we assume each input string (a and b) to aventura has at least one character; in other words, we do
not consider NULL or empty strings.

void aventura(str a, str b) {
 int pos = strlen(b) - 1;
 if (a[0] == b[pos]) {
 south_state(strlen(b), strlen(a));
 STMT_1;
 }
 STMT_2;
}
void south_state(int x, int y) {
 STMT_3;
 for (int i = 1; i < y; i++) {
 x += 1;
 }
 if (x < 8) {
 STMT_4;
 church_st(x, y);
} else {
 STMT_5;
 x = x / 2;
 church_st(y, x);
 }
}
void church_st(int m, int n) {
 if (m % n == 0) {
 STMT_6;
 return;
 }
 else {
 church_st(m, m);
 STMT_7;
 }
 STMT_8;
}

Provide one test input to aventura such that it achieves a statement coverage rate between 60% and 96%
(inclusive).
Keep in mind that the statement coverage rate must be within the specified range. Write your test input in the form
(""hello"", ""world"") followed by the corresponding coverage rate (separated by comma): for example, (""hello"",
""world""), 80%. If you believe there is no such input that can achieve the target statement coverage rate, please explain. For
your explanation, please limit your answer to at most four sentences.
In the context of this question, you have to pick inputs from the following five strings: { amers, avalon, isalita, kangs,
mani }","ANSWER: 75% coverage: (""amers"", ""isalita"") or (""avalon"", ""isalita"") 87.5% coverage: (""isalita"", ""amers"") or (""isalita"", ""avalon"")
Coverage rates along with possible corresponding inputs:
50%: not possible
62.5%: not possible
75%: (""amers"", ""isalita"") or (""avalon"", ""isalita"")
87.5%: (""isalita"", ""amers"") or (""isalita"", ""avalon"")",Hard,'
893,SWE,"You are given the following C functions. Assume that statement coverage applies only to statements marked STMT_#.
Importantly, in this question, we consider the entire program when calculating coverage. That is, even if the program execution
starts from one particular method, we consider coverage with respect to the contents of all methods shown. Similarly, even if
some methods are not executed during the program execution, we consider coverage with respect to the contents of all
methods shown. Finally, we assume each input string (a and b) to aventura has at least one character; in other words, we do
not consider NULL or empty strings.

void aventura(str a, str b) {
 int pos = strlen(b) - 1;
 if (a[0] == b[pos]) {
 south_state(strlen(b), strlen(a));
 STMT_1;
 }
 STMT_2;
}
void south_state(int x, int y) {
 STMT_3;
 for (int i = 1; i < y; i++) {
 x += 1;
 }
 if (x < 8) {
 STMT_4;
 church_st(x, y);
} else {
 STMT_5;
 x = x / 2;
 church_st(y, x);
 }
}
void church_st(int m, int n) {
 if (m % n == 0) {
 STMT_6;
 return;
 }
 else {
 church_st(m, m);
 STMT_7;
 }
 STMT_8;
}

Provide another test input to aventura such that it achieves a statement coverage rate between 60% and 96%
(inclusive) and is ddiiffffeerreenntt from the statement coverage in your answer for b(1). If your answer to b(1) is ""no such input"", you
could skip this one, since the answer will also be ""no such input"". You do not need to explain again.
The requirement is the same as in b(1). That is, the statement coverage rate must be within the specified range. Write your test
input in the form (""hello"", ""world"") followed by the corresponding coverage rate (separated by comma): for example,
(""hello"", ""world""), 80%. If you believe there is no such input that can achieve the target statement coverage rate, please
explain. For your explanation, please limit your answer to at most four sentences.
In the context of this question, you have to pick inputs from the following five strings: { amers, avalon, isalita, kangs,
mani }."," If students choose 75% coverage in their answer of 2.2.1, they should choose 87.5% coverage rate as an answer with
string (""isalita"", ""amers"") or string (""isalita"", ""avalon""). If students choose 87.5% coverage in their answer of 2.2.1, they should
choose 75% coverage rate as an answer with string (""amers"", ""isalita"") or string (""avalon"", ""isalita""). If students states a wrong
answer in their answer of 2.2.1 (neither 75% nor 87.5% coverage), they could even get full points if they states either 75% or
87.5% and its corresponding input strings.",Hard,'
894,SWE,"You are given the following C functions. Assume that statement coverage applies only to statements marked STMT_#.
Importantly, in this question, we consider the entire program when calculating coverage. That is, even if the program execution
starts from one particular method, we consider coverage with respect to the contents of all methods shown. Similarly, even if
some methods are not executed during the program execution, we consider coverage with respect to the contents of all
methods shown. Finally, we assume each input string (a and b) to aventura has at least one character; in other words, we do
not consider NULL or empty strings.

void aventura(str a, str b) {
 int pos = strlen(b) - 1;
 if (a[0] == b[pos]) {
 south_state(strlen(b), strlen(a));
 STMT_1;
 }
 STMT_2;
}
void south_state(int x, int y) {
 STMT_3;
 for (int i = 1; i < y; i++) {
 x += 1;
 }
 if (x < 8) {
 STMT_4;
 church_st(x, y);
} else {
 STMT_5;
 x = x / 2;
 church_st(y, x);
 }
}
void church_st(int m, int n) {
 if (m % n == 0) {
 STMT_6;
 return;
 }
 else {
 church_st(m, m);
 STMT_7;
 }
 STMT_8;
}

What is the maximum branch coverage achievable by exactly one input to aventura? Please briefly explain your
answer.
Put the coverage rate in the first line (as a percentage or fraction), and then justification in the rest of lines. Limit your answer
to at most four sentences.","ANSWER: 4/6 or 2/3 or 66.7% (counting the for as 0 branches, able to cover two branches in church_st but only one in
aventura and south_state)
OR
5/8 (counting the for as 2 branches — enter/dont enter — and recognize that there is some recursion in the final if statement
that allows two branches to be covered)
OR
6/8 (1.counting the for as 2 branches as both entry and exit being covered and 2.recognize that there is some recursion in the
final if statement that allows two branches to be covered)",Hard,'
895,SWE,"Suppose you are interviewing at company 481Inc., and you get the following technical question:
You have a graph of n nodes labeled from 0 to n - 1. You are given an integer n and a list of edges where edges[i] = [a_i, b_i]
indicates that there is an undirected edge between nodes a_i and b_i in the graph. Return true if the edges of the given graph
make up a valid tree, and false otherwise.
What are TWO questions you can ask the interviewer before start implementing your solution? For each question, use at most
two sentences.","Possible answers (non-exhaustive list):
What is the definition of a valid tree?
What is the maximum number of edges?
What is the maximum number of nodes?
How many neighbors can a node have?
Does edges contain duplicates?
Will there be self-loops?
Will there be repeated edges?
Can I assume edges[i].length == 2?",Medium,'
896,SWE,"Your friend Hotspur actively has been contributing to an open-source Github repository, and there are 5 levels of severity when
it comes to bug reports (with 5 being the highest).
He filed a bug report to this repository, and it has been assigned with a severity level of 4. He assumed this bug would be
addressed soon with this high severity level. Weeks later, when he realized this bug is still there, he comes to you and
complains about the repository organizer`s inefficiency.
After taking EECS 481, you learned that a severe defect report may not be assigned with a high priority, and please list TWO
reasons why this can happen. Please limit each reason to at most two sentences; your answer should use no more than four
sentences.","Possible answers (non-exhaustive list): There are many other bug reports with a severity level of 5 (or mentioning the limit of development resource). The severe defect that happens rarely or reaches limited users can lower its priority. The severe defect that is less related to the current sprint goal can have a lower priority. There are other factors (such as complexity and risk) that are used to determine the priority of a defect report Possible deductions: A reason that only mentions ""there are other more urgent defects"" does not earn a point, since it is the definition of lower priority. Only one reason is provided; or two reasons are provided, but actually the same, i.e. one is paraphrase of another. The reason only explains why the severity-4 defect is not fixed, but strays away from ""a severe defect report may not be assigned with a high priority"".",Medium,'
897,SWE,"Suppose you are working on a buggy multi-threaded C++ codebase. Your colleague suggests that both static analysis and
dynamic analysis can be used to expose bugs.
Please list one example where static analysis can be used to expose a multi-threaded program AND one example where
dynamic analysis can be used to expose a multi-threaded program. Limit your answer to at most four sentences.","Possible answers (non-exhaustive list):
Static analysis
Forgets to lock/unlock
Dynamic analysis
Race conditions
Heisenbug
Note: trivial answers that are not specific to multi-threaded programs should not receive full credits.",Medium,'
898,SWE,"You are a manager. You want to figure out how much time your team spends on the following tasks: investigating bug reports,
reading requirements, debugging, and browsing Stack Overflow. You have a hypothesis that your team is spending too much
time reading bug reports. To assess this, you consider two options: (1) use a software tool that tracks which window each team
member has active (i.e., bug report window vs. coding window) and logs how much time they spend doing each activity,
including when they switch tasks, or (2) use a software tool that displays a pop-up window to each team member every 15
minutes, asking each person to select the activity they are currently doing from a list.
Identify two profiling-related concepts in the above scenario. For each concept, explain the concept and its relationship to the
scenario in two sentences. (2 * 2 = four sentences total)","Sample Answer: (1) Describes varies types of profiling. Flat profiler, call-graph, and instrumentation are valid here with correct
explaination. Instrumentation profiling can makes sense here since we are using a technique that effectively adds instructions
to the target program to collect the required information. Flat and call-graph profilers are both profilers types that are based
on output. In this scenario, callling (1) an example of a flat profiler is valid since we are caputuing task ""times"" but don't care
about tracking the context or callees within those tasks. This senario is also similar to a call-graph because we can use the
output to determine freqeuences and call-chains. (2) Describes the sampling approach but instead asking a program how long
they are taking, we having a human check in every 15 minutes.",Medium,https://eecs481.org/exams/f24-exam2-key.pdf
899,SWE,"You are programming a calendar. When the current month is not December, all events created and added will be regular type
events. When the current month is December, all events created and added to the calendar will be of a special holiday type
instead. Events can be shown in different fonts. Using some or all of the following method signatures:
create_event()
add_event()
is_december()
change_fonts(string font_type)

Describe a (bad) way to solve this problem with an anti-pattern in 4 sentences or less","Answer: Before calling create event, first check if is_december() is true. If is_december() is true, call
holiday_event_factory.create_event(), otherwise call regular_event_factory.create_event(). Then, whichever path was taken, add
the resulting event to the calendar using add_event()
Answer: [Alternate prompt] Before calling create event, first check if is_executive_visiting() is true. If is_executive_visiting() is
true, call priority_event_factory.create_event(), otherwise call regular_event_factory.create_event(). Then, whichever path was
taken, add the resulting event to the calendar using add_event()
Answer: Create two different versions of the calendar program. The first uses regular_event_factory.create_event(), the second
uses holiday_event_factory.create_event(). Use the first program during Jan-Nov, use the second program only during Dec.
Answer: [Alternate prompt] Create two different versions of the calendar program. The first uses
regular_event_factory.create_event(), the second uses priority_event_factory.create_event(). Use the first program during when
no executives are in the office, use the second program only when executives are in the office.",Medium,'
900,SWE,"FIRST=0
SECOND=0
for i in $* ; do
 if [ $i -eq 5 ]; then FIRST=1 ; fi
 if [ $i -eq 8 ]; then SECOND=1 ; fi
done
if [ $FIRST -eq 1 ]; then
 if [ $SECOND -eq 1 ]; then
 exit 1 # yes, this set is interesting
 fi
fi

Above is a bash script is-interesting.sh which describes one particular definition of “interesting” for Delta Debugging. Given the
above bash script, how many tests (probes, considered subsets, calls to is-interesting.sh) does the Delta Debugging algorithm
perform to identify the minimal subset when applied to input_list = [4, 5, 6, 8, 9, 10] ? Assume that in the
case of an odd sized set, the split will result in the first half being smaller. Your answer should be just a number (no spacing or
other characters).",6,Medium,'
901,SWE,"FIRST=0
SECOND=0
for i in $* ; do
 if [ $i -eq 5 ]; then FIRST=1 ; fi
 if [ $i -eq 8 ]; then SECOND=1 ; fi
done
if [ $FIRST -eq 1 ]; then
 if [ $SECOND -eq 1 ]; then
 exit 1 # yes, this set is interesting
 fi
fi
With the above interesting definition, give an input_list such that Delta Debugging will encounter interference exactly ONE
time. Remember that the input list must be interesting itself. Format your answer in the form of a Python list. (e.g., [1,2,3]).
If it’s not possible, type “NOT POSSIBLE”.","As long as the list of integers contains ""5"" and ""8"", it is correct. Example: [4,5,8]",Medium,'
902,SWE,"FIRST=0
SECOND=0
for i in $* ; do
 if [ $i -eq 5 ]; then FIRST=1 ; fi
 if [ $i -eq 8 ]; then SECOND=1 ; fi
done
if [ $FIRST -eq 1 ]; then
 if [ $SECOND -eq 1 ]; then
 exit 1 # yes, this set is interesting
 fi
fi

With the above interesting definition, give an input_list such that Delta Debugging will encounter interference TWO OR
MORE times. Remember that the input list must be interesting itself. Format your answer in the form of a Python list. (e.g.,
[1,2,3]). If it’s not possible, type “NOT POSSIBLE”.",NOT POSSIBLE,Medium,'
903,SWE,"FIRST=0
SECOND=0
for i in $* ; do
 if [ $i -eq 5 ]; then FIRST=1 ; fi
 if [ $i -eq 8 ]; then SECOND=1 ; fi
done
if [ $FIRST -eq 1 ]; then
 if [ $SECOND -eq 1 ]; then
 exit 1 # yes, this set is interesting
 fi
fi

Delta Debugging can identify a minimal set of conditions that cause a failure in a program. In the context of Andreas Zeller’s
Automated Debugging: Are We Close?, explain how Delta Debugging contrasts with traditional debugging methods and why it
is considered more systematic and efficient in some cases. Support your answer with a relevant quote from the text using no
more than 6 sentences.","Answer: Delta Debugging contrasts with traditional debugging by automating the process of narrowing down the minimal set
of conditions that cause a failure, making it more efficient in many cases. In traditional debugging, programmers manually
have to analyze code and test scenarios, which can be time consuming and error prone. As mentioned in the reading, “Delta
Debugging always produces a set of relevant failure-inducing circumstances, which offer significant insights into the nature
and cause of the failure.” This systemic approach can reduce trial and error and provide a clearer understanding of the
failure’s root cause.",Medium,'
904,SWE,"You've been tasked with debugging a large multi-threaded web server application that frequently crashes under heavy load.
Users report intermittent timeouts and unresponsive behavior during peak usage periods. As part of the debugging process,
you need to identify and resolve any threading issues that may be causing these performance problems.
Should you use static or dynamic analysis? Explain your reasoning.
PPlleeaassee l liimi mitt y yoouurr e ennttiirree a annsswweerr t too n noo mo morree t thhaann 3 3 s seenntteenncceess..","ANSWER: Answers may vary. For static over dynamic an example would be static analysis uses less resources. For dynamic over
static an example would be to talk about heisenbugs that static analysis can’t detect.",Medium,https://eecs481.org/exams/w24-exam2-key.pdf
905,SWE,"You're currently working on a design document which details the design of the work of a new, upcoming project that you will
be working on. After you finish writing the design document, you show it to your manager for approval. However, halfway
through reading the design document, your manager strongly disagrees with the tech stack you propose to use for the project.
Unfortunately, you fail to see why your manager disagrees, and you believe your original approach is better.

Trying to de-escalate the conflict as much as possible, you look to use your knowledge from EECS 481. What are two methods
you can use in this scenario to help resolve the conflict? For each method, explain why you can use it to help de-escalate the
conflict.
PPlleeaassee l liimi mitt y yoouurr e ennttiirree a annsswweerr t too n noo mo morree t thhaann 4 4 s seenntteenncceess..",ANSWER: Answers may vary. Clear communication and perhaps mediation can help.,Medium,'
906,SWE,Please describe two drawbacks of confusing variable naming. Limit your entire answer to at most two sentences.,"ANSWER:
Code duplication: increased maintenance effort, higher risk of bugs, difficulty in applying updates or new features, inflated
codebase, etc.",Easy,'
907,SWE,"Which design pattern ensures a class only has one instance, and provides a global point of access to it.",Answer: Singleton,Easy,'
908,SWE,"You have an existing unchangeable code base which uses player (an instance of MP3Player) to play the audio. You now want
to additionally support playing the audio of a MP4File by utilizing its provided play_music, without changing the codebase.
You wrap it in a new class MP4AudioPlayer inherited from MP3Player, and implement the compatible interface play.

def existingUnchangeableCodeBase(player):
 player.play()
class MP3Player:
 def play(self):
 print(f""Playing MP3 file."")
class MP4File:
 def play_music(self):
 print(""Playing audio of a MP4 file"")
class MP4AudioPlayer(MP3Player):
 def __init__(self, mp4_file):
 self.mp4_file = mp4_file
 def play(self):
 self.mp4_file.play_music()

Which design pattern that best matches the description above?",Adapter,Hard,'
909,SWE,"Suppose that a particular software development project spends X=38% of its lifetime effort on implementation, Y=45% of its
lifetime effort on testing, and Z=17% of its lifetime effort on other non-testing maintenance. You have proposed a new design,
and you would like to evaluate its effectiveness. In particular, you have already concluded:
(a) this new design would increase the effort required for implementation by M=15% (for example, if implementation previously took 10 hours, with an increase effort by 35%, it would now take 13.5 hours);
(b) but this new design would also reduce the effort required for testing by N=29%.
Assume the project originally required 100 hours to complete. Now, with this new design, please calculate the hours required
for the same project. Round your answer to the nearest integer. For example, 3.4 would be rounded to 3, and 3.6 would be
rounded to 4.",ANSWER: T = Z + X*(1+M%) + Y*(1-N%) = 93,Hard,'
910,SWE,"Support or refute the claim: Given that the time required to read code during activities like code reviews or inspections is
proportional to the number of lines, and understanding code is crucial in software maintenance, writing accurate programs
with minimal lines of code emerges as the optimal design approach for maintenance. This strategy not only saves time but
also enhances the maintainability of software by simplifying comprehension and debugging processes.
PPlleeaassee u ussee c coonnccrreettee l leeccttuurree a anndd//oorr r reeaaddiinngg ma matteerriiaallss,, t too b baacckk u upp y yoouurr a annsswweerr.. Limit your entire answer to at most 4 sentences.","ANSWER:
Refute: Trying to make the program as small as possible is almost certainly a perverse incentive, as per the Measurement
lecture. For example, we know from the Code Inspection lecture that beacons and descriptive variable names really help, but
descriptive variables and comments take up space.
Support: From the code review and inspection slides, we know that the recommended reading rate is about 400 LOC per hour
and that people get tired after an hour, so it is true that if you have a smaller program, it takes less time to read the whole
program. In addition, we saw in the Productivity lecture that the amount of code you can write per day, over the course of the
entire project, is a small constant.",Medium,'
911,SWE,"Suppose you are tasked to develop a mobile banking application for a new bank. This application should be capable of making
transactions internationally, and catering to both individuals and business clients.
List 2 possible ffuunnccttiioonnaall requirements for the application. Each requirement should be described using 1
sentence. Limit your entire answer to at most 2 sentences.","ANSWER: Answers will vary. The application should have multi-currency support (allow users to make, view, and receive
transactions in multiple currencies). The application should have support for multiple accounts per user (checking, savings,
business).",Medium,'
912,SWE,"Suppose you are tasked to develop a mobile banking application for a new bank. This application should be capable of making
transactions internationally, and catering to both individuals and business clients.
List 2 possible nnoonn--ffuunnccttiioonnaall requirements for the application. Each requirement should be described using 1
sentence. Limit your entire answer to at most 2 sentences.","ANSWER: Answers will vary. The application should have security measures to ensure the safety of users' financial data. The
application should have fast response times and minimal downtime to provide a seamless user experience.",Medium,'
913,SWE,"Suppose you are tasked to develop a mobile banking application for a new bank. This application should be capable of making
transactions internationally, and catering to both individuals and business clients.
Identify 2 possible stakeholders from the application, and describe a conflict that might arise between the 2
stakeholders. Explain wwhheetthheerr the conflict you mentioned is a strong or weak conflict and why. Limit your answer to no more
than 4 sentences.","ANSWER: Answers will vary. Two stakeholders could be an individual client and a business client. The individual client might
want a personalized, simple UI whereas the business client might want advanced features such as invoicing and payroll. This
case is a strong conflict because it is not possible for the individual client to have a seamless UI if the business client wants
advanced features.",Hard,'
914,SWE,"Bob is tasked with interviewing an applicant Alice for a software development position and evaluating Alice's technical skills.
The interview question is: given an integer array nums and an integer val, remove all occurrences of val from nums. The length
of nums can be zero or larger. Return the length of the resulting array.

def removeElement(nums: List[int], val: int) -> int:
 index = 1 # point to the end of the array after element removal
 for i in range(1, len(nums)):
 if nums[i] != val:
 nums[index] = nums[i]
 index += 1
 return 

Upon receiving the problem, Alice asked about the time complexity requirement, and whether the removal should
happen in-place. After a short while, Alice presented the above code to you.
Identify two points where Alice did well during the interview.","ANSWER: Asking about requirements; comments; meaningful variable naming; type declaration, etc.",Easy,'
915,SWE,"Bob is tasked with interviewing an applicant Alice for a software development position and evaluating Alice's technical skills.
The interview question is: given an integer array nums and an integer val, remove all occurrences of val from nums. The length
of nums can be zero or larger. Return the length of the resulting array.

def removeElement(nums: List[int], val: int) -> int:
 index = 1 # point to the end of the array after element removal
 for i in range(1, len(nums)):
 if nums[i] != val:
 nums[index] = nums[i]
 index += 1
 return 

Suppose you are Alice. After you delivered the solution above, Bob prompted you that there was a bug in your
code. Bob also asked you to write test cases to better test the code (at least to reveal the bug).
In your answer, please:
(1) describe the bug in one sentence;
(2) give one test case that can expose the bug;
(3) provide an additional test case, different from the one in (2), that you believe is also necessary for better testing the code,
and explain the rationale behind it.
Please limit your entire answer to at most five sentences.","ANSWER:
1) index=1 is problematic, because nums can be empty.
2) nums=[], val=arbitrary can expose the bug.
3) All reasonable answer accepted, eg. nums=[2,4,5,4], val=4, want to test the nums with multiple elements equal to val
included; or want to test a general case; or want to test an edge case etc.",Hard,'
916,SWE,"Your friend implemented a new automated program repair tool, GenMutantProg. In particular, GenMutantProg generates
candidate higher-order mutants — from the original, buggy program using a new set of mutation operators designed by your
friend — in hope that at least one of the candidate mutants will fix the bug from the original program and pass the test suite.
Explain what “higher-order” mutants mean in one sentence? Please also list one advantage and one disadvantage of
generating higher-order mutants, compared to generating any mutants in general. Please use at most two sentences for the
advantage and at most two sentences for the disadvantage.","Answer:
Explanation of what high-order mutants mean. High-order mutants change multiple operators at the same time from
the original program.
Advantage of high-order mutants in this case. high-order mutants are more likely to fix the bug in the original
program
Disadvantage of high-order mutants in this case. Even though high-order mutants might fix the bug in the original
program, it is likely that at the same time one (or more) of the mutants introduces more bugs.",Medium,https://eecs481.org/exams/w23-exam2-key.pdf
917,SWE,"Your team maintains a codebase and your manager proposes to apply readability metrics to each pull request with the goal of
making sure the codebase contains highly readable code. Specifically, the plan is to calculate the readability score for the code
in each pull request, and only those pull requests with a high readability score can be merged into the codebase.
Is this a good plan? Would this plan go wrong in any way? Please list one possibility that this plan could go wrong. Use at most
two sentences in your answer.","Answer: (non-exhaustive, but typically it should mention it’s not a good plan):
It can lead to perverse incentives: It may be true that existing code with a few more blank lines is more readable. So what if
we just insert a blank line between every line of code?",Medium,'
918,SWE,"Suppose you maintain a very large, currently closed-source project that is very popular among many users. At some point, you
received too many feature requests and bug reports that you could not handle all by yourself alone. Now, you want to turn this
project into an open-source one, with the goal of using contributors online to resolve issues (including implementing new
features and/or fixing bugs).
However, one concern you have is that “random contributors” with different backgrounds may end up creating low-quality
code (such as code that does not function properly, code that functions but has low readability, etc.). You don’t want to allow
online contributors to add such low-quality code into your project’s codebase.
What is one approach that you can use to make sure no (or very little) low-quality code can be inserted into the codebase?
Limit your answer to at most two sentences.","Answer: (non-exhaustive):
Code review
Automated unit tests/regression tests/style checks",Medium,'
919,SWE,"Imagine you are working on the autopilot feature for an airplane manufacturer. Once implemented, this feature will be
deployed on all airplanes.
Please list one informal quality requirement and one verifiable quality requirement for this task.","Answer: (non-exhaustive):
Informal quality requirements: The feature should run reliably/accurately/efficiently
Verifiable quality requirements: The answer that receives full credits will include verifiable statistics (typically a number). For
example: in 1000 runs, it should correctly identify the optimal path in 999 runs. Another example: it should pass all 70 unit
tests.",Medium,'
920,SWE,"You have developed a tool, ErrorFixer481, that automatically fixes “Last-Mile Errors”. In particular, ErrorFixer481 is based on a
neural approach.
From the guest lecture presented by Jose Cambronero, what are Last-Mile Errors? What is one disadvantage of using a neural
approach? Please limit your answer to 4 sentences.","Answer
Definition of last-mile errors: errors that require few edits to fix (2pts)
One disadvantage of the neural approach (non-exhaustive)(2pts): need new data and retraining for new domain",Medium,'
921,SWE,"Suppose that a particular software engineering project spends 40% of its lifetime effort on implementation, 45%
of its lifetime effort on design and documentation, and 15% of its lifetime effort on testing. You are considering a design that
would (a) decrease the effort required for implementation by 20% (for example, if implementation previously took 10 hours,
but that effort is increased by 35%, it would now take 13.5 hours); however, adopting this design would also (b) increase the
effort required for design and documentation by 10% and (c) increase the effort required for testing by 10%. Assume the
project originally required 100 hours to complete over its lifetime and calculate the new hours required by the project with
your new proposed design. Should the new design be adopted? Explain your reasoning with no more than 3 sentences.","ANSWER: Old Design: 100 hours New Design: 98 hours New design should be adopted. Overall, the lifetime hours are only 2%
less. Even though less time is spent on implementation, we are focusing more on designing, documenting, and testing which
are crucial for code’s longevity and maintainability. ",Medium,'
922,SWE,"Suppose you and your partner are working on a large project together. Your partner encourages you not to add
any inline comments, as they say it makes the code look messy. Do you think your project would benefit from inline
comments? If you aren’t able to have inline comments, what is another strategy you could use to make sure your code is
accessible/maintainable for new team members? Briefly explain how this strategy would be helpful. Use at most 4 sentences.","ANSWER: The code may or may not benefit from inline comments, depending on complexity and how many there are, a good
argument about this is worth 1 point. 1 point for identifying alternative documentation (a really thorough README, git commit
messages/issues/PRs, wiki type articles) and 1 point for explaining how that would help a new team member.",Medium,'
923,SWE,"C is considered to be a low-level language while Python is considered to be a high-level language.
What are two key reasons, with respect to productivity, that one would advocate for using a higher-level language? You may
consider any aspects of software development (e.g., productivity, quality assurance, etc.). Limit your answer to no more than 4
sentences.","Answer: Modern estimates suggest that, on average, people write 10 lines of code per day in industry. The language invariance
states this number does not vary with programming language. Therefore, higher-level languages can get more work done in
10 lines. (from the productivity lecture). Students might also reference code review/inspection, pair programming, etc.",Medium,https://eecs481.org/exams/f22-exam2-key.pdf
924,SWE,"Your team is implementing a function that searches for an object from a large database.
This function takes as input two parameters: the target object and the database. Currently the two parameters of this function
are named “x” (for the target object) and “y” (for the database). However, one of your colleagues suggests naming the two
parameters as “target” and “database”.
Do you agree or disagree with this idea and why? Please reference at least two pieces of evidence from the course or elsewhere
when justifying your answer. Limit your answer to at most 4 sentences.","Answer: Agree. Top-down comprehension based on semantic cues is more efficient (easier) than bottom-up comprehension. In
other words, when compared to bottom-up comprehension, the response times are identical while energy use “across the
board” is lower. We should also reference the code review / code inspection lecture (time taken, someone else reading it, etc.)
as well as the design for maintainability lecture (what vs. why, etc.).",Medium,'
925,SWE,"Automated Program Repair tools often generate multiple candidate mutants — from an original, buggy program — in hope
that at least one of the candidate mutants will fix the bug in the original program.
For a candidate to be a valid plausible repair, it needs to pass the entire test suite. The entire test suite may consist of
thousands of test cases and thus may take a long time to run.
How can dataflow analysis for dead code be used to make the testing process more efficient, and how is this related to the
notion of static analyses being conservative? Please limit your answer to no more than 4 sentences.","Answer: In the special case of dead code, we can use dataflow analysis to decide whether two programs are functionally
equivalent. This problem is undecideable in general, but we if the dataflow analysis says an inserted line of code is dead, then
we know it and the original program are equivalent, and if it does not say the line is dead code, then we conservatively must
check it anyway. This is a conservative approximation because some edits may result in equivalent programs, but dead code
analysis won't always be able to detect them, and in such cases we have to run all of the tests anyway (conservatively). As a
result, we can reduce the search space by a factor of 10. Two programs that are functionally equivalent will have the same
behavior against the test suite. ",Hard,'
926,SWE,"Excel’s FlashFill feature works well at converting a list of full names to a list of initials.
However, it does poorly when used to convert between a month’s abbreviation to its full name (e.g., MAR to March). Explain
why it fails in this case, using concepts covered in the lectures. Limit your answer to no more than 4 sentences.","Answer: FlashFill is a Domain-specific language (DSL) for string transformation. In other words, FlashFill cannot synthesize
programs that are not expressible in its underlying programming language. In this case, transforming dates is not supported.",Medium,'
927,SWE,"Lizzy is making preparations to open her new hot air balloon resale shop on State Street called Maize and Blue'ns.
Her store will sell locally to Michigan but also online to Ohio. The local and online sales have different taxes and policies. In 3
sentences or fewer, describe which design pattern you would use and why, and one risk associated with that design pattern.","ANSWER: Multiple answers are possible. However, the question intentionally favors the Template Method. The Strategy design
pattern is also a decent fit, but is slightly harder to support. In class (e.g., slide 35 of the Design for Maintainability lecture) we
explicitly considered the situation of a store that sells in different states with different tax policies. Students could argue for
Strategy (which is extensible and separates the algorithm from the client), but the Template Method is likely a better fit since
there are explicitly invariant parts (e.g., doing sales, tracking stock, etc.) and changing parts (different states with different
policies). Students could lose points by confusing multiple methods (e.g., saying Template Method but then listing features
associated with Strategy) or by listing Strategy but not providing enough support.",Medium,https://eecs481.org/exams/w22-exam2-key.pdf
928,SWE,"Cassie is adding a new feature to decrease wait times at her carnival attraction Euphoric Carousel. Describe four
steps or activities she might follow for effective requirement elicitation. Use 4 sentences or fewer.","ANSWER: This question admits a significant amount of freedom. Students could describe 'capturing and representing
knowledge', 'identifying stakeholders', 'understanding the domain', 'interviews', and so on. Students could also list activities
that make a high-level step effective, such as 'ask follow-up questions' or 'begin with specific questions' for effective interviews.
Students could also list conflict resolution activities such as 'build a glossary' or 'explore tradeoffs'.",Medium,'
929,SWE,"List two similarities between Program Synthesis and Pair Programming. Then list two differences. Strong answers
should include a focus on the inputs and outcomes of the two tools — on when they can be used and what benefits they
provide. For example, do not simply say that one involves a second human and the other does not. Instead, compare and
contrast them in terms of their potential use in a software development process. Use at most 4 sentences.","ANSWER: Program Synthesis and Pair Programming both involve one agent producing code under the guidance of another
agent. Program Synthesis and Pair Programming both have the potential to reduce overall development effort. Pair
Programming favors communication, brainstorming and the generation of ideas and example — Program Synthesis often
requires examples or demonstrations to make progress. Pair Programming and Program Synthesis can both be useful when
creating or prototyping new code.
However, Pair Programming is likely to be useful in debugging or fault localization activities, but Program Synthesis is mostly
used only in code creation. Pair Programming may take more time than programming alone (even if it is a net advantage due
to, for example, reduced defects), while Program Synthesis (when it can solve a problem) is almost always faster than a single
programmer. Program Synthesis typically produces code in a restricted domain-specific language while Pair Programming can
produce code in any language both participants are familiar with.",Hard,'
930,SWE,"Describe, in your own words, a project that might require multiple languages. Then, provide one advantage and
one disadvantage of multi-language projects. Use at most 4 sentences.","ANSWER: Projects can vary from things like TensorFlow to personal projects. 1 point for vague answer (e.g., a project that
needs a fast C kernel), 2 points for a description of a project that involves multiple languages but no cross-language
interaction, and full credit for a project that describes in detail a project where multiple languages interact.
Advantages: Some processes can be more effectively coded or optimized in an alternate language, provides more functionality
and flexibility for projects, increasingly common, etc.
Disadvantages: Integrating data and control flow across languages can be difficult, debugging can be harder, building
becomes more complicated, developers must have expertise in more than one language.",Medium,'
