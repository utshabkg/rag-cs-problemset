Model,Model_Size_B,Mean_Score,Std_Score,Median_Score,Min_Score,Max_Score
Mistral-7B-v0.1,7,0.44086956521739135,0.3565771024278924,0.55,0.0,1.0
deepseek-llm-7b-chat,7,0.45190760869565216,0.4978780885109351,0.0,0.0,1.5
Qwen2.5-7B-Instruct,7,0.8276630434782607,0.15264613948385153,0.85,0.0,1.0
Meta-Llama-3-8B,8,0.5275543478260869,0.3335827821695328,0.6,0.0,1.0
aya-expanse-8b,8,0.7177934782608695,0.26157558253085145,0.85,0.0,1.0
